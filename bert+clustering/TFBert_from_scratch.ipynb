{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertTokenizer, BertTokenizerFast, TFBertForMaskedLM, AdamWeightDecay, DataCollatorForLanguageModeling\n",
    "import tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8b71f57495763543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default to /Users/gjuan/.cache/huggingface/datasets/text/default-8b71f57495763543/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 5007.13it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 596.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /Users/gjuan/.cache/huggingface/datasets/text/default-8b71f57495763543/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 318.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "dataset_path = \"/Users/gjuan/semiolog/models/en_bnc_berttest/corpus/\"\n",
    "dataset_files = [\"train\",\"dev\",\"test\"]\n",
    "extension = \"text\"\n",
    "\n",
    "# Use the argument split=[\"train[:1%]\", \"dev[:1%]\"] to load only 1% of each\n",
    "# split. However, this makes the dataset object not be a dict (with keys \"train\"\n",
    "# and \"dev\") but a list. To call the train split (for instance, below), one\n",
    "# should use dataset[0][\"text\"] instead of dataset[\"train\"][\"text\"]\n",
    "\n",
    "# dataset = load_dataset(extension, data_files={f:dataset_path+f+\".txt\" for f in dataset_files})#, split=[\"train[:1%]\", \"dev[:1%]\"])\n",
    "dataset = load_dataset(extension, data_files={k:dataset_path+f+\".txt\" for k,f in zip(dataset_files,[\"test\",\"dev\",\"test\"])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary of segmented sentences and save it to a vocab.txt file\n",
    "\n",
    "if not os.path.isfile(\"vocab.txt\") or False:\n",
    "    tokens = []\n",
    "\n",
    "    for sent in dataset[\"train\"][\"text\"]:\n",
    "            tokens.extend(sent.split())\n",
    "    tokens_count = Counter(tokens) # This could probably be done directly on the counter\n",
    "    vocab = [token for token, freq in tokens_count.most_common()]\n",
    "\n",
    "    with open(\"vocab.txt\", 'w') as f:\n",
    "        for token in [\"[PAD]\", \"[SEP]\", \"[CLS]\", \"[MASK]\", \"[UNK]\"] + vocab:\n",
    "            f.write(\"%s\\n\" % token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " #0:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " #0: 100%|██████████| 1/1 [00:00<00:00,  6.78ba/s]\n",
      " #1: 100%|██████████| 1/1 [00:00<00:00,  6.08ba/s]\n",
      "\n",
      " #2: 100%|██████████| 1/1 [00:00<00:00,  5.53ba/s]\n",
      "\n",
      "\n",
      " #3: 100%|██████████| 1/1 [00:00<00:00,  5.47ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " #6: 100%|██████████| 1/1 [00:00<00:00,  5.31ba/s]\n",
      " #4: 100%|██████████| 1/1 [00:00<00:00,  4.78ba/s]\n",
      " #5: 100%|██████████| 1/1 [00:00<00:00,  4.83ba/s]\n",
      " #7: 100%|██████████| 1/1 [00:00<00:00,  5.21ba/s]\n",
      "\n",
      "\n",
      " #0:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " #1: 100%|██████████| 1/1 [00:00<00:00,  9.56ba/s]\n",
      " #3: 100%|██████████| 1/1 [00:00<00:00,  9.38ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " #4: 100%|██████████| 1/1 [00:00<00:00,  5.96ba/s]\n",
      " #5: 100%|██████████| 1/1 [00:00<00:00,  5.99ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " #6: 100%|██████████| 1/1 [00:00<00:00,  5.63ba/s]\n",
      " #0: 100%|██████████| 1/1 [00:00<00:00,  4.30ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " #7: 100%|██████████| 1/1 [00:00<00:00,  4.71ba/s]\n",
      " #2: 100%|██████████| 1/1 [00:00<00:00,  3.83ba/s]\n",
      " #0:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " #0: 100%|██████████| 1/1 [00:00<00:00,  4.42ba/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " #2: 100%|██████████| 1/1 [00:00<00:00,  3.73ba/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " #5: 100%|██████████| 1/1 [00:00<00:00,  4.13ba/s]\n",
      " #1: 100%|██████████| 1/1 [00:00<00:00,  3.41ba/s]\n",
      " #6: 100%|██████████| 1/1 [00:00<00:00,  4.27ba/s]\n",
      " #3: 100%|██████████| 1/1 [00:00<00:00,  3.52ba/s]\n",
      " #4: 100%|██████████| 1/1 [00:00<00:00,  3.63ba/s]\n",
      " #7: 100%|██████████| 1/1 [00:00<00:00,  4.27ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] then using all thep an ache of basil faw l ty i display ed a carefully laid out tray of h oot ers for aparty go er [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Build tokenizer out that vocabulary and tokenize the dataset\n",
    "\n",
    "# tokenizer= BertTokenizer(\n",
    "#         vocab_file = \"vocab.txt\",\n",
    "#         do_lower_case=True,\n",
    "#         do_basic_tokenize=True,\n",
    "#         never_split=None,\n",
    "#         unk_token=\"[UNK]\",\n",
    "#         sep_token=\"[SEP]\",\n",
    "#         pad_token=\"[PAD]\",\n",
    "#         cls_token=\"[CLS]\",\n",
    "#         mask_token=\"[MASK]\",\n",
    "#         tokenize_chinese_chars=True,\n",
    "#         strip_accents=None,\n",
    "# )\n",
    "\n",
    "tokenizer = BertTokenizerFast(\n",
    "        vocab_file=\"vocab.txt\",\n",
    "        tokenizer_file=None,\n",
    "        do_lower_case=True,\n",
    "        unk_token=\"[UNK]\",\n",
    "        sep_token=\"[SEP]\",\n",
    "        pad_token=\"[PAD]\",\n",
    "        cls_token=\"[CLS]\",\n",
    "        mask_token=\"[MASK]\",\n",
    "        tokenize_chinese_chars=True,\n",
    "        strip_accents=None,\n",
    ")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, batch_size=10000, num_proc=8, remove_columns=[\"text\"])\n",
    "\n",
    "# print a decoded tokenized sentence\n",
    "print(tokenizer.decode(tokenized_datasets[\"train\"][0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! Please ensure your labels are passed as the 'labels' key of the input dict so that they are accessible to the model during the forward pass. To disable this behaviour, please pass a loss argument, or explicitly pass loss=None if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "# Build the model (Huggingface Tensor Flow Bert for Mask Language Model: TFBertForMaskedLM)\n",
    "\n",
    "configuration = BertConfig(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        hidden_size=768,\n",
    "        num_hidden_layers=12,\n",
    "        num_attention_heads=12,\n",
    "        intermediate_size=3072,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        max_position_embeddings=512,\n",
    "        type_vocab_size=2,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        pad_token_id=0,\n",
    "        position_embedding_type=\"absolute\",\n",
    "        use_cache=True,\n",
    "        classifier_dropout=None,\n",
    ")\n",
    "\n",
    "model = TFBertForMaskedLM(\n",
    "    configuration\n",
    ")\n",
    "\n",
    "learning_rate = 5e-5 #2e-5\n",
    "weight_decay = 0.01\n",
    "\n",
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer\n",
    "    # optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    # metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Data Collator and train and validation sets. The Data Collator\n",
    "# construct the batches, with padding, and in this particular case, random\n",
    "# masking at a probability defined in the argument: mlm_probability\"). Outputing\n",
    "# TensorFlow tensors must be asked explicitly.\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15,\n",
    "return_tensors=\"tf\"\n",
    ")\n",
    "\n",
    "train_set = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "validation_set = tokenized_datasets[\"dev\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From /Users/gjuan/.pyenv/versions/3.9.4/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "303/303 [==============================] - 1055s 3s/step - loss: 9.0891 - val_loss: 8.8661\n",
      "Epoch 2/2\n",
      "303/303 [==============================] - 878s 3s/step - loss: 8.7070 - val_loss: 8.7760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x179db30d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit(train_set, validation_data=validation_set, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(save_directory=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at ./tf_model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "config2 = \"./config.json\"\n",
    "model2 = TFBertForMaskedLM.from_pretrained('./tf_model.h5', config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these canget into food [MASK] water especially in countries with poor s an itary facilities and thus infect otherpeople'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = dataset[\"dev\"][200][\"text\"]\n",
    "n = 4\n",
    "sent_mask = \" \".join([t if i!=n else \"[MASK]\" for i,t in enumerate(sent.split())])\n",
    "sent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFMaskedLMOutput(loss=None, logits=<tf.Tensor: shape=(1, 21, 26290), dtype=float32, numpy=\n",
       "array([[[-3.7524655, -1.9820781, -1.8103092, ..., -4.796723 ,\n",
       "         -5.1437397, -5.0155263],\n",
       "        [-3.7525015, -1.9820858, -1.8103209, ..., -4.796742 ,\n",
       "         -5.1437283, -5.015563 ],\n",
       "        [-3.7523944, -1.9820297, -1.8102915, ..., -4.796576 ,\n",
       "         -5.143581 , -5.0154   ],\n",
       "        ...,\n",
       "        [-3.752418 , -1.9820464, -1.8103127, ..., -4.796629 ,\n",
       "         -5.143641 , -5.0154343],\n",
       "        [-3.7524612, -1.9820689, -1.8103261, ..., -4.7967014,\n",
       "         -5.1437335, -5.01552  ],\n",
       "        [-3.7524457, -1.9820572, -1.8103211, ..., -4.7966614,\n",
       "         -5.14363  , -5.0154767]]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(tokenizer(sent_mask, return_tensors=\"tf\")[\"input_ids\"])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these canget into food or water especially in countries with poor s an itary facilities and thus infect otherpeople'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parad = [[(tokenizer.ids_to_tokens[k],v) for v,k in sorted([(v,i) for i,v in enumerate(outputs.logits[:,p].numpy().tolist()[0])], reverse=True)] for p in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('and', 4.18861722946167),\n",
       "  ('in', 3.6120033264160156),\n",
       "  ('the', 3.423407793045044),\n",
       "  ('a', 3.3643510341644287)],\n",
       " [('and', 4.188627243041992),\n",
       "  ('in', 3.6119933128356934),\n",
       "  ('the', 3.423452138900757),\n",
       "  ('a', 3.364354133605957)],\n",
       " [('and', 4.18848991394043),\n",
       "  ('in', 3.611909866333008),\n",
       "  ('the', 3.4233429431915283),\n",
       "  ('a', 3.364262342453003)],\n",
       " [('and', 4.1886138916015625),\n",
       "  ('in', 3.611983299255371),\n",
       "  ('the', 3.4234120845794678),\n",
       "  ('a', 3.3643462657928467)],\n",
       " [('and', 4.188564300537109),\n",
       "  ('in', 3.6119673252105713),\n",
       "  ('the', 3.4233763217926025),\n",
       "  ('a', 3.3643195629119873)],\n",
       " [('and', 4.188572406768799),\n",
       "  ('in', 3.611945152282715),\n",
       "  ('the', 3.423354387283325),\n",
       "  ('a', 3.3643226623535156)],\n",
       " [('and', 4.188621997833252),\n",
       "  ('in', 3.6120097637176514),\n",
       "  ('the', 3.4233970642089844),\n",
       "  ('a', 3.3643224239349365)],\n",
       " [('and', 4.18859338760376),\n",
       "  ('in', 3.611996650695801),\n",
       "  ('the', 3.423382043838501),\n",
       "  ('a', 3.364325523376465)],\n",
       " [('and', 4.188673973083496),\n",
       "  ('in', 3.6120736598968506),\n",
       "  ('the', 3.4234230518341064),\n",
       "  ('a', 3.364363431930542)],\n",
       " [('and', 4.188634872436523),\n",
       "  ('in', 3.6119704246520996),\n",
       "  ('the', 3.423402786254883),\n",
       "  ('a', 3.3643386363983154)],\n",
       " [('and', 4.188622951507568),\n",
       "  ('in', 3.611994981765747),\n",
       "  ('the', 3.423379898071289),\n",
       "  ('a', 3.364342212677002)],\n",
       " [('and', 4.188541412353516),\n",
       "  ('in', 3.611928701400757),\n",
       "  ('the', 3.423330783843994),\n",
       "  ('a', 3.3642852306365967)],\n",
       " [('and', 4.188640594482422),\n",
       "  ('in', 3.612018346786499),\n",
       "  ('the', 3.423412799835205),\n",
       "  ('a', 3.3643577098846436)],\n",
       " [('and', 4.188643455505371),\n",
       "  ('in', 3.6120176315307617),\n",
       "  ('the', 3.4234254360198975),\n",
       "  ('a', 3.3643569946289062)],\n",
       " [('and', 4.188562870025635),\n",
       "  ('in', 3.6119544506073),\n",
       "  ('the', 3.4233462810516357),\n",
       "  ('a', 3.3642940521240234)],\n",
       " [('and', 4.188511848449707),\n",
       "  ('in', 3.6119441986083984),\n",
       "  ('the', 3.423323154449463),\n",
       "  ('a', 3.3642735481262207)],\n",
       " [('and', 4.1887288093566895),\n",
       "  ('in', 3.6120495796203613),\n",
       "  ('the', 3.423443078994751),\n",
       "  ('a', 3.3643672466278076)],\n",
       " [('and', 4.188560485839844),\n",
       "  ('in', 3.6119678020477295),\n",
       "  ('the', 3.4233405590057373),\n",
       "  ('a', 3.3642985820770264)],\n",
       " [('and', 4.188554763793945),\n",
       "  ('in', 3.611927032470703),\n",
       "  ('the', 3.4233479499816895),\n",
       "  ('a', 3.364301919937134)],\n",
       " [('and', 4.188596725463867),\n",
       "  ('in', 3.611995220184326),\n",
       "  ('the', 3.4233922958374023),\n",
       "  ('a', 3.3643202781677246)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[parad[i][:4] for i in range(len(parad))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 4.188596725463867),\n",
       " ('in', 3.611995220184326),\n",
       " ('the', 3.4233922958374023),\n",
       " ('a', 3.3643202781677246),\n",
       " ('of', 3.1104166507720947),\n",
       " ('s', 2.9200122356414795),\n",
       " ('as', 2.7588236331939697),\n",
       " ('to', 2.752182722091675),\n",
       " ('for', 2.6618316173553467),\n",
       " ('is', 2.543020486831665),\n",
       " ('ing', 2.5419626235961914),\n",
       " ('that', 2.469393730163574),\n",
       " ('ed', 2.4655823707580566),\n",
       " ('with', 2.2697136402130127),\n",
       " ('but', 2.2521259784698486),\n",
       " ('it', 2.1866116523742676),\n",
       " ('on', 2.175072193145752),\n",
       " ('are', 2.151090145111084),\n",
       " ('was', 2.099869728088379),\n",
       " ('their', 2.0783278942108154),\n",
       " ('by', 2.038564443588257),\n",
       " ('from', 1.9598013162612915),\n",
       " ('or', 1.9573495388031006),\n",
       " ('which', 1.919629454612732),\n",
       " ('sof', 1.9009828567504883),\n",
       " ('at', 1.8680275678634644),\n",
       " ('an', 1.8291583061218262),\n",
       " ('all', 1.7533565759658813),\n",
       " ('inthe', 1.6526025533676147),\n",
       " ('ofthe', 1.6392264366149902),\n",
       " ('so', 1.5874210596084595),\n",
       " ('his', 1.5371545553207397),\n",
       " ('ly', 1.5112706422805786),\n",
       " ('forthe', 1.4921764135360718),\n",
       " ('up', 1.4889801740646362),\n",
       " ('tothe', 1.419952154159546),\n",
       " ('her', 1.4174782037734985),\n",
       " ('er', 1.3927414417266846),\n",
       " ('edby', 1.3834657669067383),\n",
       " ('sand', 1.3773835897445679),\n",
       " ('will', 1.3194668292999268),\n",
       " ('not', 1.3055858612060547),\n",
       " ('more', 1.3034896850585938),\n",
       " ('y', 1.2682865858078003),\n",
       " ('this', 1.2675282955169678),\n",
       " ('onthe', 1.2601557970046997),\n",
       " ('has', 1.2402127981185913),\n",
       " ('after', 1.2247577905654907),\n",
       " ('over', 1.1858409643173218),\n",
       " ('e', 1.181726336479187),\n",
       " ('they', 1.1787561178207397),\n",
       " ('what', 1.1764119863510132),\n",
       " ('now', 1.1593527793884277),\n",
       " ('ers', 1.159040093421936),\n",
       " ('ad', 1.1585323810577393),\n",
       " ('being', 1.1480348110198975),\n",
       " ('al', 1.138663649559021),\n",
       " ('its', 1.1377400159835815),\n",
       " ('p', 1.1237914562225342),\n",
       " ('you', 1.1106228828430176),\n",
       " ('atthe', 1.105273723602295),\n",
       " ('down', 1.0897501707077026),\n",
       " ('well', 1.081494927406311),\n",
       " ('one', 1.0806487798690796),\n",
       " ('out', 1.0806317329406738),\n",
       " ('un', 1.0792149305343628),\n",
       " ('these', 1.0744575262069702),\n",
       " ('like', 1.0715301036834717),\n",
       " ('had', 1.0681785345077515),\n",
       " ('he', 1.0664681196212769),\n",
       " ('them', 1.062146782875061),\n",
       " ('however', 1.0229346752166748),\n",
       " ('open', 1.0057815313339233),\n",
       " ('very', 0.9955208897590637),\n",
       " ('swere', 0.9930244088172913),\n",
       " ('withthe', 0.9920066595077515),\n",
       " ('ate', 0.9782595038414001),\n",
       " ('if', 0.9752914309501648),\n",
       " ('id', 0.9717839956283569),\n",
       " ('both', 0.9662997722625732),\n",
       " ('then', 0.9343931078910828),\n",
       " ('ingthe', 0.9308047890663147),\n",
       " ('willbe', 0.916740357875824),\n",
       " ('our', 0.9096766114234924),\n",
       " ('st', 0.9009581804275513),\n",
       " ('itis', 0.8778434991836548),\n",
       " ('itwas', 0.870171844959259),\n",
       " ('when', 0.8645011186599731),\n",
       " ('place', 0.8427491784095764),\n",
       " ('me', 0.8384291529655457),\n",
       " ('andthe', 0.8232009410858154),\n",
       " ('end', 0.8140720129013062),\n",
       " ('dis', 0.8076232075691223),\n",
       " ('before', 0.7997972965240479),\n",
       " ('some', 0.7986429333686829),\n",
       " ('who', 0.7946624755859375),\n",
       " ('top', 0.7849791646003723),\n",
       " ('she', 0.7692611217498779),\n",
       " ('am', 0.7673812508583069),\n",
       " ('because', 0.757354736328125),\n",
       " ('were', 0.753876805305481),\n",
       " ('about', 0.7511958479881287),\n",
       " ('es', 0.7399439811706543),\n",
       " ('i', 0.7393589615821838),\n",
       " ('de', 0.7308561205863953),\n",
       " ('be', 0.7238130569458008),\n",
       " ('should', 0.7203500866889954),\n",
       " ('have', 0.71871417760849),\n",
       " ('how', 0.715461790561676),\n",
       " ('ated', 0.709293782711029),\n",
       " ('m', 0.7064841389656067),\n",
       " ('t', 0.6898095607757568),\n",
       " ('made', 0.6503640413284302),\n",
       " ('your', 0.6395373940467834),\n",
       " ('thatthe', 0.6336239576339722),\n",
       " ('him', 0.6109103560447693),\n",
       " ('use', 0.6038874983787537),\n",
       " ('sare', 0.603480875492096),\n",
       " ('tobe', 0.5953811407089233),\n",
       " ('ah', 0.593451738357544),\n",
       " ('than', 0.5894008874893188),\n",
       " ('first', 0.5822848081588745),\n",
       " ('any', 0.5819017887115479),\n",
       " ('en', 0.579866886138916),\n",
       " ('said', 0.5771037936210632),\n",
       " ('ut', 0.5685401558876038),\n",
       " ('between', 0.56380295753479),\n",
       " ('us', 0.562586784362793),\n",
       " ('edin', 0.5439702272415161),\n",
       " ('able', 0.5436840057373047),\n",
       " ('hadbeen', 0.5414645671844482),\n",
       " ('havebeen', 0.5390923619270325),\n",
       " ('new', 0.5384907722473145),\n",
       " ('ic', 0.5370153784751892),\n",
       " ('car', 0.5319360494613647),\n",
       " ('make', 0.5267786383628845),\n",
       " ('hewas', 0.5195579528808594),\n",
       " ('also', 0.5053325891494751),\n",
       " ('d', 0.5031552314758301),\n",
       " ('outof', 0.4983938932418823),\n",
       " ('ab', 0.4932360351085663),\n",
       " ('l', 0.4846830368041992),\n",
       " ('just', 0.4793558120727539),\n",
       " ('h', 0.4758477807044983),\n",
       " ('life', 0.47253182530403137),\n",
       " ('thatis', 0.47237834334373474),\n",
       " ('ands', 0.46311357617378235),\n",
       " ('c', 0.4610399603843689),\n",
       " ('do', 0.4588022232055664),\n",
       " ('thisis', 0.4571782648563385),\n",
       " ('sor', 0.44879505038261414),\n",
       " ('thes', 0.4303807020187378),\n",
       " ('less', 0.42277976870536804),\n",
       " ('would', 0.41706225275993347),\n",
       " ('partofthe', 0.4138144850730896),\n",
       " ('edto', 0.4077501893043518),\n",
       " ('time', 0.4034692943096161),\n",
       " ('people', 0.4016842544078827),\n",
       " ('g', 0.39946386218070984),\n",
       " ('anew', 0.39623963832855225),\n",
       " ('ation', 0.3905866742134094),\n",
       " ('used', 0.38879433274269104),\n",
       " ('ap', 0.3845011293888092),\n",
       " ('side', 0.38070735335350037),\n",
       " ('experience', 0.3801468014717102),\n",
       " ('men', 0.3793400526046753),\n",
       " ('thesame', 0.3779509663581848),\n",
       " ('shewas', 0.3778892457485199),\n",
       " ('found', 0.3711046874523163),\n",
       " ('edthe', 0.3700577914714813),\n",
       " ('youmay', 0.361531525850296),\n",
       " ('edat', 0.35581114888191223),\n",
       " ('around', 0.35277900099754333),\n",
       " ('canbe', 0.3520709276199341),\n",
       " ('son', 0.3444174528121948),\n",
       " ('three', 0.3430471122264862),\n",
       " ('ating', 0.342806339263916),\n",
       " ('london', 0.33792486786842346),\n",
       " ('system', 0.337401807308197),\n",
       " ('other', 0.3373609483242035),\n",
       " ('while', 0.3355967700481415),\n",
       " ('4', 0.33545202016830444),\n",
       " ('only', 0.333047091960907),\n",
       " ('r', 0.33240652084350586),\n",
       " ('ent', 0.3311406373977661),\n",
       " ('est', 0.3305603861808777),\n",
       " ('ina', 0.325199693441391),\n",
       " ('back', 0.3050273358821869),\n",
       " ('b', 0.3030985891819),\n",
       " ('my', 0.30213943123817444),\n",
       " ('tomake', 0.30072206258773804),\n",
       " ('no', 0.2967453598976135),\n",
       " ('low', 0.2854841947555542),\n",
       " ('re', 0.282010942697525),\n",
       " ('left', 0.28165432810783386),\n",
       " ('todo', 0.27771973609924316),\n",
       " ('hasbeen', 0.27414628863334656),\n",
       " ('man', 0.27408742904663086),\n",
       " ('fromthe', 0.26648950576782227),\n",
       " ('le', 0.2619384825229645),\n",
       " ('softhe', 0.25955653190612793),\n",
       " ('into', 0.25488412380218506),\n",
       " ('therewas', 0.25121429562568665),\n",
       " ('work', 0.24930374324321747),\n",
       " ('without', 0.24718856811523438),\n",
       " ('house', 0.24602635204792023),\n",
       " ('became', 0.23906318843364716),\n",
       " ('50', 0.23750169575214386),\n",
       " ('land', 0.23081381618976593),\n",
       " ('yet', 0.22943678498268127),\n",
       " ('believe', 0.2250332534313202),\n",
       " ('2', 0.21755357086658478),\n",
       " ('still', 0.2134104073047638),\n",
       " ('ay', 0.20915180444717407),\n",
       " ('f', 0.20882548391819),\n",
       " ('we', 0.2039806842803955),\n",
       " ('may', 0.19914068281650543),\n",
       " ('such', 0.1965118795633316),\n",
       " ('ir', 0.19257695972919464),\n",
       " ('ive', 0.1905345469713211),\n",
       " ('best', 0.18952195346355438),\n",
       " ('even', 0.1890074908733368),\n",
       " ('years', 0.18709345161914825),\n",
       " ('andhis', 0.1818499118089676),\n",
       " ('two', 0.17989405989646912),\n",
       " ('erm', 0.17666010558605194),\n",
       " ('25', 0.16355229914188385),\n",
       " ('focus', 0.15986739099025726),\n",
       " ('aand', 0.15734818577766418),\n",
       " ('wouldhave', 0.15563218295574188),\n",
       " ('sthe', 0.15123037993907928),\n",
       " ('where', 0.15099197626113892),\n",
       " ('tor', 0.14892935752868652),\n",
       " ('n', 0.14853931963443756),\n",
       " ('doesnot', 0.14744074642658234),\n",
       " ('several', 0.1414049118757248),\n",
       " ('theyre', 0.13510967791080475),\n",
       " ('theywere', 0.13419422507286072),\n",
       " ('per', 0.131317138671875),\n",
       " ('ifyou', 0.1250704675912857),\n",
       " ('inter', 0.12108759582042694),\n",
       " ('action', 0.12033271789550781),\n",
       " ('theonly', 0.11783447861671448),\n",
       " ('18', 0.11336708068847656),\n",
       " ('why', 0.11075355112552643),\n",
       " ('mis', 0.1046457514166832),\n",
       " ('received', 0.10427907109260559),\n",
       " ('form', 0.1010981947183609),\n",
       " ('each', 0.09531185030937195),\n",
       " ('needed', 0.0929718092083931),\n",
       " ('rate', 0.09036972373723984),\n",
       " ('il', 0.0871305838227272),\n",
       " ('six', 0.08301957696676254),\n",
       " ('tohave', 0.08219482004642487),\n",
       " ('em', 0.08179835975170135),\n",
       " ('self', 0.08048167079687119),\n",
       " ('especially', 0.07910634577274323),\n",
       " ('period', 0.07148750871419907),\n",
       " ('v', 0.0711049810051918),\n",
       " ('inwhich', 0.07060027122497559),\n",
       " ('practical', 0.06894053518772125),\n",
       " ('inthis', 0.06738501787185669),\n",
       " ('off', 0.06269422918558121),\n",
       " ('thenew', 0.06263003498315811),\n",
       " ('tri', 0.060062941163778305),\n",
       " ('hard', 0.04995616152882576),\n",
       " ('ine', 0.049044251441955566),\n",
       " ('inan', 0.042804233729839325),\n",
       " ('under', 0.0404968224465847),\n",
       " ('6', 0.039446908980607986),\n",
       " ('greater', 0.03864225745201111),\n",
       " ('can', 0.03837669640779495),\n",
       " ('musthave', 0.03534679114818573),\n",
       " ('ies', 0.03370607644319534),\n",
       " ('almost', 0.033156659454107285),\n",
       " ('too', 0.029380792751908302),\n",
       " ('anything', 0.02639746479690075),\n",
       " ('ar', 0.024072544649243355),\n",
       " ('goingto', 0.023535870015621185),\n",
       " ('days', 0.022640902549028397),\n",
       " ('isthe', 0.020724892616271973),\n",
       " ('long', 0.01831085979938507),\n",
       " ('done', 0.01816636510193348),\n",
       " ('oh', 0.01798047497868538),\n",
       " ('look', 0.017347706481814384),\n",
       " ('edfrom', 0.01696884259581566),\n",
       " ('mind', 0.015248613432049751),\n",
       " ('places', 0.014690625481307507),\n",
       " ('14', 0.011821302585303783),\n",
       " ('ch', 0.008118325844407082),\n",
       " ('17', 0.0054949307814240456),\n",
       " ('agood', 0.003582489676773548),\n",
       " ('ia', 0.003479716135188937),\n",
       " ('most', -0.0005464137066155672),\n",
       " ('aw', -0.0007410522666759789),\n",
       " ('ow', -0.004155520349740982),\n",
       " ('ac', -0.005794508848339319),\n",
       " ('ful', -0.006544366478919983),\n",
       " ('came', -0.006808462552726269),\n",
       " ('children', -0.00944836251437664),\n",
       " ('here', -0.011849481612443924),\n",
       " ('women', -0.01864147186279297),\n",
       " ('table', -0.018865127116441727),\n",
       " ('market', -0.019132569432258606),\n",
       " ('during', -0.022458307445049286),\n",
       " ('until', -0.026050718501210213),\n",
       " ('death', -0.032516080886125565),\n",
       " ('near', -0.032519128173589706),\n",
       " ('box', -0.03254524990916252),\n",
       " ('complete', -0.03260070085525513),\n",
       " ('thereis', -0.03341004252433777),\n",
       " ('ne', -0.035263482481241226),\n",
       " ('room', -0.03527288883924484),\n",
       " ('dress', -0.03857998549938202),\n",
       " ('go', -0.039729051291942596),\n",
       " ('park', -0.04082435742020607),\n",
       " ('theyare', -0.04465354606509209),\n",
       " ('forall', -0.048991478979587555),\n",
       " ('already', -0.053172849118709564),\n",
       " ('ingand', -0.05339059978723526),\n",
       " ('ard', -0.05704362690448761),\n",
       " ('government', -0.06095658987760544),\n",
       " ('explain', -0.06421288102865219),\n",
       " ('election', -0.0645822212100029),\n",
       " ('kind', -0.06656993180513382),\n",
       " ('k', -0.06803593039512634),\n",
       " ('asif', -0.06989096850156784),\n",
       " ('sc', -0.07163238525390625),\n",
       " ('supply', -0.07317252457141876),\n",
       " ('face', -0.07436618953943253),\n",
       " ('later', -0.07760656625032425),\n",
       " ('return', -0.07804770022630692),\n",
       " ('against', -0.0820111483335495),\n",
       " ('few', -0.08275661617517471),\n",
       " ('sto', -0.08402994275093079),\n",
       " ('put', -0.08532292395830154),\n",
       " ('aboutthe', -0.08555664122104645),\n",
       " ('abig', -0.08649985492229462),\n",
       " ('bythe', -0.08664749562740326),\n",
       " ('whether', -0.08847213536500931),\n",
       " ('business', -0.08964342623949051),\n",
       " ('head', -0.08990101516246796),\n",
       " ('board', -0.09074179083108902),\n",
       " ('ordinary', -0.0916951522231102),\n",
       " ('ian', -0.09341645985841751),\n",
       " ('ary', -0.09492511302232742),\n",
       " ('good', -0.09915448725223541),\n",
       " ('based', -0.09989906847476959),\n",
       " ('1', -0.10067909955978394),\n",
       " ('having', -0.10392603278160095),\n",
       " ('travel', -0.10589852929115295),\n",
       " ('great', -0.10946892201900482),\n",
       " ('ism', -0.10949824005365372),\n",
       " ('say', -0.11066291481256485),\n",
       " ('street', -0.11193201690912247),\n",
       " ('ihave', -0.11360453069210052),\n",
       " ('produced', -0.11710201948881149),\n",
       " ('betweenthem', -0.1237054169178009),\n",
       " ('water', -0.12719042599201202),\n",
       " ('thefirst', -0.1297847330570221),\n",
       " ('take', -0.13015508651733398),\n",
       " ('u', -0.13452817499637604),\n",
       " ('though', -0.13577252626419067),\n",
       " ('ton', -0.136084645986557),\n",
       " ('ley', -0.13623394072055817),\n",
       " ('in16', -0.13668754696846008),\n",
       " ('ted', -0.13873399794101715),\n",
       " ('states', -0.1391088366508484),\n",
       " ('cause', -0.13920952379703522),\n",
       " ('although', -0.14266078174114227),\n",
       " ('butthe', -0.14328104257583618),\n",
       " ('hehad', -0.14387938380241394),\n",
       " ('sin', -0.14489135146141052),\n",
       " ('shad', -0.14639170467853546),\n",
       " ('book', -0.14955325424671173),\n",
       " ('way', -0.15238207578659058),\n",
       " ('youknow', -0.15263746678829193),\n",
       " ('role', -0.15392769873142242),\n",
       " ('art', -0.15423814952373505),\n",
       " ('wehave', -0.1549861580133438),\n",
       " ('claim', -0.1550566852092743),\n",
       " ('add', -0.1554790586233139),\n",
       " ('hed', -0.15647362172603607),\n",
       " ('control', -0.16038621962070465),\n",
       " ('together', -0.16398176550865173),\n",
       " ('see', -0.16515734791755676),\n",
       " ('hesaid', -0.1658480316400528),\n",
       " ('did', -0.1693001091480255),\n",
       " ('bar', -0.17400680482387543),\n",
       " ('help', -0.1750299483537674),\n",
       " ('material', -0.17734184861183167),\n",
       " ('body', -0.17753106355667114),\n",
       " ('ity', -0.17812177538871765),\n",
       " ('ment', -0.17915722727775574),\n",
       " ('suicide', -0.17995575070381165),\n",
       " ('through', -0.1801149547100067),\n",
       " ('japanese', -0.18291112780570984),\n",
       " ('et', -0.18312206864356995),\n",
       " ('br', -0.18370437622070312),\n",
       " ('saw', -0.18563447892665863),\n",
       " ('father', -0.1859842985868454),\n",
       " ('improved', -0.18696466088294983),\n",
       " ('hours', -0.18872575461864471),\n",
       " ('ithink', -0.18883350491523743),\n",
       " ('aboutthis', -0.19066250324249268),\n",
       " ('better', -0.1914258897304535),\n",
       " ('another', -0.19173313677310944),\n",
       " ('aid', -0.19262221455574036),\n",
       " ('overthe', -0.19325639307498932),\n",
       " ('therewere', -0.19533897936344147),\n",
       " ('someofthe', -0.19588442146778107),\n",
       " ('external', -0.1968250423669815),\n",
       " ('10', -0.19702869653701782),\n",
       " ('pen', -0.19815731048583984),\n",
       " ('problem', -0.1986164003610611),\n",
       " ('esand', -0.19875137507915497),\n",
       " ('test', -0.1995670050382614),\n",
       " ('read', -0.19974756240844727),\n",
       " ('dr', -0.20017537474632263),\n",
       " ('different', -0.20030559599399567),\n",
       " ('[MASK]', -0.2009948045015335),\n",
       " ('again', -0.20650503039360046),\n",
       " ('od', -0.2140687108039856),\n",
       " ('gone', -0.21788939833641052),\n",
       " ('doesnt', -0.21976742148399353),\n",
       " ('thereare', -0.22112886607646942),\n",
       " ('might', -0.22235752642154694),\n",
       " ('give', -0.22653689980506897),\n",
       " ('thats', -0.22725988924503326),\n",
       " ('sthat', -0.22766795754432678),\n",
       " ('become', -0.22887350618839264),\n",
       " ('avery', -0.22971980273723602),\n",
       " ('shed', -0.22989338636398315),\n",
       " ('there', -0.23066648840904236),\n",
       " ('z', -0.23239994049072266),\n",
       " ('onyour', -0.23244769871234894),\n",
       " ('led', -0.23305152356624603),\n",
       " ('fellow', -0.23395150899887085),\n",
       " ('togive', -0.23504754900932312),\n",
       " ('ors', -0.23598051071166992),\n",
       " ('ling', -0.23701158165931702),\n",
       " ('god', -0.24016842246055603),\n",
       " ('others', -0.24250920116901398),\n",
       " ('didnot', -0.24657854437828064),\n",
       " ('ane', -0.24728840589523315),\n",
       " ('mayhave', -0.24768085777759552),\n",
       " ('pc', -0.24960196018218994),\n",
       " ('average', -0.2506217062473297),\n",
       " ('sat', -0.25131240487098694),\n",
       " ('big', -0.25273168087005615),\n",
       " ('ish', -0.2534611225128174),\n",
       " ('13', -0.2546491026878357),\n",
       " ('fast', -0.2564077079296112),\n",
       " ('large', -0.2576034367084503),\n",
       " ('carryout', -0.2603297829627991),\n",
       " ('j', -0.26104670763015747),\n",
       " ('girls', -0.26449739933013916),\n",
       " ('summer', -0.2647572457790375),\n",
       " ('forward', -0.2663966417312622),\n",
       " ('equal', -0.2698860466480255),\n",
       " ('iam', -0.27003350853919983),\n",
       " ('aswellas', -0.27367183566093445),\n",
       " ('ath', -0.274140864610672),\n",
       " ('withinthe', -0.2746383845806122),\n",
       " ('many', -0.27498456835746765),\n",
       " ('social', -0.27593550086021423),\n",
       " ('ide', -0.2767620086669922),\n",
       " ('events', -0.2801955044269562),\n",
       " ('thed', -0.28100496530532837),\n",
       " ('industrial', -0.28280770778656006),\n",
       " ('sp', -0.28508898615837097),\n",
       " ('obligation', -0.2858890891075134),\n",
       " ('movement', -0.2859298884868622),\n",
       " ('game', -0.28718358278274536),\n",
       " ('ale', -0.2872730791568756),\n",
       " ('ings', -0.2892701327800751),\n",
       " ('flow', -0.2904410660266876),\n",
       " ('inc', -0.2915925681591034),\n",
       " ('se', -0.29811549186706543),\n",
       " ('ell', -0.29837119579315186),\n",
       " ('level', -0.30007660388946533),\n",
       " ('team', -0.30022090673446655),\n",
       " ('speech', -0.3011927008628845),\n",
       " ('fully', -0.3035864233970642),\n",
       " ('young', -0.3038980960845947),\n",
       " ('things', -0.3066447079181671),\n",
       " ('beganto', -0.3106081485748291),\n",
       " ('programme', -0.31464895606040955),\n",
       " ('glass', -0.31465664505958557),\n",
       " ('year', -0.3148050904273987),\n",
       " ('progress', -0.3204191327095032),\n",
       " ('o', -0.323770672082901),\n",
       " ('little', -0.3272514045238495),\n",
       " ('those', -0.3273226022720337),\n",
       " ('workers', -0.32802048325538635),\n",
       " ('afterthe', -0.3285679221153259),\n",
       " ('seven', -0.3308907151222229),\n",
       " ('teachers', -0.33243975043296814),\n",
       " ('tie', -0.3337060809135437),\n",
       " ('miles', -0.33583134412765503),\n",
       " ('money', -0.3373003602027893),\n",
       " ('person', -0.33767035603523254),\n",
       " ('intheir', -0.3398037850856781),\n",
       " ('pocket', -0.34007999300956726),\n",
       " ('edbythe', -0.34081342816352844),\n",
       " ('find', -0.3409612774848938),\n",
       " ('been', -0.34278997778892517),\n",
       " ('surroundedby', -0.3428364396095276),\n",
       " ('high', -0.34304168820381165),\n",
       " ('case', -0.34653550386428833),\n",
       " ('shouldbe', -0.3474939465522766),\n",
       " ('fivehundred', -0.34789010882377625),\n",
       " ('wehad', -0.3492697477340698),\n",
       " ('food', -0.35097071528434753),\n",
       " ('group', -0.35200536251068115),\n",
       " ('stage', -0.3521574139595032),\n",
       " ('every', -0.3525467813014984),\n",
       " ('shop', -0.35334721207618713),\n",
       " ('friends', -0.35595813393592834),\n",
       " ('much', -0.35792022943496704),\n",
       " ('forces', -0.35872408747673035),\n",
       " ('ant', -0.35911425948143005),\n",
       " ('morethan', -0.36094534397125244),\n",
       " ('either', -0.36125582456588745),\n",
       " ('carbondioxide', -0.3624792695045471),\n",
       " ('road', -0.3629065752029419),\n",
       " ('oneofthe', -0.36331555247306824),\n",
       " ('hecould', -0.3639199137687683),\n",
       " ('ill', -0.3653671145439148),\n",
       " ('cell', -0.36620545387268066),\n",
       " ('service', -0.36831411719322205),\n",
       " ('acoupleof', -0.36927536129951477),\n",
       " ('necessary', -0.37047961354255676),\n",
       " ('ure', -0.3709331154823303),\n",
       " ('ators', -0.37313517928123474),\n",
       " ('op', -0.3735891878604889),\n",
       " ('please', -0.37610822916030884),\n",
       " ('leeds', -0.379102885723114),\n",
       " ('ak', -0.3831210136413574),\n",
       " ('away', -0.38482773303985596),\n",
       " ('simpl', -0.38490030169487),\n",
       " ('3', -0.3858981132507324),\n",
       " ('nothing', -0.3864746391773224),\n",
       " ('front', -0.3876223564147949),\n",
       " ('royal', -0.38894781470298767),\n",
       " ('onhis', -0.3891391456127167),\n",
       " ('drop', -0.3910103142261505),\n",
       " ('dropped', -0.39115166664123535),\n",
       " ('que', -0.392300009727478),\n",
       " ('beforethe', -0.3962348699569702),\n",
       " ('institutions', -0.39825326204299927),\n",
       " ('edand', -0.39850321412086487),\n",
       " ('main', -0.3986667990684509),\n",
       " ('early', -0.39866819977760315),\n",
       " ('whose', -0.39914560317993164),\n",
       " ('performance', -0.3999173939228058),\n",
       " ('ious', -0.4006510376930237),\n",
       " ('labour', -0.4025607109069824),\n",
       " ('in18', -0.4030989110469818),\n",
       " ('feel', -0.4040486514568329),\n",
       " ('mountain', -0.40421050786972046),\n",
       " ('afew', -0.4055699408054352),\n",
       " ('international', -0.40563464164733887),\n",
       " ('authority', -0.40647149085998535),\n",
       " ('far', -0.4066874086856842),\n",
       " ('air', -0.40733879804611206),\n",
       " ('whichis', -0.40787267684936523),\n",
       " ('percent', -0.40882015228271484),\n",
       " ('beautiful', -0.4096680283546448),\n",
       " ('w', -0.40973973274230957),\n",
       " ('ists', -0.41039249300956726),\n",
       " ('ifthey', -0.4131450355052948),\n",
       " ('oc', -0.4136107265949249),\n",
       " ('ts', -0.41475772857666016),\n",
       " ('local', -0.41526365280151367),\n",
       " ('sexual', -0.417013019323349),\n",
       " ('sleep', -0.4175291359424591),\n",
       " ('edhis', -0.41778862476348877),\n",
       " ('pay', -0.41962841153144836),\n",
       " ('writing', -0.4211330711841583),\n",
       " ('ally', -0.42170876264572144),\n",
       " ('82', -0.4227207601070404),\n",
       " ('really', -0.4233510196208954),\n",
       " ('outofthe', -0.4256226420402527),\n",
       " ('crack', -0.42727547883987427),\n",
       " ('played', -0.42762768268585205),\n",
       " ('often', -0.42793402075767517),\n",
       " ('ain', -0.42849746346473694),\n",
       " ('forevery', -0.4311619997024536),\n",
       " ('ade', -0.4330318868160248),\n",
       " ('among', -0.43466344475746155),\n",
       " ('act', -0.43496283888816833),\n",
       " ('ie', -0.4357943832874298),\n",
       " ('ther', -0.43673837184906006),\n",
       " ('fine', -0.4380660355091095),\n",
       " ('employed', -0.43861687183380127),\n",
       " ('te', -0.43959811329841614),\n",
       " ('parties', -0.44079554080963135),\n",
       " ('staff', -0.44194290041923523),\n",
       " ('quarter', -0.44251224398612976),\n",
       " ('brought', -0.44507676362991333),\n",
       " ('relief', -0.44515544176101685),\n",
       " ('itwould', -0.44541022181510925),\n",
       " ('sortof', -0.4459395110607147),\n",
       " ('ave', -0.44613730907440186),\n",
       " ('european', -0.44632580876350403),\n",
       " ('towards', -0.44662564992904663),\n",
       " ('green', -0.44888147711753845),\n",
       " ('maybe', -0.4489537477493286),\n",
       " ('display', -0.4495134651660919),\n",
       " ('specific', -0.4496164321899414),\n",
       " ('fundholding', -0.44968459010124207),\n",
       " ('growth', -0.4552406370639801),\n",
       " ('parent', -0.4559221565723419),\n",
       " ('edwith', -0.4571840465068817),\n",
       " ('ington', -0.45918992161750793),\n",
       " ('world', -0.463271826505661),\n",
       " ('including', -0.46485385298728943),\n",
       " ('given', -0.465339332818985),\n",
       " ('8', -0.4655725359916687),\n",
       " ('hewent', -0.4660755693912506),\n",
       " ('bring', -0.4664192199707031),\n",
       " ('despite', -0.4667469561100006),\n",
       " ('real', -0.46736466884613037),\n",
       " ('woman', -0.4675333797931671),\n",
       " ('past', -0.4687409996986389),\n",
       " ('finished', -0.4692052900791168),\n",
       " ('call', -0.4702391028404236),\n",
       " ('area', -0.4708611071109772),\n",
       " ('hear', -0.4710911214351654),\n",
       " ('popular', -0.4718666970729828),\n",
       " ('energy', -0.4727102220058441),\n",
       " ('novel', -0.4729240834712982),\n",
       " ('path', -0.47312426567077637),\n",
       " ('want', -0.47379642724990845),\n",
       " ('fuel', -0.47491952776908875),\n",
       " ('provided', -0.4779486060142517),\n",
       " ('trees', -0.47826993465423584),\n",
       " ('research', -0.47903186082839966),\n",
       " ('right', -0.4794194996356964),\n",
       " ('prefer', -0.4800282120704651),\n",
       " ('treatment', -0.4805621802806854),\n",
       " ('red', -0.48111313581466675),\n",
       " ('note', -0.4826810657978058),\n",
       " ('family', -0.4828808307647705),\n",
       " ('16', -0.48349085450172424),\n",
       " ('weight', -0.48443424701690674),\n",
       " ('change', -0.48574328422546387),\n",
       " ('backto', -0.4866853356361389),\n",
       " ('himself', -0.4868503212928772),\n",
       " ('sh', -0.4868595600128174),\n",
       " ('tore', -0.487242728471756),\n",
       " ('adeep', -0.4878348708152771),\n",
       " ('ise', -0.4886249601840973),\n",
       " ('tr', -0.4897109568119049),\n",
       " ('various', -0.49139168858528137),\n",
       " ('support', -0.4957512617111206),\n",
       " ('learn', -0.49661004543304443),\n",
       " ('pass', -0.4980625808238983),\n",
       " ('home', -0.49825671315193176),\n",
       " ('allthe', -0.498295396566391),\n",
       " ('ineurope', -0.49922123551368713),\n",
       " ('whatthey', -0.4993096590042114),\n",
       " ('mr', -0.5011245608329773),\n",
       " ('quite', -0.501584529876709),\n",
       " ('going', -0.5027087330818176),\n",
       " ('available', -0.505632221698761),\n",
       " ('provide', -0.5056414008140564),\n",
       " ('th', -0.5057026743888855),\n",
       " ('institute', -0.506923496723175),\n",
       " ('adam', -0.5074934959411621),\n",
       " ('paid', -0.5077196955680847),\n",
       " ('whohad', -0.5084263682365417),\n",
       " ('record', -0.5086932182312012),\n",
       " ('ten', -0.5092469453811646),\n",
       " ('old', -0.5092679858207703),\n",
       " ('blame', -0.5123839974403381),\n",
       " ('thiswas', -0.5126895904541016),\n",
       " ('sfrom', -0.5155065059661865),\n",
       " ('wouldbe', -0.5158933997154236),\n",
       " ('rain', -0.5161221027374268),\n",
       " ('swhich', -0.5169687867164612),\n",
       " ('shave', -0.5182333588600159),\n",
       " ('line', -0.5186342000961304),\n",
       " ('ics', -0.520219087600708),\n",
       " ('provides', -0.5225816369056702),\n",
       " ('accept', -0.5237653255462646),\n",
       " ('ash', -0.5240020155906677),\n",
       " ('roll', -0.5242728590965271),\n",
       " ('job', -0.5252994894981384),\n",
       " ('appropriate', -0.5255110263824463),\n",
       " ('space', -0.5259417295455933),\n",
       " ('iously', -0.5261807441711426),\n",
       " ('committee', -0.5264618396759033),\n",
       " ('cross', -0.526733934879303),\n",
       " ('thefollowing', -0.5268155336380005),\n",
       " ('ul', -0.5272256135940552),\n",
       " ('edon', -0.5272941589355469),\n",
       " ('october', -0.5278396010398865),\n",
       " ('arrested', -0.5303364396095276),\n",
       " ('thatit', -0.530953586101532),\n",
       " ('league', -0.531104564666748),\n",
       " ('award', -0.5318183302879333),\n",
       " ('above', -0.5324975252151489),\n",
       " ('get', -0.532768189907074),\n",
       " ('activities', -0.5344581007957458),\n",
       " ('units', -0.535344123840332),\n",
       " ('forthis', -0.535811185836792),\n",
       " ('history', -0.5361306667327881),\n",
       " ('sir', -0.5367053151130676),\n",
       " ('show', -0.5370549559593201),\n",
       " ('abilityto', -0.5372005701065063),\n",
       " ('lines', -0.5375416874885559),\n",
       " ('probably', -0.538922131061554),\n",
       " ('increased', -0.5390361547470093),\n",
       " ('sn', -0.5391384363174438),\n",
       " ('thecurrent', -0.5392756462097168),\n",
       " ('issues', -0.5397469401359558),\n",
       " ('ion', -0.5399059653282166),\n",
       " ('major', -0.5406892895698547),\n",
       " ('second', -0.540734589099884),\n",
       " ('thenext', -0.5414555668830872),\n",
       " ('questions', -0.5416545271873474),\n",
       " ('check', -0.5425474047660828),\n",
       " ('turn', -0.5435354113578796),\n",
       " ('tend', -0.5456249713897705),\n",
       " ('themselves', -0.5466114282608032),\n",
       " ('reliev', -0.5474357604980469),\n",
       " ('event', -0.5507706999778748),\n",
       " ('practice', -0.5517357587814331),\n",
       " ('astart', -0.5529347658157349),\n",
       " ('os', -0.5546663403511047),\n",
       " ('considered', -0.5548251271247864),\n",
       " ('text', -0.5550326704978943),\n",
       " ('betweenthe', -0.5551097989082336),\n",
       " ('actually', -0.5555052757263184),\n",
       " ('edhim', -0.5573545098304749),\n",
       " ('leg', -0.5576817989349365),\n",
       " ('thepolice', -0.5579200983047485),\n",
       " ('cameto', -0.5582841634750366),\n",
       " ('office', -0.5583949089050293),\n",
       " ('materials', -0.5585792064666748),\n",
       " ('ep', -0.5597580075263977),\n",
       " ('edintothe', -0.5599567890167236),\n",
       " ('youwill', -0.5606018304824829),\n",
       " ('um', -0.5619493126869202),\n",
       " ('advice', -0.5623397827148438),\n",
       " ('edout', -0.5628143548965454),\n",
       " ('wall', -0.5652804970741272),\n",
       " ('thep', -0.5654217600822449),\n",
       " ('does', -0.5663416385650635),\n",
       " ('ingof', -0.566668689250946),\n",
       " ('heads', -0.5673717260360718),\n",
       " ('stay', -0.5675473809242249),\n",
       " ('times', -0.5676100254058838),\n",
       " ('needto', -0.5685431957244873),\n",
       " ('adrink', -0.5701019167900085),\n",
       " ('once', -0.570565402507782),\n",
       " ('design', -0.5708255767822266),\n",
       " ('sas', -0.5719491839408875),\n",
       " ('opportunities', -0.5732101202011108),\n",
       " ('cur', -0.5739941596984863),\n",
       " ('0000', -0.574307918548584),\n",
       " ('sign', -0.5745708346366882),\n",
       " ('determin', -0.5747398734092712),\n",
       " ('hetook', -0.5750308036804199),\n",
       " ('plot', -0.5763307809829712),\n",
       " ('age', -0.5771809816360474),\n",
       " ('isthat', -0.5787316560745239),\n",
       " ('studies', -0.5788943767547607),\n",
       " ('reduced', -0.5811896324157715),\n",
       " ('theydo', -0.5813817381858826),\n",
       " ('dick', -0.5820704102516174),\n",
       " ('free', -0.5820710062980652),\n",
       " ('day', -0.5820942521095276),\n",
       " ('particular', -0.5825560688972473),\n",
       " ('atic', -0.5830469131469727),\n",
       " ('don', -0.5831916332244873),\n",
       " ('results', -0.5834973454475403),\n",
       " ('question', -0.5847097635269165),\n",
       " ('paper', -0.5851231217384338),\n",
       " ('physical', -0.5859015583992004),\n",
       " ('requires', -0.5863481163978577),\n",
       " ('organization', -0.5865890383720398),\n",
       " ('setup', -0.5869095325469971),\n",
       " ('om', -0.587518572807312),\n",
       " ('themessage', -0.5880071520805359),\n",
       " ('ump', -0.5894894003868103),\n",
       " ('ach', -0.5898185968399048),\n",
       " ('plan', -0.5900039076805115),\n",
       " ('shehas', -0.5903793573379517),\n",
       " ('deep', -0.5912050604820251),\n",
       " ('asmall', -0.5917542576789856),\n",
       " ('ex', -0.5930752754211426),\n",
       " ('tokeep', -0.5942094922065735),\n",
       " ('ind', -0.5944286584854126),\n",
       " ('band', -0.594956636428833),\n",
       " ('next', -0.5960659980773926),\n",
       " ('gr', -0.596829891204834),\n",
       " ('eof', -0.5984927415847778),\n",
       " ('ot', -0.5990695357322693),\n",
       " ('share', -0.6007819175720215),\n",
       " ('five', -0.6007829904556274),\n",
       " ('ground', -0.6007928848266602),\n",
       " ('soon', -0.6009891033172607),\n",
       " ('making', -0.6009892225265503),\n",
       " ('im', -0.6027216911315918),\n",
       " ('language', -0.6029436588287354),\n",
       " ('persons', -0.6034972071647644),\n",
       " ('order', -0.6043458580970764),\n",
       " ('national', -0.6060230135917664),\n",
       " ('enough', -0.6065574884414673),\n",
       " ('hang', -0.6081544756889343),\n",
       " ('view', -0.6093325614929199),\n",
       " ('reading', -0.609999418258667),\n",
       " ('knowthat', -0.6108770370483398),\n",
       " ('madeby', -0.6119503378868103),\n",
       " ('rescue', -0.6125767827033997),\n",
       " ('outside', -0.6129373908042908),\n",
       " ('point', -0.6152851581573486),\n",
       " ('anumberof', -0.6162323355674744),\n",
       " ('aday', -0.616515576839447),\n",
       " ('match', -0.616599977016449),\n",
       " ('somuch', -0.6181155443191528),\n",
       " ('held', -0.6182234883308411),\n",
       " ('ood', -0.6183822751045227),\n",
       " ('thec', -0.6194552183151245),\n",
       " ('content', -0.6194965243339539),\n",
       " ('ative', -0.6204888224601746),\n",
       " ('norwich', -0.6210750341415405),\n",
       " ('iwould', -0.62230384349823),\n",
       " ('nearly', -0.6223687529563904),\n",
       " ('suit', -0.6225243806838989),\n",
       " ('ontheotherhand', -0.6226568818092346),\n",
       " ('built', -0.6233258247375488),\n",
       " ('books', -0.6235170364379883),\n",
       " ('sense', -0.6235172748565674),\n",
       " ('visited', -0.6242002248764038),\n",
       " ('bill', -0.6249200105667114),\n",
       " ('stock', -0.6260719299316406),\n",
       " ('finding', -0.6268114447593689),\n",
       " ('kindof', -0.6278116703033447),\n",
       " ('togo', -0.6289458870887756),\n",
       " ('hair', -0.6292522549629211),\n",
       " ('hill', -0.6315572261810303),\n",
       " ('quality', -0.6332426071166992),\n",
       " ('length', -0.6336596608161926),\n",
       " ('value', -0.6336844563484192),\n",
       " ('bad', -0.6346042156219482),\n",
       " ('tell', -0.6353128552436829),\n",
       " ('stop', -0.6376593708992004),\n",
       " ('fresh', -0.6378742456436157),\n",
       " ('infection', -0.6380271911621094),\n",
       " ('yer', -0.6402710676193237),\n",
       " ('evidence', -0.6415588855743408),\n",
       " ('planning', -0.6423828601837158),\n",
       " ('likethe', -0.6428746581077576),\n",
       " ('burst', -0.6431270837783813),\n",
       " ('15', -0.6454720497131348),\n",
       " ('5', -0.6460118889808655),\n",
       " ('mer', -0.6465375423431396),\n",
       " ('associatedwith', -0.6468596458435059),\n",
       " ('performed', -0.6471471190452576),\n",
       " ('aman', -0.6477651596069336),\n",
       " ('ithought', -0.6479215025901794),\n",
       " ('wewant', -0.6480737924575806),\n",
       " ('programmes', -0.6489703059196472),\n",
       " ('edup', -0.6492001414299011),\n",
       " ('nor', -0.6498437523841858),\n",
       " ('whatwas', -0.650009274482727),\n",
       " ('play', -0.6502708792686462),\n",
       " ('youcan', -0.6505720019340515),\n",
       " ('ink', -0.6511900424957275),\n",
       " ('address', -0.6536542773246765),\n",
       " ('intothe', -0.654142439365387),\n",
       " ('isnot', -0.6542094945907593),\n",
       " ('napoleon', -0.6543470621109009),\n",
       " ('wood', -0.6545112133026123),\n",
       " ('ness', -0.6554630398750305),\n",
       " ('ro', -0.6556061506271362),\n",
       " ('movedto', -0.6560573577880859),\n",
       " ('white', -0.6562991738319397),\n",
       " ('inher', -0.6566209197044373),\n",
       " ('sfor', -0.6570374965667725),\n",
       " ('small', -0.6571634411811829),\n",
       " ('edfor', -0.6596519351005554),\n",
       " ('ifthe', -0.6598308682441711),\n",
       " ('tests', -0.6611403226852417),\n",
       " ('hell', -0.6614660024642944),\n",
       " ('production', -0.6615114212036133),\n",
       " ('hes', -0.6637791395187378),\n",
       " ('iwas', -0.6640408039093018),\n",
       " ('stress', -0.6642725467681885),\n",
       " ('ull', -0.6671686768531799),\n",
       " ('fourth', -0.6674131751060486),\n",
       " ('present', -0.6674900054931641),\n",
       " ('political', -0.6679798364639282),\n",
       " ('shedoes', -0.6680782437324524),\n",
       " ('12', -0.6686326265335083),\n",
       " ('half', -0.6689120531082153),\n",
       " ('ser', -0.6689513325691223),\n",
       " ('hold', -0.6697281002998352),\n",
       " ('british', -0.6698941588401794),\n",
       " ('whenthe', -0.6704414486885071),\n",
       " ('scatter', -0.6708006858825684),\n",
       " ('forty', -0.6711111664772034),\n",
       " ('ofthis', -0.672667384147644),\n",
       " ('scarcely', -0.6729697585105896),\n",
       " ('recent', -0.672970175743103),\n",
       " ('certain', -0.6736223697662354),\n",
       " ('ingin', -0.6736544966697693),\n",
       " ('conditions', -0.6746249198913574),\n",
       " ('killing', -0.6747350692749023),\n",
       " ('think', -0.675493061542511),\n",
       " ('plants', -0.6761752963066101),\n",
       " ('mail', -0.6775902509689331),\n",
       " ('review', -0.6800666451454163),\n",
       " ('andother', -0.6800958514213562),\n",
       " ('cos', -0.6803516149520874),\n",
       " ('mustbe', -0.6806856393814087),\n",
       " ('representing', -0.6807541847229004),\n",
       " ('experiment', -0.6827435493469238),\n",
       " ('taste', -0.6828309297561646),\n",
       " ('special', -0.6832959055900574),\n",
       " ('psycho', -0.6841982007026672),\n",
       " ('shopping', -0.6853241920471191),\n",
       " ('di', -0.6855087876319885),\n",
       " ('budget', -0.6859028339385986),\n",
       " ('gives', -0.6859927773475647),\n",
       " ('sex', -0.6863443851470947),\n",
       " ('odd', -0.6881247758865356),\n",
       " ('hammer', -0.6893243789672852),\n",
       " ('co', -0.6898437142372131),\n",
       " ('computer', -0.6899760365486145),\n",
       " ('del', -0.6914688348770142),\n",
       " ('slightly', -0.6922629475593567),\n",
       " ('army', -0.692501425743103),\n",
       " ('breast', -0.6925859451293945),\n",
       " ('impossible', -0.6926254630088806),\n",
       " ('direction', -0.6935431957244873),\n",
       " ('along', -0.6941924095153809),\n",
       " ('statement', -0.6942911148071289),\n",
       " ('avisitto', -0.6943404674530029),\n",
       " ('ofher', -0.6947473883628845),\n",
       " ('suchas', -0.6958009004592896),\n",
       " ('close', -0.6964048743247986),\n",
       " ('lovely', -0.6964601874351501),\n",
       " ('atedby', -0.6971153020858765),\n",
       " ('temper', -0.6978214383125305),\n",
       " ('resources', -0.6980527639389038),\n",
       " ('conducted', -0.6988998651504517),\n",
       " ('asthe', -0.6989914178848267),\n",
       " ('stopped', -0.7001339793205261),\n",
       " ('elizabeth', -0.7001935839653015),\n",
       " ('lost', -0.7002925276756287),\n",
       " ('scheme', -0.700958251953125),\n",
       " ('twenty', -0.7009934782981873),\n",
       " ('thus', -0.7011886835098267),\n",
       " ('economic', -0.7013407945632935),\n",
       " ('couldbe', -0.7017313838005066),\n",
       " ('batt', -0.702165424823761),\n",
       " ('advent', -0.7025260329246521),\n",
       " ('opportunity', -0.7032829523086548),\n",
       " ('ox', -0.7047554850578308),\n",
       " ('sinthe', -0.704801619052887),\n",
       " ('serve', -0.7056300640106201),\n",
       " ('alittle', -0.7061205506324768),\n",
       " ('relationships', -0.7062575221061707),\n",
       " ('ren', -0.7075297832489014),\n",
       " ('heavy', -0.7076262831687927),\n",
       " ('roof', -0.7076439261436462),\n",
       " ('busy', -0.7081215381622314),\n",
       " ('ableto', -0.7083141803741455),\n",
       " ('starts', -0.708376407623291),\n",
       " ('press', -0.7085212469100952),\n",
       " ('ater', -0.7085694670677185),\n",
       " ('pool', -0.7086005210876465),\n",
       " ('traditionally', -0.7089027762413025),\n",
       " ('hisface', -0.7089134454727173),\n",
       " ('localauthorities', -0.7089365124702454),\n",
       " ('size', -0.709024965763092),\n",
       " ('war', -0.7097005844116211),\n",
       " ('survive', -0.7104529738426208),\n",
       " ('mrs', -0.7118405103683472),\n",
       " ('yand', -0.7121061682701111),\n",
       " ('den', -0.7126155495643616),\n",
       " ('andthen', -0.7130674123764038),\n",
       " ('walking', -0.7141583561897278),\n",
       " ('always', -0.7146658301353455),\n",
       " ('unit', -0.7167784571647644),\n",
       " ('since', -0.7181352972984314),\n",
       " ('thin', -0.718809187412262),\n",
       " ('26', -0.7189613580703735),\n",
       " ('ick', -0.7190006375312805),\n",
       " ('awkward', -0.7191647887229919),\n",
       " ('shetook', -0.7195308208465576),\n",
       " ('motor', -0.7206445932388306),\n",
       " ('ingto', -0.7209306955337524),\n",
       " ('ward', -0.7214173078536987),\n",
       " ('skin', -0.7216365337371826),\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parad[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
