{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import semiolog as slg"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "semiotic_corpus = slg.Corpus('wikipedia', '20200501.fr',length=10)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Reusing dataset wikipedia (/Users/Gianni/.cache/huggingface/datasets/wikipedia/20200501.fr/1.0.0/2fe8db1405aef67dff9fcc51e133e1f9c5b0106f9d9e9638188176d278fd5ff1)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "semiotic_corpus.training\n",
                "slg.util_g.str2txt(\"/n\".join(semiotic_corpus.training),\"train_test\",\"examples\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "\"blaqsdqsd\".startswith((\"bla\",\"bla\"))"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "source": [
                "from collections import Counter\n",
                "from semiolog import util_g\n",
                "import functools\n",
                "import time\n",
                "import operator"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "semiotic = slg.load(\"fr_wiki\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "from datasets import load_dataset\n",
                "dataset = load_dataset('glue', 'mrpc')\n",
                "dataset_wiki = load_dataset('wikipedia', '20200501.fr',split=None)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Reusing dataset glue (/Users/Gianni/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
                        "Reusing dataset wikipedia (/Users/Gianni/.cache/huggingface/datasets/wikipedia/20200501.fr/1.0.0/2fe8db1405aef67dff9fcc51e133e1f9c5b0106f9d9e9638188176d278fd5ff1)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "from semiolog.syntagmatic import tokenizer"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "input = dataset_wiki[\"train\"][:5][\"text\"]\n",
                "input = \" \".join(input)\n",
                "\n",
                "bla = tokenizer.pre_tokenizers.Layout.pre_tokenize(None,input)\n",
                "\n",
                "bla2 = tokenizer.processors.SentencesNLTK.process(\"\",bla,is_pretokenized=True)\n",
                "\n",
                "bla3 = tokenizer.post_processors.WikiFR.post_process(\"\",bla2)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "bla3"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{\", Prix Hercule-Catenacci de l'Académie française.\",\n",
                            " '1973',\n",
                            " \"20px Championne d'URSS de poursuite par équipes : 1968, 1969, 1972, 1973, 1974, 1976 et 1977\",\n",
                            " \"20px Championne d'URSS du 500 mètres : 1968, 1969, 1973, 1974 et 1975\",\n",
                            " \"20px Championne d'URSS sur route\",\n",
                            " 'Agrégé de grammaire, il devient enseignant en Corse puis travaille comme assistant de Charles Picard à la Sorbonne.',\n",
                            " \"Alberti, né à Hattingen, est issu d'une famille de facteurs d'orgue.\",\n",
                            " \"Alors que son père est organiste à l'église Sankt-Reinold à Dortmund, il ouvre son atelier dans la ville, atelier que reprendra le fils à la mort de son père.\",\n",
                            " 'André Leroi-Gourhan et la technique des fouilles, in Bulletin de la Société préhistorique française, , 1984, p.\\xa0328-334',\n",
                            " \"Après avoir quitté en 1960 l’École française d'Athènes, il devient directeur d'étude et enseigne à la  section de l’École pratique des hautes études.\",\n",
                            " 'Avec Groslier, il crée aussi au sein du CNRS un Centre de recherches archéologiques.',\n",
                            " 'Bibliographie',\n",
                            " 'Biographie',\n",
                            " 'Bulletin de correspondance hellénique, supplément , 1973, p.\\xa0157-172',\n",
                            " \"Championnats d'URSS\",\n",
                            " 'Championnats du monde',\n",
                            " 'Championne du monde de vitesse',\n",
                            " 'De 1971 à 1984, il dirige les fouilles de  en Syrie.',\n",
                            " 'Dortmund 2010',\n",
                            " 'Dreihundert Jahre Alberti-Orgel in der Alten Kirche Wellinghofen.',\n",
                            " 'Déjà son grand-père Peter Alberti († 1670), organiste à Hattingen, et son père Albertus Alberti (1614-1670) ont construit des orgues.',\n",
                            " 'E Will, Nécrologie: Paul Courbin (1922-1994), in Syria , 1997, p.\\xa0221 (Lire en ligne)',\n",
                            " \"En 1949, il entre à l'École française d'Athènes avec Jean Deshayes et s'y voit confier la publication de l'Oikos des Naxiens de Délos.\",\n",
                            " \"En 1967, il fonde le Bureau d'études des méthodes archéologiques et crée les chantiers d'écoles de Fontainebleau (1962-1963), Chartres (1967-1972) et Saint-Marcel-d'Ardèche (1973-1987), qu'il anime.\",\n",
                            " 'En 1974, elle remporte le championnat du monde de vitesse à Montréal.',\n",
                            " 'Hommage',\n",
                            " \"Il est chef des travaux pratiques de géologie et chargé de conférences à l'Université de Paris.\",\n",
                            " \"Il fait ses études à Lyon puis devient élève de l'École normale supérieure (1943).\",\n",
                            " \"Il fouille à Gortys et, lors de la reprise des fouilles d'Argos, en 1952, consacre sa thèse à la céramique géométrique de l'Argolide.\",\n",
                            " 'Ingomar Kury: 1710 - 2010.',\n",
                            " \"Johann Georg Alberti construit différents orgues en Westphalie, entre autres à Witten (1696) et à Dortmund (Wellinghofen) où l'on conserve encore le contrat de 1709 qui prévoit la reconstruction (réussie) de l'orgue de Witten pour 320 thalers.\",\n",
                            " \"L'ammonite Fagesia pervinquieri lui est dédiée.\",\n",
                            " \"La Céramique géométrique de l'Argolide, 1966\",\n",
                            " 'Le colosse naxien et le palmier de Nicias, in Études déliennes.',\n",
                            " 'Liens externes',\n",
                            " 'Montréal 1974',\n",
                            " \"Nommé secrétaire général de l’École en 1954, il décide d'appliquer avec Bernard Philippe Groslier à Argos, les méthodes de fouille de Mortimer Wheeler (1955).\",\n",
                            " 'Notes et références',\n",
                            " 'P. Darcque, Paul Courbin et la méthode Wheeler, Bulletin de correspondance hellénique , 1996, p.\\xa0315-323',\n",
                            " 'PRB 1 ;',\n",
                            " 'PRB 2 ;',\n",
                            " 'PRB 3 ;',\n",
                            " 'PRB 4 ;',\n",
                            " 'PRB 5.',\n",
                            " 'PRB, une série de cinq voiliers monocoques  IMOCA sponsorisés par la société PRB (Produits de revêtements du bâtiment) :',\n",
                            " 'Palmarès sur piste',\n",
                            " 'Palmarès sur route',\n",
                            " 'Parti régionaliste breton ;',\n",
                            " 'Parti républicain brésilien ;',\n",
                            " 'Paul Courbin (Lyon, -Paris, ) est un archéologue français.',\n",
                            " 'Publications',\n",
                            " 'Réalisations (sélection)',\n",
                            " 'Ses publications abordent également la géographie.',\n",
                            " 'Source',\n",
                            " 'Source de la traduction',\n",
                            " 'Tamara Piltsikova (née en 1946 à Toula) est une coureuse cycliste soviétique, spécialiste de la piste.',\n",
                            " \"Tombes géométriques d'Argos, 1974\",\n",
                            " 'Travaux',\n",
                            " \"Une rue d'Anglet porte son nom.\",\n",
                            " 'en voile',\n",
                            " 'point de rassemblement des blessés en médecine militaire ;',\n",
                            " 'protéine du rétinoblastome en biochimie ;',\n",
                            " \"un code qui signifie «  Désirez-vous communiquer avec ma station à l'aide du Code international de signaux?\",\n",
                            " '» (« PRB?',\n",
                            " '» (« PRB») selon le code Q.',\n",
                            " \"») ou «  Je désire communiquer avec votre station à l'aide du Code international de signaux.\",\n",
                            " 'Ève Gran-Aymerich, Les chercheurs de passé, Éditions du CNRS, 2007, p.\\xa0726-727',\n",
                            " 'Études archéologiques, 1963'}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 15
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "import sklearn\n",
                "\n",
                "training_dataset, test_dataset = sklearn.model_selection.train_test_split(list(bla3), train_size=.9, test_size=.1)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "source": [
                "len(training_dataset)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "61"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 30
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "source": [
                "for i in norm_input:\n",
                "    for j in sent_tokenize(i):\n",
                "        print(j+\"#####\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Johann Georg Alberti (né en 1644; mort en 1722) est un organiste et facteur d'orgue allemand originaire de Dortmund.#####\n",
                        "Biographie#####\n",
                        "Alberti, né à Hattingen, est issu d'une famille de facteurs d'orgue.#####\n",
                        "Déjà son grand-père Peter Alberti († 1670), organiste à Hattingen, et son père Albertus Alberti (1614-1670) ont construit des orgues.#####\n",
                        "Alors que son père est organiste à l'église Sankt-Reinold à Dortmund, il ouvre son atelier dans la ville, atelier que reprendra le fils à la mort de son père.#####\n",
                        "Johann Georg Alberti construit différents orgues en Westphalie, entre autres à Witten (1696) et à Dortmund (Wellinghofen) où l'on conserve encore le contrat de 1709 qui prévoit la reconstruction (réussie) de l'orgue de Witten pour 320 thalers.#####\n",
                        "Réalisations (sélection)#####\n",
                        "Source#####\n",
                        "Ingomar Kury: 1710 - 2010.#####\n",
                        "Dreihundert Jahre Alberti-Orgel in der Alten Kirche Wellinghofen.#####\n",
                        "Dortmund 2010#####\n",
                        "Source de la traduction#####\n",
                        "Catégorie:Facteur d'orgue allemand#####\n",
                        "Catégorie:Organiste classique allemand#####\n",
                        "Catégorie:Naissance en 1644#####\n",
                        "Catégorie:Décès en 1722#####\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "input[1]"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\"Johann Georg Alberti (né en 1644; mort en 1722) est un organiste et facteur d'orgue allemand originaire de Dortmund.\\n\\nBiographie \\nAlberti, né à Hattingen, est issu d'une famille de facteurs d'orgue. Déjà son grand-père Peter Alberti († 1670), organiste à Hattingen, et son père Albertus Alberti (1614-1670) ont construit des orgues. Alors que son père est organiste à l'église Sankt-Reinold à Dortmund, il ouvre son atelier dans la ville, atelier que reprendra le fils à la mort de son père.\\n\\nJohann Georg Alberti construit différents orgues en Westphalie, entre autres à Witten (1696) et à Dortmund (Wellinghofen) où l'on conserve encore le contrat de 1709 qui prévoit la reconstruction (réussie) de l'orgue de Witten pour 320 thalers.\\n\\nRéalisations (sélection)\\n\\nSource \\n Ingomar Kury: 1710 - 2010. Dreihundert Jahre Alberti-Orgel in der Alten Kirche Wellinghofen. Dortmund 2010\\n\\nSource de la traduction \\n\\nCatégorie:Facteur d'orgue allemand\\nCatégorie:Organiste classique allemand\\nCatégorie:Naissance en 1644\\nCatégorie:Décès en 1722\""
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "source": [
                "bla = semiotic.syntagmatic.tokenizer.normalizer.normalize(\"\".join(input[:1000]))\n",
                "# bla[10000000:10001000]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "source": [
                "slg.util_g.str2txt(bla,\"fr_test\",\"examples/\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "source": [
                "from pathlib import Path\n",
                "\n",
                "from tokenizers import ByteLevelBPETokenizer\n",
                "\n",
                "# Initialize a tokenizer\n",
                "tokenizer = ByteLevelBPETokenizer()\n",
                "\n",
                "# Customize training\n",
                "tokenizer.train(files=\"examples/fr_test.txt\", vocab_size=461, min_frequency=2, special_tokens=[\n",
                "    \"<s>\",\n",
                "    \"<pad>\",\n",
                "    \"</s>\",\n",
                "    \"<unk>\",\n",
                "    \"<mask>\",\n",
                "])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "source": [
                "bla_voc = tokenizer.get_vocab()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "source": [
                "sorted([(i,k) for k,i in bla_voc.items()])[261:]"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[(261, 'Ìģ'),\n",
                            " (262, 'es'),\n",
                            " (263, 'de'),\n",
                            " (264, 'en'),\n",
                            " (265, 'on'),\n",
                            " (266, 're'),\n",
                            " (267, 'le'),\n",
                            " (268, 'te'),\n",
                            " (269, 'an'),\n",
                            " (270, 'la'),\n",
                            " (271, 'ti'),\n",
                            " (272, 'ri'),\n",
                            " (273, 'ou'),\n",
                            " (274, 'is'),\n",
                            " (275, 'ÌĢ'),\n",
                            " (276, 'in'),\n",
                            " (277, 'ar'),\n",
                            " (278, 'er'),\n",
                            " (279, 'qu'),\n",
                            " (280, 'et'),\n",
                            " (281, 'ne'),\n",
                            " (282, 'ta'),\n",
                            " (283, 'les'),\n",
                            " (284, 'ra'),\n",
                            " (285, 'li'),\n",
                            " (286, 'ch'),\n",
                            " (287, 'des'),\n",
                            " (288, 'se'),\n",
                            " (289, 'du'),\n",
                            " (290, 'or'),\n",
                            " (291, 'au'),\n",
                            " (292, 'ur'),\n",
                            " (293, 'ce'),\n",
                            " (294, 'ent'),\n",
                            " (295, 'me'),\n",
                            " (296, 'ca'),\n",
                            " (297, 'il'),\n",
                            " (298, 'om'),\n",
                            " (299, 'tion'),\n",
                            " (300, 'si'),\n",
                            " (301, 'ro'),\n",
                            " (302, 'que'),\n",
                            " (303, 'un'),\n",
                            " (304, 'ie'),\n",
                            " (305, 'ma'),\n",
                            " (306, 'par'),\n",
                            " (307, 'pe'),\n",
                            " (308, 'dela'),\n",
                            " (309, 'al'),\n",
                            " (310, 've'),\n",
                            " (311, 'rie'),\n",
                            " (312, 'our'),\n",
                            " (313, 'di'),\n",
                            " (314, 'ÌĤ'),\n",
                            " (315, 'ans'),\n",
                            " (316, 'con'),\n",
                            " (317, 'it'),\n",
                            " (318, 'sa'),\n",
                            " (319, 'ge'),\n",
                            " (320, '19'),\n",
                            " (321, 'pa'),\n",
                            " (322, 'ant'),\n",
                            " (323, 'go'),\n",
                            " (324, 'est'),\n",
                            " (325, 'com'),\n",
                            " (326, 'res'),\n",
                            " (327, 'lu'),\n",
                            " (328, 'ment'),\n",
                            " (329, 'po'),\n",
                            " (330, '20'),\n",
                            " (331, 'cate'),\n",
                            " (332, 'ci'),\n",
                            " (333, 'da'),\n",
                            " (334, 'lo'),\n",
                            " (335, 'pre'),\n",
                            " (336, 'vi'),\n",
                            " (337, 'ran'),\n",
                            " (338, 'dans'),\n",
                            " (339, 'tu'),\n",
                            " (340, 'lle'),\n",
                            " (341, 'tre'),\n",
                            " (342, 'to'),\n",
                            " (343, 'ter'),\n",
                            " (344, 'co'),\n",
                            " (345, 'na'),\n",
                            " (346, 'th'),\n",
                            " (347, 'mp'),\n",
                            " (348, 'son'),\n",
                            " (349, 'une'),\n",
                            " (350, 'gorie'),\n",
                            " (351, 'ire'),\n",
                            " (352, 'su'),\n",
                            " (353, 'mi'),\n",
                            " (354, 'ces'),\n",
                            " (355, 'ph'),\n",
                            " (356, 'fa'),\n",
                            " (357, 'ver'),\n",
                            " (358, 'sde'),\n",
                            " (359, 'vo'),\n",
                            " (360, 'pour'),\n",
                            " (361, 'us'),\n",
                            " (362, 'ille'),\n",
                            " (363, 'pro'),\n",
                            " (364, 'ba'),\n",
                            " (365, 'va'),\n",
                            " (366, 'ren'),\n",
                            " (367, 'mo'),\n",
                            " (368, 'fe'),\n",
                            " (369, 'che'),\n",
                            " (370, 'lan'),\n",
                            " (371, 'pu'),\n",
                            " (372, 'tes'),\n",
                            " (373, 'ine'),\n",
                            " (374, 'gu'),\n",
                            " (375, 'ise'),\n",
                            " (376, 'ux'),\n",
                            " (377, 'âĶ'),\n",
                            " (378, 'ga'),\n",
                            " (379, 'ts'),\n",
                            " (380, 'mon'),\n",
                            " (381, 'fran'),\n",
                            " (382, 'cu'),\n",
                            " (383, 'qui'),\n",
                            " (384, 'st'),\n",
                            " (385, 'ques'),\n",
                            " (386, 'fi'),\n",
                            " (387, 'men'),\n",
                            " (388, 'cha'),\n",
                            " (389, '200'),\n",
                            " (390, 'be'),\n",
                            " (391, 'den'),\n",
                            " (392, 'ss'),\n",
                            " (393, 'man'),\n",
                            " (394, 'pri'),\n",
                            " (395, 'bi'),\n",
                            " (396, '201'),\n",
                            " (397, 'vec'),\n",
                            " (398, 'per'),\n",
                            " (399, 'no'),\n",
                            " (400, 'aux'),\n",
                            " (401, 'ion'),\n",
                            " (402, 'tra'),\n",
                            " (403, 'mes'),\n",
                            " (404, 'rou'),\n",
                            " (405, 'mb'),\n",
                            " (406, 'ten'),\n",
                            " (407, 'sen'),\n",
                            " (408, 'ite'),\n",
                            " (409, 'ction'),\n",
                            " (410, 'do'),\n",
                            " (411, 'gra'),\n",
                            " (412, 'for'),\n",
                            " (413, 'mar'),\n",
                            " (414, 'ais'),\n",
                            " (415, 'nes'),\n",
                            " (416, 'plu'),\n",
                            " (417, '18'),\n",
                            " (418, 'Ì§'),\n",
                            " (419, 'bu'),\n",
                            " (420, 'sur'),\n",
                            " (421, 'ni'),\n",
                            " (422, 'don'),\n",
                            " (423, 'lon'),\n",
                            " (424, 'je'),\n",
                            " (425, 'gne'),\n",
                            " (426, 'pi'),\n",
                            " (427, 'teur'),\n",
                            " (428, 'sse'),\n",
                            " (429, 'por'),\n",
                            " (430, 'ru'),\n",
                            " (431, 'cou'),\n",
                            " (432, 'len'),\n",
                            " (433, 'car'),\n",
                            " (434, 'parti'),\n",
                            " (435, 'ale'),\n",
                            " (436, 'so'),\n",
                            " (437, 'ac'),\n",
                            " (438, 'the'),\n",
                            " (439, 'ance'),\n",
                            " (440, 'lie'),\n",
                            " (441, '199'),\n",
                            " (442, 'ses'),\n",
                            " (443, 'lin'),\n",
                            " (444, 'min'),\n",
                            " (445, 'avec'),\n",
                            " (446, 'dis'),\n",
                            " (447, 'sion'),\n",
                            " (448, 'Â»'),\n",
                            " (449, 'Â«'),\n",
                            " (450, 'ation'),\n",
                            " (451, 'franc'),\n",
                            " (452, 'ir'),\n",
                            " (453, 'ste'),\n",
                            " (454, 'lor'),\n",
                            " (455, 'tin'),\n",
                            " (456, 'tri'),\n",
                            " (457, 'ser'),\n",
                            " (458, 'fin'),\n",
                            " (459, 'ÌĪ'),\n",
                            " (460, 'el')]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 68
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "source": [
                "import re, collections\n",
                "\n",
                "def get_stats(vocab):\n",
                "    pairs = collections.defaultdict(int)\n",
                "    for word, freq in vocab.items():\n",
                "        symbols = word.split()\n",
                "        for i in range(len(symbols)-1):\n",
                "            pairs[symbols[i],symbols[i+1]] += freq\n",
                "    return pairs\n",
                "        \n",
                "def merge_vocab(pair, v_in):\n",
                "    v_out = {}\n",
                "    bigram = re.escape(' '.join(pair))\n",
                "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
                "    for word in v_in:\n",
                "        w_out = p.sub(''.join(pair), word)\n",
                "        v_out[w_out] = v_in[word]\n",
                "    return v_out\n",
                "\n",
                "vocab = {\" \".join(bla) : 1}\n",
                "\n",
                "num_merges = 200\n",
                "\n",
                "for i in range(num_merges):\n",
                "    pairs = get_stats(vocab)\n",
                "    best = max(pairs, key=pairs.get)\n",
                "    vocab = merge_vocab(best, vocab)\n",
                "    print(best)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "('e', '́')\n",
                        "('e', 's')\n",
                        "('e', 'n')\n",
                        "('o', 'n')\n",
                        "('d', 'e')\n",
                        "('a', 'n')\n",
                        "('l', 'e')\n",
                        "('r', 'e')\n",
                        "('l', 'a')\n",
                        "('t', 'i')\n",
                        "('e', 'r')\n",
                        "('i', 's')\n",
                        "('i', 'n')\n",
                        "('u', 'r')\n",
                        "('a', 'r')\n",
                        "('o', 'r')\n",
                        "('t', 'e')\n",
                        "('q', 'u')\n",
                        "('e', 't')\n",
                        "('i', 'e')\n",
                        "('u', 'n')\n",
                        "('en', 't')\n",
                        "('o', 'u')\n",
                        "('i', 'l')\n",
                        "('i', 't')\n",
                        "('a', 'l')\n",
                        "('a', 'u')\n",
                        "('c', 'h')\n",
                        "('a', 't')\n",
                        "('d', 'es')\n",
                        "('l', 'es')\n",
                        "('o', 'm')\n",
                        "('a', '̀')\n",
                        "('ti', 'on')\n",
                        "('c', 'e')\n",
                        "('d', 'u')\n",
                        "('r', 'a')\n",
                        "('s', 'e')\n",
                        "('p', 'r')\n",
                        "('p', 'o')\n",
                        "('p', 'ar')\n",
                        "('l', 'i')\n",
                        "('qu', 'e')\n",
                        "('es', 't')\n",
                        "('é', 'g')\n",
                        "('de', 'la')\n",
                        "('m', 'e')\n",
                        "('an', 't')\n",
                        "('d', 'é')\n",
                        "('s', 'i')\n",
                        "('r', 'i')\n",
                        "('n', 'e')\n",
                        "('an', 's')\n",
                        "('c', 'on')\n",
                        "('m', 'ent')\n",
                        "('d', 'i')\n",
                        "('a', 's')\n",
                        "('1', '9')\n",
                        "('v', 'e')\n",
                        "('r', 'é')\n",
                        "('a', 'm')\n",
                        "('c', 'om')\n",
                        "('u', 's')\n",
                        "('r', 'o')\n",
                        "('c', 'at')\n",
                        "('p', 'e')\n",
                        "('2', '0')\n",
                        "('m', 'a')\n",
                        "('c', 'o')\n",
                        "('ég', 'or')\n",
                        "('t', 'é')\n",
                        "('cat', 'égor')\n",
                        "('c', 'i')\n",
                        "('un', 'e')\n",
                        "('t', 'a')\n",
                        "('r', 'es')\n",
                        "('l', 'o')\n",
                        "('d', 'ans')\n",
                        "('r', 'an')\n",
                        "('g', 'e')\n",
                        "('s', 'a')\n",
                        "('v', 'i')\n",
                        "('c', 'a')\n",
                        "('e', 'l')\n",
                        "('é', 'e')\n",
                        "('o', 'i')\n",
                        "('t', 'er')\n",
                        "('catégor', 'ie')\n",
                        "('d', 'a')\n",
                        "('s', 'on')\n",
                        "('p', 'h')\n",
                        "('a', 'le')\n",
                        "('t', 're')\n",
                        "('po', 'ur')\n",
                        "('c', 'es')\n",
                        "('v', 'er')\n",
                        "('l', 'u')\n",
                        "('t', 'h')\n",
                        "('ie', '̀')\n",
                        "('a', 'i')\n",
                        "('a', 'tion')\n",
                        "('l', 'é')\n",
                        "('pr', 'o')\n",
                        "('s', 'u')\n",
                        "('a', 'is')\n",
                        "('il', 'le')\n",
                        "('é', 'r')\n",
                        "('ur', 's')\n",
                        "('t', 'o')\n",
                        "('p', 'u')\n",
                        "('m', 'p')\n",
                        "('l', 'an')\n",
                        "('t', 'u')\n",
                        "('p', 'a')\n",
                        "('é', 's')\n",
                        "('p', 're')\n",
                        "('m', 'o')\n",
                        "('g', 'u')\n",
                        "('m', 'ar')\n",
                        "('f', 'f')\n",
                        "('a', 'c')\n",
                        "('m', 'i')\n",
                        "('m', 'on')\n",
                        "('t', 'es')\n",
                        "('au', 'x')\n",
                        "('qu', 'i')\n",
                        "('f', 'ran')\n",
                        "('l', 'le')\n",
                        "('in', 'e')\n",
                        "('qu', 'es')\n",
                        "('s', 't')\n",
                        "('u', 'x')\n",
                        "('p', 'i')\n",
                        "('20', '0')\n",
                        "('g', 'n')\n",
                        "('̀', 's')\n",
                        "('ch', 'e')\n",
                        "('i', 'en')\n",
                        "('p', 'er')\n",
                        "('it', 'é')\n",
                        "('c', 'u')\n",
                        "('m', 'an')\n",
                        "('a', 'b')\n",
                        "('20', '1')\n",
                        "('à', 'la')\n",
                        "('ve', 'c')\n",
                        "('m', 'é')\n",
                        "('p', 'l')\n",
                        "('d', 'en')\n",
                        "('s', 'de')\n",
                        "('m', 'es')\n",
                        "('s', 'ur')\n",
                        "('in', 't')\n",
                        "('f', 'i')\n",
                        "('f', 'or')\n",
                        "('s', 'o')\n",
                        "('r', 'ou')\n",
                        "('m', 'b')\n",
                        "('t', 'ra')\n",
                        "('1', '8')\n",
                        "('c', 'tion')\n",
                        "('n', 'é')\n",
                        "('g', 'ra')\n",
                        "('d', 'on')\n",
                        "('b', 'u')\n",
                        "('c', '̧')\n",
                        "('a', 'vec')\n",
                        "('d', 'o')\n",
                        "('ti', 'n')\n",
                        "('en', 'd')\n",
                        "('p', 'or')\n",
                        "('p', 'é')\n",
                        "('a', 'it')\n",
                        "('v', 'o')\n",
                        "('pl', 'us')\n",
                        "('j', 'o')\n",
                        "('is', 't')\n",
                        "('j', 'e')\n",
                        "('l', 'on')\n",
                        "('s', 'é')\n",
                        "('c', 'ar')\n",
                        "('a', 'v')\n",
                        "('par', 'ti')\n",
                        "('l', 'is')\n",
                        "('g', 'é')\n",
                        "('m', 'in')\n",
                        "('n', 'es')\n",
                        "('s', 'er')\n",
                        "('19', '9')\n",
                        "('n', 'o')\n",
                        "('r', 'u')\n",
                        "('c', 'ou')\n",
                        "('si', 'on')\n",
                        "('de', 'l')\n",
                        "('an', 'ce')\n",
                        "('iè', 're')\n",
                        "('g', 'ne')\n",
                        "('com', 'm')\n",
                        "('te', 'ur')\n",
                        "('s', 'es')\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def find_best_pair(chain_spaced):\n",
                "    pairs = Counter()\n",
                "    pre_units = chain_spaced.split()\n",
                "    for i in range(len(pre_units) - 1):\n",
                "        pairs[pre_units[i], pre_units[i + 1]] += 1\n",
                "    return pairs.most_common()[0][0]\n",
                "\n",
                "def agglutinate_chain(pair, chain_spaced):\n",
                "    bigram = re.escape(\" \".join(pair))\n",
                "    p = re.compile(r\"(?<!\\S)\" + bigram + r\"(?!\\S)\")\n",
                "    new_chain = p.sub(\"\".join(pair), chain_spaced)\n",
                "    return new_chain\n",
                "\n",
                "def count_units_in_chain(chain_spaced):\n",
                "    vocab = Counter()\n",
                "    chain_units = chain_spaced.split()\n",
                "    for unit in chain_units:\n",
                "        vocab[unit] += 1\n",
                "    return dict(vocab.most_common())\n",
                "\n",
                "def build_vocab(\n",
                "    chain:str,\n",
                "    voc_length: int,\n",
                "    inter_save = [],\n",
                "    save_finalQ = True,\n",
                "    filename = \"voc_default\",\n",
                "    resumeQ = False,\n",
                "    corpus_name = \"corp_deefault\",\n",
                "    courpus_length = None,\n",
                "):\n",
                "    if resumeQ:\n",
                "        initial_chain = chain.replace(\" \", \"\")\n",
                "    else:\n",
                "        initial_chain = chain\n",
                "    spaced_chain = \" \".join(chain)\n",
                "    alpha = count_units_in_chain(spaced_chain)\n",
                "    alpha_len = len(alpha)\n",
                "    print(f\"Length of initial alphabet: {alpha_len}\")\n",
                "    if resumeQ:\n",
                "        print(\"Resuming chain...\")\n",
                "        spaced_chains = chain\n",
                "        print(\"Chain resumed\")\n",
                "    if voc_length > 0:\n",
                "        print(\"Enter loop\")\n",
                "        for i in range(voc_length):\n",
                "            start = time.perf_counter()\n",
                "            best_pair = find_best_pair(spaced_chain)\n",
                "            spaced_chain = agglutinate_chain(best_pair, spaced_chain)\n",
                "            finish = time.perf_counter()\n",
                "            print(\n",
                "                f\"{i}: {''.join(best_pair)} - Computed in {round(finish - start,2)} secs\"\n",
                "            )\n",
                "            # if i in inter_save:\n",
                "            #     vocab = count_units_in_chain(spaced_chain)\n",
                "            #     print(\n",
                "            #         f\"Saving intermediate result. Vocabulary length: {len(vocab)-alpha_len}\"\n",
                "            #     )\n",
                "            #     output_file = (\n",
                "            #         f\"voc_A_{corpus_name}_{len(vocab)-alpha_len}_inter\"\n",
                "            #     )\n",
                "            #     util_g.dict2csv(vocab, output_file, paths.vocabularies)\n",
                "\n",
                "            #     output_resume = f\"{corpus_name}_resume\"\n",
                "            #     util_g.str2txt(spaced_chain, output_resume, paths.scratch)\n",
                "            #     util_g.str2txt(\n",
                "            #         f\"Input corpus: {corpus_name}\\nCorpus Lenght: {courpus_length}\\nParallel: {parallelQ}\\nNumbers of Cores: {n_cores}\\nVocabulary length (so far): {len(vocab)-alpha_len}\",\n",
                "            #         f\"{corpus_name}_resume_info\",\n",
                "            #         paths.scratch,\n",
                "            #     )\n",
                "    print(\"Collecting frequencies of terms\")\n",
                "    vocab = count_units_in_chain(spaced_chain)\n",
                "    # if save_finalQ:\n",
                "    #     util_g.dict2csv(vocab, filename, paths.vocabularies)\n",
                "    return vocab\n",
                "\n",
                "def find_best_pair_par(chain_spaced):\n",
                "    pairs = Counter()\n",
                "    pre_units = chain_spaced.split()\n",
                "    for i in range(len(pre_units) - 1):\n",
                "        pairs[pre_units[i], pre_units[i + 1]] += 1\n",
                "    return dict(\n",
                "        pairs.most_common()[:100]\n",
                "    )  # Looking only on top 100 pre_units of each par list, for efficiency\n",
                "\n",
                "def build_vocab_par(\n",
                "    chain: str,\n",
                "    voc_length: int,\n",
                "    n_cores=4,\n",
                "    inter_save=[],\n",
                "    resumeQ = False,\n",
                "    save_finalQ=False,\n",
                "    filename = \"voc_p_default\",\n",
                "    corpus_name = \"corp_deefault\",\n",
                "    courpus_length = None,\n",
                "    ):\n",
                "    if resumeQ:\n",
                "        initial_chain = chain.replace(' ','').replace('\\n','')\n",
                "    else:\n",
                "        initial_chain = chain\n",
                "    print(\"Spacing chain...\")\n",
                "    spaced_chains = [\" \".join(chain_part) for chain_part in util_g.partition(initial_chain, n_cores)]\n",
                "    print(f\"Chain spaced\")\n",
                "    alphas = util_g.multiprocessing(count_units_in_chain, spaced_chains)\n",
                "    alpha = dict(functools.reduce(operator.add, [Counter(voc) for voc in alphas]).most_common())\n",
                "    apha_len = len(alpha)\n",
                "    print(f'Length of initial alphabet: {apha_len}')\n",
                "    if resumeQ:\n",
                "        print(\"Resuming chain...\")\n",
                "        spaced_chains = chain.split('\\n')\n",
                "        print('Chain resumed')\n",
                "    if voc_length > 0:\n",
                "        print(\"Enter loop\")\n",
                "        for i in range(voc_length):\n",
                "            start = time.perf_counter()\n",
                "            top_pairs_par = util_g.multiprocessing(find_best_pair_par, spaced_chains)\n",
                "            best_pair = functools.reduce(\n",
                "                operator.add, [Counter(top_pairs) for top_pairs in top_pairs_par]\n",
                "            ).most_common()[0][0]\n",
                "            spaced_chains = util_g.multiprocessing(\n",
                "                functools.partial(agglutinate_chain, best_pair), spaced_chains\n",
                "            )\n",
                "            finish = time.perf_counter()\n",
                "            print(\n",
                "                f\"{i}: {''.join(best_pair)} - Computed in {round(finish - start,2)} secs\"\n",
                "            )\n",
                "            # if i in inter_save:\n",
                "            #     vocabs = util_g.multiprocessing(count_units_in_chain, spaced_chains)\n",
                "            #     vocab = dict(\n",
                "            #         functools.reduce(\n",
                "            #             operator.add, [Counter(voc) for voc in vocabs]\n",
                "            #         ).most_common()\n",
                "            #     )\n",
                "            #     print(f\"Saving intermediate result. Vocabulary length: {len(vocab)-apha_len}\")\n",
                "            #     output_file = f\"voc_A_{corpus_name}_p_{len(vocab)-apha_len}_inter\"\n",
                "            #     util_g.dict2csv(vocab, output_file, paths.vocabularies)\n",
                "\n",
                "            #     output_resume = f\"{corpus_name}_p_resume\"\n",
                "            #     util_g.str2txt('\\n'.join(spaced_chains), output_resume, paths.scratch)\n",
                "            #     util_g.str2txt(f'Input corpus: {corpus_name}\\nCorpus Lenght: {courpus_length}\\nParallel: {parallelQ}\\nNumbers of Cores: {n_cores}\\nVocabulary length (so far): {len(vocab)-apha_len}',f\"{corpus_name}_p_resume_info\",paths.scratch)\n",
                "    print('Collecting frequencies of terms')\n",
                "    vocabs = util_g.multiprocessing(count_units_in_chain, spaced_chains)\n",
                "    vocab = dict(\n",
                "        functools.reduce(operator.add, [Counter(voc) for voc in vocabs]).most_common()\n",
                "    )\n",
                "    # if save_finalQ:\n",
                "    #     util_g.dict2csv(vocab, filename, paths.vocabularies)\n",
                "    return vocab\n",
                "\n",
                "def build_vocabulary(\n",
                "    chain,\n",
                "    printQ = True,\n",
                "    parallelQ = True,\n",
                "    n_cores = 4,\n",
                "    voc_len = 10,\n",
                "    inter_results = False,\n",
                "    resumeQ = False,\n",
                "    save_finalQ = False,\n",
                "    filename = \"voc_default\",\n",
                "    corpus_name = \"corp_deefault\",\n",
                "    courpus_length = None,\n",
                "):\n",
                "    start = time.perf_counter()\n",
                "    print(f\"Building Vocabulary\")\n",
                "    if printQ:\n",
                "        print(\"Print is on\")\n",
                "    else:\n",
                "        print(\"Print is off\")\n",
                "    if parallelQ:\n",
                "        print(f\"Method: Parallel - N° of Cores: {n_cores}\")\n",
                "        voc = build_vocab_par(chain, voc_len, n_cores, inter_save=inter_results, save_finalQ=save_finalQ, resumeQ = resumeQ, filename = filename, corpus_name = corpus_name, courpus_length = courpus_length)\n",
                "    else:\n",
                "        print(f\"Method: Sequential\")\n",
                "        voc = build_vocab(chain, voc_len, inter_save=inter_results, save_finalQ=save_finalQ,resumeQ = resumeQ, filename = filename, corpus_name = corpus_name, courpus_length = courpus_length)\n",
                "    finish = time.perf_counter()\n",
                "    print(f\"Vocabulary built in {round(finish - start,2)} secs\")\n",
                "    return voc"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "source": [
                "slg_voc = build_vocabulary(\n",
                "    bla,\n",
                "    printQ = True,\n",
                "    parallelQ = False,\n",
                "    n_cores = 4,\n",
                "    voc_len = 200,\n",
                "    inter_results = False,\n",
                "    resumeQ = False,\n",
                "    save_finalQ = False,\n",
                "    filename = \"voc_default\",\n",
                "    corpus_name = \"corp_deefault\",\n",
                "    courpus_length = None,\n",
                ")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Building Vocabulary\n",
                        "Print is on\n",
                        "Method: Sequential\n",
                        "Length of initial alphabet: 309\n",
                        "Enter loop\n",
                        "0: é - Computed in 0.82 secs\n",
                        "1: es - Computed in 0.8 secs\n",
                        "2: en - Computed in 0.79 secs\n",
                        "3: on - Computed in 0.79 secs\n",
                        "4: de - Computed in 0.78 secs\n",
                        "5: an - Computed in 0.78 secs\n",
                        "6: le - Computed in 0.88 secs\n",
                        "7: re - Computed in 0.83 secs\n",
                        "8: la - Computed in 0.8 secs\n",
                        "9: ti - Computed in 0.76 secs\n",
                        "10: er - Computed in 0.81 secs\n",
                        "11: is - Computed in 0.77 secs\n",
                        "12: in - Computed in 0.75 secs\n",
                        "13: ur - Computed in 0.77 secs\n",
                        "14: ar - Computed in 0.77 secs\n",
                        "15: or - Computed in 0.72 secs\n",
                        "16: te - Computed in 0.74 secs\n",
                        "17: qu - Computed in 0.74 secs\n",
                        "18: et - Computed in 0.71 secs\n",
                        "19: ie - Computed in 0.7 secs\n",
                        "20: un - Computed in 0.7 secs\n",
                        "21: ent - Computed in 0.69 secs\n",
                        "22: ou - Computed in 0.68 secs\n",
                        "23: il - Computed in 0.68 secs\n",
                        "24: it - Computed in 0.68 secs\n",
                        "25: al - Computed in 0.7 secs\n",
                        "26: au - Computed in 0.69 secs\n",
                        "27: ch - Computed in 0.67 secs\n",
                        "28: at - Computed in 0.68 secs\n",
                        "29: des - Computed in 0.69 secs\n",
                        "30: les - Computed in 0.68 secs\n",
                        "31: om - Computed in 0.68 secs\n",
                        "32: à - Computed in 0.67 secs\n",
                        "33: tion - Computed in 0.67 secs\n",
                        "34: ce - Computed in 0.67 secs\n",
                        "35: du - Computed in 0.67 secs\n",
                        "36: ra - Computed in 0.67 secs\n",
                        "37: se - Computed in 0.67 secs\n",
                        "38: pr - Computed in 0.66 secs\n",
                        "39: po - Computed in 0.67 secs\n",
                        "40: par - Computed in 0.66 secs\n",
                        "41: li - Computed in 0.67 secs\n",
                        "42: que - Computed in 0.66 secs\n",
                        "43: est - Computed in 0.66 secs\n",
                        "44: ég - Computed in 0.67 secs\n",
                        "45: dela - Computed in 0.66 secs\n",
                        "46: me - Computed in 0.68 secs\n",
                        "47: ant - Computed in 0.65 secs\n",
                        "48: dé - Computed in 0.65 secs\n",
                        "49: si - Computed in 0.65 secs\n",
                        "50: ri - Computed in 0.68 secs\n",
                        "51: ne - Computed in 0.66 secs\n",
                        "52: ans - Computed in 0.66 secs\n",
                        "53: con - Computed in 0.64 secs\n",
                        "54: ment - Computed in 0.67 secs\n",
                        "55: di - Computed in 0.65 secs\n",
                        "56: as - Computed in 0.66 secs\n",
                        "57: 19 - Computed in 0.67 secs\n",
                        "58: ve - Computed in 0.65 secs\n",
                        "59: ré - Computed in 0.69 secs\n",
                        "60: am - Computed in 0.67 secs\n",
                        "61: com - Computed in 0.68 secs\n",
                        "62: us - Computed in 0.65 secs\n",
                        "63: ro - Computed in 0.65 secs\n",
                        "64: cat - Computed in 0.65 secs\n",
                        "65: pe - Computed in 0.65 secs\n",
                        "66: 20 - Computed in 0.68 secs\n",
                        "67: ma - Computed in 0.74 secs\n",
                        "68: co - Computed in 0.67 secs\n",
                        "69: égor - Computed in 0.67 secs\n",
                        "70: té - Computed in 0.64 secs\n",
                        "71: catégor - Computed in 0.65 secs\n",
                        "72: ci - Computed in 0.65 secs\n",
                        "73: une - Computed in 0.65 secs\n",
                        "74: ta - Computed in 0.64 secs\n",
                        "75: res - Computed in 0.65 secs\n",
                        "76: lo - Computed in 0.63 secs\n",
                        "77: dans - Computed in 0.65 secs\n",
                        "78: ran - Computed in 0.64 secs\n",
                        "79: ge - Computed in 0.63 secs\n",
                        "80: sa - Computed in 0.63 secs\n",
                        "81: vi - Computed in 0.64 secs\n",
                        "82: ca - Computed in 0.67 secs\n",
                        "83: el - Computed in 0.63 secs\n",
                        "84: ée - Computed in 0.65 secs\n",
                        "85: oi - Computed in 0.66 secs\n",
                        "86: ter - Computed in 0.64 secs\n",
                        "87: catégorie - Computed in 0.66 secs\n",
                        "88: da - Computed in 0.64 secs\n",
                        "89: son - Computed in 0.65 secs\n",
                        "90: ph - Computed in 0.65 secs\n",
                        "91: ale - Computed in 0.65 secs\n",
                        "92: tre - Computed in 0.64 secs\n",
                        "93: pour - Computed in 0.63 secs\n",
                        "94: ces - Computed in 0.64 secs\n",
                        "95: ver - Computed in 0.64 secs\n",
                        "96: lu - Computed in 0.63 secs\n",
                        "97: th - Computed in 0.64 secs\n",
                        "98: iè - Computed in 0.65 secs\n",
                        "99: ai - Computed in 0.64 secs\n",
                        "100: ation - Computed in 0.67 secs\n",
                        "101: lé - Computed in 0.66 secs\n",
                        "102: pro - Computed in 0.64 secs\n",
                        "103: su - Computed in 0.65 secs\n",
                        "104: ais - Computed in 0.63 secs\n",
                        "105: ille - Computed in 0.64 secs\n",
                        "106: ér - Computed in 0.65 secs\n",
                        "107: urs - Computed in 0.64 secs\n",
                        "108: to - Computed in 0.71 secs\n",
                        "109: pu - Computed in 0.68 secs\n",
                        "110: mp - Computed in 0.64 secs\n",
                        "111: lan - Computed in 0.65 secs\n",
                        "112: tu - Computed in 0.66 secs\n",
                        "113: pa - Computed in 0.66 secs\n",
                        "114: és - Computed in 0.65 secs\n",
                        "115: pre - Computed in 0.64 secs\n",
                        "116: mo - Computed in 0.66 secs\n",
                        "117: gu - Computed in 0.66 secs\n",
                        "118: mar - Computed in 0.64 secs\n",
                        "119: ff - Computed in 0.63 secs\n",
                        "120: ac - Computed in 0.64 secs\n",
                        "121: mi - Computed in 0.64 secs\n",
                        "122: mon - Computed in 0.64 secs\n",
                        "123: tes - Computed in 0.64 secs\n",
                        "124: aux - Computed in 0.64 secs\n",
                        "125: qui - Computed in 0.63 secs\n",
                        "126: fran - Computed in 0.64 secs\n",
                        "127: lle - Computed in 0.64 secs\n",
                        "128: ine - Computed in 0.64 secs\n",
                        "129: ques - Computed in 0.63 secs\n",
                        "130: st - Computed in 0.63 secs\n",
                        "131: ux - Computed in 0.65 secs\n",
                        "132: pi - Computed in 0.63 secs\n",
                        "133: 200 - Computed in 0.64 secs\n",
                        "134: gn - Computed in 0.64 secs\n",
                        "135: ̀s - Computed in 0.63 secs\n",
                        "136: che - Computed in 0.63 secs\n",
                        "137: ien - Computed in 0.64 secs\n",
                        "138: per - Computed in 0.64 secs\n",
                        "139: ité - Computed in 0.65 secs\n",
                        "140: cu - Computed in 0.64 secs\n",
                        "141: man - Computed in 0.64 secs\n",
                        "142: ab - Computed in 0.65 secs\n",
                        "143: 201 - Computed in 0.64 secs\n",
                        "144: àla - Computed in 0.64 secs\n",
                        "145: vec - Computed in 0.65 secs\n",
                        "146: mé - Computed in 0.71 secs\n",
                        "147: pl - Computed in 0.65 secs\n",
                        "148: den - Computed in 0.63 secs\n",
                        "149: sde - Computed in 0.65 secs\n",
                        "150: mes - Computed in 0.75 secs\n",
                        "151: sur - Computed in 0.7 secs\n",
                        "152: int - Computed in 0.76 secs\n",
                        "153: fi - Computed in 0.77 secs\n",
                        "154: for - Computed in 0.83 secs\n",
                        "155: so - Computed in 0.77 secs\n",
                        "156: rou - Computed in 0.76 secs\n",
                        "157: mb - Computed in 0.73 secs\n",
                        "158: tra - Computed in 0.66 secs\n",
                        "159: 18 - Computed in 0.74 secs\n",
                        "160: ction - Computed in 0.68 secs\n",
                        "161: né - Computed in 0.78 secs\n",
                        "162: gra - Computed in 0.64 secs\n",
                        "163: don - Computed in 0.65 secs\n",
                        "164: bu - Computed in 0.64 secs\n",
                        "165: ç - Computed in 0.65 secs\n",
                        "166: avec - Computed in 0.71 secs\n",
                        "167: do - Computed in 0.69 secs\n",
                        "168: tin - Computed in 0.83 secs\n",
                        "169: end - Computed in 0.64 secs\n",
                        "170: por - Computed in 0.74 secs\n",
                        "171: pé - Computed in 0.66 secs\n",
                        "172: ait - Computed in 0.66 secs\n",
                        "173: vo - Computed in 0.66 secs\n",
                        "174: plus - Computed in 0.66 secs\n",
                        "175: jo - Computed in 0.72 secs\n",
                        "176: ist - Computed in 0.63 secs\n",
                        "177: je - Computed in 0.63 secs\n",
                        "178: lon - Computed in 0.64 secs\n",
                        "179: sé - Computed in 0.64 secs\n",
                        "180: car - Computed in 0.63 secs\n",
                        "181: av - Computed in 0.63 secs\n",
                        "182: parti - Computed in 0.63 secs\n",
                        "183: lis - Computed in 0.63 secs\n",
                        "184: gé - Computed in 0.71 secs\n",
                        "185: min - Computed in 0.69 secs\n",
                        "186: nes - Computed in 0.76 secs\n",
                        "187: ser - Computed in 0.62 secs\n",
                        "188: 199 - Computed in 0.62 secs\n",
                        "189: no - Computed in 0.65 secs\n",
                        "190: ru - Computed in 0.63 secs\n",
                        "191: cou - Computed in 0.64 secs\n",
                        "192: sion - Computed in 0.63 secs\n",
                        "193: del - Computed in 0.64 secs\n",
                        "194: ance - Computed in 0.84 secs\n",
                        "195: ière - Computed in 0.61 secs\n",
                        "196: gne - Computed in 0.81 secs\n",
                        "197: comm - Computed in 0.68 secs\n",
                        "198: teur - Computed in 0.66 secs\n",
                        "199: ses - Computed in 0.64 secs\n",
                        "Collecting frequencies of terms\n",
                        "Vocabulary built in 135.74 secs\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "source": [
                "slg_voc"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'s': 29685,\n",
                            " 'i': 23917,\n",
                            " 't': 22410,\n",
                            " 'de': 22388,\n",
                            " 'en': 21764,\n",
                            " 'c': 21382,\n",
                            " 'le': 19255,\n",
                            " 'a': 18479,\n",
                            " 'b': 17994,\n",
                            " 're': 17815,\n",
                            " 'd': 17360,\n",
                            " 'o': 16337,\n",
                            " 'la': 15649,\n",
                            " 'g': 14941,\n",
                            " 'e': 14778,\n",
                            " 'f': 14640,\n",
                            " 'é': 14359,\n",
                            " 'p': 14325,\n",
                            " 'is': 14094,\n",
                            " 'r': 13810,\n",
                            " 'l': 13610,\n",
                            " 'in': 13119,\n",
                            " 'te': 13111,\n",
                            " 'es': 13023,\n",
                            " 'et': 12914,\n",
                            " 'v': 12837,\n",
                            " 'u': 12346,\n",
                            " 'm': 11810,\n",
                            " 'on': 11053,\n",
                            " 'er': 11034,\n",
                            " 'n': 10157,\n",
                            " 'al': 9995,\n",
                            " 'ti': 9880,\n",
                            " 'an': 9837,\n",
                            " 'h': 9742,\n",
                            " 'ur': 9688,\n",
                            " 'des': 9655,\n",
                            " 'y': 9572,\n",
                            " 'les': 9147,\n",
                            " 'or': 8891,\n",
                            " 'ou': 8541,\n",
                            " 'il': 8530,\n",
                            " 'un': 8176,\n",
                            " 'ch': 8119,\n",
                            " 'au': 8035,\n",
                            " 'it': 7567,\n",
                            " 'du': 7506,\n",
                            " 'ar': 7127,\n",
                            " 'se': 7121,\n",
                            " 'à': 6790,\n",
                            " 'ie': 6704,\n",
                            " 'ce': 6610,\n",
                            " 'ent': 6581,\n",
                            " 'li': 6245,\n",
                            " 'que': 6130,\n",
                            " 'est': 6026,\n",
                            " 'k': 5740,\n",
                            " 'at': 5629,\n",
                            " 'dela': 5617,\n",
                            " 'me': 5549,\n",
                            " '1': 5474,\n",
                            " 'ant': 5439,\n",
                            " 'dé': 5425,\n",
                            " 'ri': 5358,\n",
                            " 'x': 5312,\n",
                            " 'par': 5161,\n",
                            " '̂': 4978,\n",
                            " 'con': 4945,\n",
                            " 'ment': 4843,\n",
                            " 'di': 4840,\n",
                            " 'as': 4836,\n",
                            " 'pr': 4594,\n",
                            " 'ré': 4506,\n",
                            " 'j': 4357,\n",
                            " 'ra': 4318,\n",
                            " 'am': 4282,\n",
                            " '̀': 4280,\n",
                            " 'si': 4271,\n",
                            " 'om': 4222,\n",
                            " '0': 4103,\n",
                            " 'ro': 4069,\n",
                            " 'qu': 4068,\n",
                            " 'pe': 4024,\n",
                            " 'ne': 4022,\n",
                            " 'tion': 4003,\n",
                            " '2': 3818,\n",
                            " 'po': 3814,\n",
                            " 'ma': 3810,\n",
                            " 'co': 3774,\n",
                            " 'té': 3745,\n",
                            " 'ci': 3720,\n",
                            " 'une': 3629,\n",
                            " 'ta': 3602,\n",
                            " 'res': 3590,\n",
                            " '19': 3575,\n",
                            " 'lo': 3402,\n",
                            " 'w': 3373,\n",
                            " '3': 3333,\n",
                            " '4': 3278,\n",
                            " 'dans': 3275,\n",
                            " 'ge': 3184,\n",
                            " 'sa': 3162,\n",
                            " 'com': 3154,\n",
                            " '7': 3152,\n",
                            " 'vi': 3145,\n",
                            " '5': 3136,\n",
                            " 'z': 3072,\n",
                            " 'ca': 3063,\n",
                            " 'el': 3060,\n",
                            " 've': 3048,\n",
                            " '6': 2952,\n",
                            " 'ée': 2939,\n",
                            " 'oi': 2907,\n",
                            " 'ter': 2869,\n",
                            " 'catégorie': 2848,\n",
                            " '8': 2843,\n",
                            " 'us': 2837,\n",
                            " 'da': 2825,\n",
                            " 'son': 2739,\n",
                            " 'ph': 2632,\n",
                            " 'ale': 2628,\n",
                            " 'tre': 2600,\n",
                            " 'pour': 2578,\n",
                            " 'ces': 2544,\n",
                            " 'ver': 2482,\n",
                            " 'lu': 2470,\n",
                            " 'th': 2468,\n",
                            " 'ai': 2441,\n",
                            " 'ation': 2411,\n",
                            " 'lé': 2410,\n",
                            " 'pro': 2373,\n",
                            " 'su': 2342,\n",
                            " 'ais': 2323,\n",
                            " 'ille': 2316,\n",
                            " 'ér': 2279,\n",
                            " 'urs': 2252,\n",
                            " 'to': 2252,\n",
                            " 'pu': 2239,\n",
                            " 'mp': 2191,\n",
                            " 'lan': 2177,\n",
                            " 'tu': 2172,\n",
                            " 'pa': 2151,\n",
                            " 'és': 2150,\n",
                            " 'ég': 2118,\n",
                            " 'pre': 2069,\n",
                            " 'mo': 2063,\n",
                            " '9': 2012,\n",
                            " 'gu': 1999,\n",
                            " 'mar': 1987,\n",
                            " 'ff': 1974,\n",
                            " 'ac': 1948,\n",
                            " 'mi': 1935,\n",
                            " 'mon': 1933,\n",
                            " 'tes': 1931,\n",
                            " 'aux': 1921,\n",
                            " 'qui': 1913,\n",
                            " 'fran': 1913,\n",
                            " 'lle': 1869,\n",
                            " 'ine': 1856,\n",
                            " 'ques': 1820,\n",
                            " 'st': 1799,\n",
                            " 'ux': 1784,\n",
                            " 'pi': 1782,\n",
                            " '200': 1775,\n",
                            " 'gn': 1774,\n",
                            " 'ans': 1741,\n",
                            " '̀s': 1725,\n",
                            " 'che': 1708,\n",
                            " 'ien': 1689,\n",
                            " 'per': 1674,\n",
                            " 'ité': 1663,\n",
                            " 'cu': 1659,\n",
                            " 'man': 1656,\n",
                            " 'ab': 1652,\n",
                            " '201': 1646,\n",
                            " 'àla': 1645,\n",
                            " 'mé': 1598,\n",
                            " 'den': 1568,\n",
                            " 'sde': 1505,\n",
                            " 'mes': 1496,\n",
                            " 'sur': 1491,\n",
                            " 'int': 1478,\n",
                            " 'fi': 1470,\n",
                            " 'for': 1466,\n",
                            " 'so': 1455,\n",
                            " 'rou': 1451,\n",
                            " 'mb': 1447,\n",
                            " 'tra': 1446,\n",
                            " '18': 1444,\n",
                            " 'ction': 1411,\n",
                            " 'né': 1386,\n",
                            " 'gra': 1383,\n",
                            " 'don': 1381,\n",
                            " 'bu': 1380,\n",
                            " 'ç': 1360,\n",
                            " 'avec': 1350,\n",
                            " 'ran': 1345,\n",
                            " 'do': 1340,\n",
                            " 'tin': 1339,\n",
                            " 'iè': 1326,\n",
                            " 'end': 1298,\n",
                            " 'por': 1293,\n",
                            " 'pé': 1286,\n",
                            " 'ait': 1276,\n",
                            " 'vo': 1273,\n",
                            " 'plus': 1260,\n",
                            " 'jo': 1250,\n",
                            " 'ist': 1239,\n",
                            " 'je': 1237,\n",
                            " 'lon': 1235,\n",
                            " 'sé': 1234,\n",
                            " 'car': 1231,\n",
                            " 'av': 1210,\n",
                            " 'parti': 1206,\n",
                            " 'lis': 1194,\n",
                            " 'gé': 1188,\n",
                            " 'min': 1186,\n",
                            " 'nes': 1183,\n",
                            " 'ser': 1177,\n",
                            " '199': 1173,\n",
                            " 'no': 1169,\n",
                            " 'ru': 1157,\n",
                            " 'cou': 1154,\n",
                            " 'sion': 1143,\n",
                            " 'del': 1138,\n",
                            " 'ance': 1137,\n",
                            " '»': 1135,\n",
                            " '«': 1133,\n",
                            " 'ière': 1133,\n",
                            " 'gne': 1128,\n",
                            " 'comm': 1127,\n",
                            " 'teur': 1120,\n",
                            " 'ses': 1096,\n",
                            " '̈': 1045,\n",
                            " 'catégor': 891,\n",
                            " '│': 854,\n",
                            " '─': 606,\n",
                            " '́': 518,\n",
                            " '20': 508,\n",
                            " 'œ': 433,\n",
                            " '├': 360,\n",
                            " 'q': 344,\n",
                            " 'cat': 320,\n",
                            " 'pl': 316,\n",
                            " 'vec': 293,\n",
                            " '└': 243,\n",
                            " '̌': 199,\n",
                            " '°': 142,\n",
                            " '̄': 136,\n",
                            " 'ł': 93,\n",
                            " '̧': 75,\n",
                            " '̃': 56,\n",
                            " '†': 52,\n",
                            " '×': 42,\n",
                            " 'а': 41,\n",
                            " 'и': 36,\n",
                            " 'æ': 36,\n",
                            " 'δ': 31,\n",
                            " 'о': 30,\n",
                            " 'к': 23,\n",
                            " 'н': 23,\n",
                            " 'р': 22,\n",
                            " 'е': 22,\n",
                            " '̆': 21,\n",
                            " 'т': 19,\n",
                            " '̇': 17,\n",
                            " 'с': 16,\n",
                            " 'в': 16,\n",
                            " '̨': 14,\n",
                            " 'ß': 14,\n",
                            " 'α': 14,\n",
                            " 'σ': 12,\n",
                            " '̊': 11,\n",
                            " 'м': 10,\n",
                            " 'л': 10,\n",
                            " 'ι': 10,\n",
                            " 'ø': 10,\n",
                            " '±': 9,\n",
                            " 'ا': 9,\n",
                            " '̦': 8,\n",
                            " 'ρ': 8,\n",
                            " 'ς': 8,\n",
                            " 'ο': 7,\n",
                            " 'у': 7,\n",
                            " '→': 7,\n",
                            " 'ð': 7,\n",
                            " 'ч': 7,\n",
                            " '☆': 7,\n",
                            " 'д': 6,\n",
                            " 'ı': 6,\n",
                            " 'κ': 6,\n",
                            " 'égor': 6,\n",
                            " 'з': 6,\n",
                            " 'я': 6,\n",
                            " 'τ': 6,\n",
                            " 'ɛ': 5,\n",
                            " 'μ': 5,\n",
                            " 'ω': 5,\n",
                            " 'г': 5,\n",
                            " 'ب': 5,\n",
                            " 'ل': 5,\n",
                            " 'х': 5,\n",
                            " 'đ': 5,\n",
                            " 'ˈ': 4,\n",
                            " 'ー': 4,\n",
                            " 'þ': 4,\n",
                            " 'ν': 4,\n",
                            " 'β': 4,\n",
                            " '院': 4,\n",
                            " '城': 4,\n",
                            " '中': 4,\n",
                            " '心': 4,\n",
                            " '街': 4,\n",
                            " '站': 4,\n",
                            " '长': 4,\n",
                            " '安': 4,\n",
                            " 'ن': 4,\n",
                            " '̣': 4,\n",
                            " '⁄': 4,\n",
                            " '✝': 4,\n",
                            " 'п': 4,\n",
                            " 'η': 4,\n",
                            " '⋅': 3,\n",
                            " '་': 3,\n",
                            " '┌': 3,\n",
                            " '€': 3,\n",
                            " 'π': 3,\n",
                            " 'б': 3,\n",
                            " '学': 3,\n",
                            " '路': 3,\n",
                            " '东': 3,\n",
                            " '新': 3,\n",
                            " '厚': 3,\n",
                            " '汽': 3,\n",
                            " '车': 3,\n",
                            " 'ي': 3,\n",
                            " 'ر': 3,\n",
                            " 'ᅡ': 3,\n",
                            " 'ь': 3,\n",
                            " '▼': 3,\n",
                            " 'ད': 2,\n",
                            " 'བ': 2,\n",
                            " '‰': 2,\n",
                            " 'ʂ': 2,\n",
                            " 'ε': 2,\n",
                            " 'υ': 2,\n",
                            " 'ц': 2,\n",
                            " '風': 2,\n",
                            " 'の': 2,\n",
                            " '展': 2,\n",
                            " '大': 2,\n",
                            " '虎': 2,\n",
                            " '门': 2,\n",
                            " 'خ': 2,\n",
                            " 'ط': 2,\n",
                            " 'ٔ': 2,\n",
                            " 'م': 2,\n",
                            " '̮': 2,\n",
                            " '£': 2,\n",
                            " 'ᄒ': 2,\n",
                            " 'ᅩ': 2,\n",
                            " '一': 2,\n",
                            " 'λ': 2,\n",
                            " '▲': 2,\n",
                            " '►': 2,\n",
                            " '्': 2,\n",
                            " 'ᄋ': 2,\n",
                            " 'ス': 1,\n",
                            " 'ハ': 1,\n",
                            " '゚': 1,\n",
                            " '≈': 1,\n",
                            " 'ƒ': 1,\n",
                            " 'ཚ': 1,\n",
                            " 'ེ': 1,\n",
                            " 'ང': 1,\n",
                            " 'པ': 1,\n",
                            " 'ལ': 1,\n",
                            " 'འ': 1,\n",
                            " 'ྱ': 1,\n",
                            " 'ོ': 1,\n",
                            " 'ར': 1,\n",
                            " '阳': 1,\n",
                            " '明': 1,\n",
                            " '区': 1,\n",
                            " '̓': 1,\n",
                            " 'ə': 1,\n",
                            " '͂': 1,\n",
                            " 'ш': 1,\n",
                            " 'ј': 1,\n",
                            " 'ф': 1,\n",
                            " '真': 1,\n",
                            " '言': 1,\n",
                            " '宗': 1,\n",
                            " '寺': 1,\n",
                            " '雨': 1,\n",
                            " '宝': 1,\n",
                            " '匹': 1,\n",
                            " '婦': 1,\n",
                            " '河': 1,\n",
                            " '越': 1,\n",
                            " '骨': 1,\n",
                            " '赤': 1,\n",
                            " '倉': 1,\n",
                            " '錦': 1,\n",
                            " 'こ': 1,\n",
                            " '時': 1,\n",
                            " '号': 1,\n",
                            " 'は': 1,\n",
                            " '照': 1,\n",
                            " '文': 1,\n",
                            " '『': 1,\n",
                            " '魚': 1,\n",
                            " '眠': 1,\n",
                            " '洞': 1,\n",
                            " '発': 1,\n",
                            " '句': 1,\n",
                            " '集': 1,\n",
                            " '』': 1,\n",
                            " '石': 1,\n",
                            " '龙': 1,\n",
                            " '茶': 1,\n",
                            " '山': 1,\n",
                            " '北': 1,\n",
                            " '理': 1,\n",
                            " '工': 1,\n",
                            " '西': 1,\n",
                            " '横': 1,\n",
                            " '会': 1,\n",
                            " '南': 1,\n",
                            " '水': 1,\n",
                            " '濂': 1,\n",
                            " '公': 1,\n",
                            " '园': 1,\n",
                            " '道': 1,\n",
                            " '览': 1,\n",
                            " '莞': 1,\n",
                            " '商': 1,\n",
                            " '贸': 1,\n",
                            " '宁': 1,\n",
                            " '厦': 1,\n",
                            " '边': 1,\n",
                            " '村': 1,\n",
                            " '沙': 1,\n",
                            " '头': 1,\n",
                            " '步': 1,\n",
                            " '行': 1,\n",
                            " '͡': 1,\n",
                            " 'ف': 1,\n",
                            " 'ش': 1,\n",
                            " 'ق': 1,\n",
                            " 'و': 1,\n",
                            " 'غ': 1,\n",
                            " 'ҥ': 1,\n",
                            " 'ᄆ': 1,\n",
                            " 'ᆫ': 1,\n",
                            " 'ᅪ': 1,\n",
                            " 'ᄀ': 1,\n",
                            " 'ᄑ': 1,\n",
                            " 'ᄅ': 1,\n",
                            " '“': 1,\n",
                            " '”': 1,\n",
                            " '周': 1,\n",
                            " '冰': 1,\n",
                            " '潘': 1,\n",
                            " '逸': 1,\n",
                            " '人': 1,\n",
                            " '謙': 1,\n",
                            " '郎': 1,\n",
                            " '漢': 1,\n",
                            " '笹': 1,\n",
                            " '波': 1,\n",
                            " '篳': 1,\n",
                            " '广': 1,\n",
                            " '博': 1,\n",
                            " '物': 1,\n",
                            " '馆': 1,\n",
                            " 'ː': 1,\n",
                            " 'ю': 1,\n",
                            " '👍': 1,\n",
                            " '受': 1,\n",
                            " '動': 1,\n",
                            " '素': 1,\n",
                            " '子': 1,\n",
                            " 'カ': 1,\n",
                            " 'ラ': 1,\n",
                            " 'コ': 1,\n",
                            " 'ト': 1,\n",
                            " '゙': 1,\n",
                            " 'ʃ': 1,\n",
                            " '‡': 1,\n",
                            " 'स': 1,\n",
                            " 'त': 1,\n",
                            " 'य': 1,\n",
                            " 'ा': 1,\n",
                            " 'ग': 1,\n",
                            " 'र': 1,\n",
                            " 'ह': 1,\n",
                            " 'ж': 1,\n",
                            " 'ᅵ': 1,\n",
                            " 'ᅲ': 1,\n",
                            " 'ᄌ': 1,\n",
                            " 'ᅥ': 1,\n",
                            " 'ᆼ': 1,\n",
                            " 'γ': 1,\n",
                            " 'ɲ': 1,\n",
                            " 'ъ': 1,\n",
                            " 'ح': 1,\n",
                            " 'س': 1,\n",
                            " '¡': 1}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 62
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}