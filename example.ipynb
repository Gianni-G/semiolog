{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import semiolog as slg"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SLG: Checking config correctness...\n",
                        "SLG: Config correct!\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 3/3 [00:00<00:00, 13.44it/s]\n"
                    ]
                }
            ],
            "source": [
                "semiotic = slg.Cenematic(\"en_bnc\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "semiotic.syntagmatic.build()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import datasets\n",
                "\n",
                "tokenized_dataset = datasets.load_from_disk(semiotic.paths.syntagmas / \"tokenized\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "DatasetDict({\n",
                            "    train: Dataset({\n",
                            "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
                            "        num_rows: 5000\n",
                            "    })\n",
                            "    dev: Dataset({\n",
                            "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
                            "        num_rows: 277\n",
                            "    })\n",
                            "    test: Dataset({\n",
                            "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
                            "        num_rows: 277\n",
                            "    })\n",
                            "})"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tokenized_dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! Please ensure your labels are passed as keys in the input dict so that they are accessible to the model during the forward pass. To disable this behaviour, please pass a loss argument, or explicitly pass loss=None if you do not want your model to compute a loss.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SLG: Compiling model\n",
                        "SLG: Tokenized dataset loaded from disk\n",
                        "SLG: Filtering rows of length <2\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1/1 [00:00<00:00, 40.62ba/s]\n",
                        "100%|██████████| 1/1 [00:00<00:00, 278.71ba/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SLG: Building train set\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SLG: Building validation set\n",
                        "SLG: Starting training...\n",
                        "\n",
                        "Epoch 1/2\n",
                        "6/6 [==============================] - 53s 6s/step - loss: 10.3539\n",
                        "Epoch 2/2\n",
                        "6/6 [==============================] - 36s 6s/step - loss: 10.2116\n",
                        "SLG: Training finished\n",
                        "\n",
                        "SLG: Model saved.\n",
                        "SLG: Training history saved.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "'SLG: Model built!'"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "semiotic.paradigmatic.build(n_sents=200)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "4208644\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8a0ea4cc7a6c40f78f51a0b1220588ef",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "interactive(children=(Output(),), _dom_classes=('widget-interact',))"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "<function semiolog.syntagmatic.tree.Tree.plot.<locals>.inter()>"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from random import randint\n",
                "n = randint(0,semiotic.corpus.train.num_rows)\n",
                "# n = 51900\n",
                "sent = semiotic.corpus.train[n][\"text\"]\n",
                "\n",
                "\n",
                "sent_seq = semiotic(sent)\n",
                "print(n)\n",
                "sent_seq.tree.plot()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>thankyou_0</th>\n",
                            "      <th>foryour_1</th>\n",
                            "      <th>letter_2</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>syl</td>\n",
                            "      <td>offic</td>\n",
                            "      <td>bowl</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>loor</td>\n",
                            "      <td>junc</td>\n",
                            "      <td>headd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>bowl</td>\n",
                            "      <td>ility</td>\n",
                            "      <td>offic</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>hesit</td>\n",
                            "      <td>aslightly</td>\n",
                            "      <td>wenever</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>junc</td>\n",
                            "      <td>educed</td>\n",
                            "      <td>cd</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>orry</td>\n",
                            "      <td>grammar</td>\n",
                            "      <td>junc</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>hereto</td>\n",
                            "      <td>fter</td>\n",
                            "      <td>hereto</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>incorpor</td>\n",
                            "      <td>olve</td>\n",
                            "      <td>syl</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>sevent</td>\n",
                            "      <td>inson</td>\n",
                            "      <td>frain</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>thecritical</td>\n",
                            "      <td>becalled</td>\n",
                            "      <td>fter</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>10</th>\n",
                            "      <td>aminut</td>\n",
                            "      <td>item</td>\n",
                            "      <td>offers</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>theard</td>\n",
                            "      <td>missed</td>\n",
                            "      <td>muchless</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>12</th>\n",
                            "      <td>pert</td>\n",
                            "      <td>totest</td>\n",
                            "      <td>loor</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13</th>\n",
                            "      <td>roadand</td>\n",
                            "      <td>alph</td>\n",
                            "      <td>dealwith</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>14</th>\n",
                            "      <td>itspr</td>\n",
                            "      <td>nessand</td>\n",
                            "      <td>excuse</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>15</th>\n",
                            "      <td>emonstration</td>\n",
                            "      <td>bitch</td>\n",
                            "      <td>opportunityof</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>16</th>\n",
                            "      <td>frain</td>\n",
                            "      <td>aust</td>\n",
                            "      <td>vs</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>17</th>\n",
                            "      <td>ridiculous</td>\n",
                            "      <td>glo</td>\n",
                            "      <td>verynice</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>18</th>\n",
                            "      <td>1995</td>\n",
                            "      <td>busy</td>\n",
                            "      <td>cel</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>19</th>\n",
                            "      <td>ontheedgeofthe</td>\n",
                            "      <td>printer</td>\n",
                            "      <td>thanniversary</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        thankyou_0  foryour_1       letter_2\n",
                            "0              syl      offic           bowl\n",
                            "1             loor       junc          headd\n",
                            "2             bowl      ility          offic\n",
                            "3            hesit  aslightly        wenever\n",
                            "4             junc     educed             cd\n",
                            "5             orry    grammar           junc\n",
                            "6           hereto       fter         hereto\n",
                            "7         incorpor       olve            syl\n",
                            "8           sevent      inson          frain\n",
                            "9      thecritical   becalled           fter\n",
                            "10          aminut       item         offers\n",
                            "11          theard     missed       muchless\n",
                            "12            pert     totest           loor\n",
                            "13         roadand       alph       dealwith\n",
                            "14           itspr    nessand         excuse\n",
                            "15    emonstration      bitch  opportunityof\n",
                            "16           frain       aust             vs\n",
                            "17      ridiculous        glo       verynice\n",
                            "18            1995       busy            cel\n",
                            "19  ontheedgeofthe    printer  thanniversary"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "sent_seq.parad_chain.df()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "cccfb5a2fd0f3598afe9b50a9347d4d83dedd025ace78c5a47e49a8025e0aa16"
        },
        "kernelspec": {
            "display_name": "Python 3.9.4 64-bit ('3.9.4')",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.10"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
