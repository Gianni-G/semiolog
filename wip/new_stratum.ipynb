{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration corpus-a27362c15ef31df6\n",
      "Reusing dataset text (/Users/Gianni/.cache/huggingface/datasets/text/corpus-a27362c15ef31df6/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
      "100%|██████████| 3/3 [00:00<00:00, 625.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import semiolog as slg\n",
    "\n",
    "semiotic = slg.Cenematic(\"en_bnc_old_sgs_new_stratum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at models/en_bnc_old_segments/paradigms/tf_model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "Using custom data configuration corpus-48c43d9b917d9e96\n",
      "Reusing dataset text (/Users/Gianni/.cache/huggingface/datasets/text/corpus-48c43d9b917d9e96/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
      "100%|██████████| 3/3 [00:00<00:00, 190.02it/s]\n",
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at models/en_bnc_old_segments/paradigms/tf_model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "semiotic_0 = slg.Cenematic(\"en_bnc_old_segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/Gianni/semiolog/models/en_bnc_old_segments/paradigms/kmeans_ids.txt\", \"r\") as k_ids:\n",
    "    cluster_ids = [[int(id) for id in cluster.split()] for cluster in k_ids]\n",
    "cluster_labels = [[semiotic_0.vocab.decode[id] for id in cluster[:40]] for cluster in cluster_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_types = {i:k for i,k in enumerate(semiotic_0.vocab.alpha.keys()) if i<40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_types = {v:k for k,v in encode_types.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_n = 3\n",
    "sent = semiotic.corpus.test[\"text\"][sent_n]\n",
    "sent_0 = semiotic_0.corpus.test[\"text\"][sent_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_seq = semiotic(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Functive(h,(0, 1)),\n",
       " Functive(x,(1, 2)),\n",
       " Functive(or,(2, 4)),\n",
       " Functive(u,(4, 5)),\n",
       " Functive(cl,(5, 7)),\n",
       " Functive(rq,(7, 9)),\n",
       " Functive(cc,(9, 11)),\n",
       " Functive(rq,(11, 13)),\n",
       " Functive(or,(13, 15)),\n",
       " Functive(o,(15, 16)),\n",
       " Functive(0q,(16, 18)),\n",
       " Functive(e,(18, 19)),\n",
       " Functive(r,(19, 20)),\n",
       " Functive(o,(20, 21)),\n",
       " Functive(cg,(21, 23)),\n",
       " Functive(r,(23, 24))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_seq.chain.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she instantly knew thiswasnot ime tobe telling him what her trip to blooming dale shad cost her in peace of mind\n",
      "hxoruclrqccrqoro0qerocgr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[8,\n",
       "  22,\n",
       "  3,\n",
       "  7,\n",
       "  12,\n",
       "  11,\n",
       "  9,\n",
       "  7,\n",
       "  27,\n",
       "  11,\n",
       "  11,\n",
       "  7,\n",
       "  27,\n",
       "  3,\n",
       "  7,\n",
       "  3,\n",
       "  26,\n",
       "  27,\n",
       "  0,\n",
       "  7,\n",
       "  3,\n",
       "  11,\n",
       "  16,\n",
       "  7]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sent_0)\n",
    "print(sent)\n",
    "segmented_types = [[decode_types[t] for t in seg_t] for seg_t in sent_seq.chain.input.split()]\n",
    "segmented_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 'she'),\n",
       " (22, 'instantly'),\n",
       " (3, 'knew'),\n",
       " (7, 'thiswasnot'),\n",
       " (12, 'ime'),\n",
       " (11, 'tobe'),\n",
       " (9, 'telling'),\n",
       " (7, 'him'),\n",
       " (27, 'what'),\n",
       " (11, 'her'),\n",
       " (11, 'trip'),\n",
       " (7, 'to'),\n",
       " (27, 'blooming'),\n",
       " (3, 'dale'),\n",
       " (7, 'shad'),\n",
       " (3, 'cost'),\n",
       " (26, 'her'),\n",
       " (27, 'in'),\n",
       " (0, 'peace'),\n",
       " (7, 'of'),\n",
       " (3, 'mind')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(decode_types[r],l) for l,r in zip(sent_0.split(),sent)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['and', 'but', 'that', 'as', 'when'],\n",
       "  ['and', 'a', 'in', 'all', 'one'],\n",
       "  ['inthe', 'the', 'tothe', 'onthe', 'fromthe'],\n",
       "  ['water', 'head', 'back', 'side', 'wall'],\n",
       "  ['old', 'red', 'black', 'white', 'high'],\n",
       "  ['s', 'in', 'p', 'and', 'f'],\n",
       "  ['on', 's', 'a', 'and', 'er'],\n",
       "  ['water', 'head', 'back', 'side', 'wall'],\n",
       "  ['and', 's', 'of', 'sand', 'sof'],\n",
       "  ['s', 'in', 'p', 'and', 'f'],\n",
       "  ['s', 'in', 'p', 'and', 'f'],\n",
       "  ['water', 'head', 'back', 'side', 'wall'],\n",
       "  ['and', 's', 'of', 'sand', 'sof'],\n",
       "  ['inthe', 'the', 'tothe', 'onthe', 'fromthe'],\n",
       "  ['water', 'head', 'back', 'side', 'wall'],\n",
       "  ['inthe', 'the', 'tothe', 'onthe', 'fromthe'],\n",
       "  ['mark', 'back', 'mix', 'present', 'view'],\n",
       "  ['and', 's', 'of', 'sand', 'sof'],\n",
       "  ['s', 'p', 'the', 't', 'them'],\n",
       "  ['water', 'head', 'back', 'side', 'wall'],\n",
       "  ['inthe', 'the', 'tothe', 'onthe', 'fromthe'],\n",
       "  ['s', 'in', 'p', 'and', 'f'],\n",
       "  ['ing', 'al', 'es', 'a', 's'],\n",
       "  ['water', 'head', 'back', 'side', 'wall']]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[[cluster_labels[c][:5] for c in segment] for segment in segmented_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
