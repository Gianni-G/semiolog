{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import semiolog as slg\n",
    "\n",
    "semiotic = slg.Cenematic(\"fr_wiki\",requested_cpu=4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: models/fr_wiki/vocabulary/merges.txt does not exist.\n",
      "Vocabulary will not be loaded from file.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from collections import Counter\n",
    "import operator\n",
    "from functools import reduce\n",
    "import regex as re\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def count(chain):\n",
    "    count = Counter()\n",
    "    for pair in zip(chain,chain[1:]):\n",
    "        count[pair] += 1\n",
    "    return count\n",
    "\n",
    "def normalize(chain):\n",
    "    return list((\" \".join(chain)).replace(\" \",\"\"))\n",
    "\n",
    "def agglutinate_chain(pair, chain_list):\n",
    "    chain_list = \" \".join(chain_list) \n",
    "    bigram = re.escape(\" \".join(pair))\n",
    "    p = re.compile(r\"(?<!\\S)\" + bigram + r\"(?!\\S)\")\n",
    "    chain_list = p.sub(\"\".join(pair), chain_list)\n",
    "    chain_list = chain_list.split()\n",
    "    return chain_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# vocab_size = 10000\n",
    "chunksize = 250000 #int(vocab_size/semiotic.config.system.cpu_count)+1\n",
    "chains = [semiotic.corpus.train[i*chunksize:i*chunksize+chunksize] for i in range(semiotic.config.system.cpu_count)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "with Parallel(n_jobs=semiotic.config.system.cpu_count) as parallel:\n",
    "    chains = [normalize(chain) for chain in chains]\n",
    "    n_iter = 0\n",
    "    while n_iter<10:\n",
    "        result = parallel(delayed(count)(chain) for chain in chains)\n",
    "        pairs = reduce(operator.add, result)\n",
    "        best_pair = \"\".join(pairs.most_common(1)[0][0])\n",
    "        \n",
    "        chains = parallel(delayed(agglutinate_chain)(best_pair,chain) for chain in chains)\n",
    "        n_iter += 1\n",
    "    freqs = parallel(delayed(Counter)(chain) for chain in chains)\n",
    "    freq = reduce(operator.add, freqs)\n",
    "    \n",
    "print(time.perf_counter()-start)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "90.00467734\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "vocab_size = chunksize * semiotic.config.system.cpu_count\n",
    "chain = semiotic.corpus.train[:vocab_size]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "start = time.perf_counter()\n",
    "chain = normalize(chain)\n",
    "n_iter = 0\n",
    "while n_iter<10:\n",
    "    pairs = count(chain)\n",
    "    best_pair = \"\".join(pairs.most_common(1)[0][0])\n",
    "    chain = agglutinate_chain(best_pair,chain)\n",
    "    n_iter += 1\n",
    "freq_seq = Counter(chain)\n",
    "\n",
    "print(time.perf_counter()-start)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "59.490051267\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for l,r in list(zip(freq.most_common(),freq_seq.most_common())):\n",
    "    if l!=r:\n",
    "        print(l,r)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "n = 50\n",
    "list(zip(freq.most_common(n),freq_seq.most_common(n)))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(('a', 441290), ('a', 441290)),\n",
       " (('t', 393100), ('t', 393100)),\n",
       " (('i', 368352), ('i', 368352)),\n",
       " (('e', 363301), ('e', 363301)),\n",
       " (('u', 360618), ('u', 360618)),\n",
       " (('r', 335156), ('r', 335156)),\n",
       " (('l', 300385), ('l', 300385)),\n",
       " (('o', 267331), ('o', 267331)),\n",
       " (('s', 263724), ('s', 263724)),\n",
       " (('c', 211612), ('c', 211612)),\n",
       " (('d', 181825), ('d', 181825)),\n",
       " (('n', 180368), ('n', 180368)),\n",
       " (('es', 176590), ('es', 176590)),\n",
       " (('p', 176275), ('p', 176275)),\n",
       " (('m', 173766), ('m', 173766)),\n",
       " (('é', 162941), ('é', 162941)),\n",
       " (('en', 122018), ('en', 122018)),\n",
       " (('on', 112878), ('on', 112878)),\n",
       " (('de', 103861), ('de', 103861)),\n",
       " ((',', 93686), (',', 93686)),\n",
       " (('an', 91953), ('an', 91953)),\n",
       " (('g', 80184), ('g', 80184)),\n",
       " (('v', 79655), ('v', 79655)),\n",
       " (('le', 76879), ('le', 76879)),\n",
       " (('re', 72665), ('re', 72665)),\n",
       " (('ti', 70646), ('ti', 70646)),\n",
       " (('h', 69910), ('h', 69910)),\n",
       " (('er', 65824), ('er', 65824)),\n",
       " (('f', 65681), ('f', 65681)),\n",
       " (('.', 64470), ('.', 64470)),\n",
       " (('is', 63108), ('is', 63108)),\n",
       " (('b', 57166), ('b', 57166)),\n",
       " ((\"'\", 53373), (\"'\", 53373)),\n",
       " (('q', 49720), ('q', 49720)),\n",
       " (('1', 42108), ('1', 42108)),\n",
       " (('L', 37012), ('L', 37012)),\n",
       " (('y', 29718), ('y', 29718)),\n",
       " (('x', 29487), ('x', 29487)),\n",
       " (('C', 29215), ('C', 29215)),\n",
       " (('à', 28230), ('à', 28230)),\n",
       " (('0', 28138), ('0', 28138)),\n",
       " (('-', 28062), ('-', 28062)),\n",
       " (('è', 26234), ('è', 26234)),\n",
       " (('9', 26155), ('9', 26155)),\n",
       " (('S', 24970), ('S', 24970)),\n",
       " (('A', 24693), ('A', 24693)),\n",
       " (('2', 22377), ('2', 22377)),\n",
       " (('(', 21532), ('(', 21532)),\n",
       " (('M', 21519), ('M', 21519)),\n",
       " ((')', 21431), (')', 21431))]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}