{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import os\n",
                "os.chdir(\"../\")\n",
                "\n",
                "import semiolog as slg"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "semiotic = slg.Cenematic(\"fr_wiki\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Warning: models/fr_wiki/vocabulary/merges.txt does not exist.\n",
                        "Vocabulary will not be loaded from file.\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "semiotic.vocab.build(vocab_size = 503,parallel=False, parallel_mode=\"process\")"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=252431.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "9916b216f26342e2be69947ff7c9ace3"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 498\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "ac9da98d20fd4d0296e24e581c6b18d8"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=16650242.0, style=Progres…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "00e1be0f35bd48729f4b091795eb65ea"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "chainlist_seq = semiotic.vocab.chain_list\n",
                "alpha_seq = semiotic.vocab.alpha"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "semiotic.vocab.build(vocab_size = 503,parallel=True, parallel_mode=\"process\")"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "c0a34eedbaf64ff192a9fddcf3bfe6d0"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "b41394c2a7b64666974e5411ad2d0776"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 498\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "7339783faf6747608a6a00f33b6bbaef"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=16650242.0, style=Progres…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "4f686d65155a4185ae7a464d309552e5"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "print(chainlist_seq == semiotic.vocab.chain_list)\n",
                "print(alpha_seq == semiotic.vocab.alpha)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "True\n",
                        "True\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "n = 455700\n",
                "chainlist_seq[:n] == semiotic.vocab.chain_list[:n]"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 22
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "[(i,(l,r)) for i,(l,r) in enumerate(zip(sorted(alpha_seq.items()),sorted(semiotic.vocab.alpha.items()))) if l!=r]"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[(1, (('1', 106323), ('1', 106327))),\n",
                            " (2, (('2', 57157), ('2', 57158))),\n",
                            " (3, (('3', 26276), ('3', 26278))),\n",
                            " (6, (('6', 23762), ('6', 23763))),\n",
                            " (9, (('9', 65768), ('9', 65773))),\n",
                            " (10, (('a', 1407511), ('a', 1407529))),\n",
                            " (12, (('c', 610267), ('c', 610278))),\n",
                            " (13, (('d', 761112), ('d', 761124))),\n",
                            " (14, (('e', 2519128), ('e', 2519164))),\n",
                            " (15, (('f', 198180), ('f', 198184))),\n",
                            " (16, (('g', 232012), ('g', 232014))),\n",
                            " (18, (('i', 1307647), ('i', 1307653))),\n",
                            " (19, (('j', 59196), ('j', 59199))),\n",
                            " (21, (('l', 1048131), ('l', 1048140))),\n",
                            " (22, (('m', 494139), ('m', 494146))),\n",
                            " (23, (('n', 1309534), ('n', 1309561))),\n",
                            " (24, (('o', 976389), ('o', 976402))),\n",
                            " (25, (('p', 497908), ('p', 497912))),\n",
                            " (26, (('q', 130512), ('q', 130514))),\n",
                            " (27, (('r', 1231139), ('r', 1231159))),\n",
                            " (28, (('s', 1335796), ('s', 1335809))),\n",
                            " (29, (('t', 1204908), ('t', 1204916))),\n",
                            " (30, (('u', 923685), ('u', 923701))),\n",
                            " (31, (('v', 224262), ('v', 224263))),\n",
                            " (33, (('x', 77466), ('x', 77467))),\n",
                            " (35, (('z', 25807), ('z', 25808))),\n",
                            " (57, (('ç', 11036), ('ç', 11037))),\n",
                            " (58, (('è', 66540), ('è', 66541))),\n",
                            " (59, (('é', 422979), ('é', 422987))),\n",
                            " (74, (('ù', 3839), ('ù', 3840)))]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "[(i,(l,r)) for i,(l,r) in enumerate(zip(chainlist_seq,semiotic.vocab.chain_list)) if l!=r]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "def parallel_chain(chain, n_of_parts):\n",
                "    \"\"\"\n",
                "    Breaks the chain in n chunks to compute best pair of terms. Chunks are overlapping by one term, so as no pair of terms is lost due to the break.\n",
                "    \"\"\"\n",
                "    if not isinstance(chain,list):\n",
                "        chain = list(chain)\n",
                "    chunk_size = int(len(chain) / n_of_parts)+1\n",
                "    for i in range(0, len(chain), chunk_size):\n",
                "        yield chain[i : i + chunk_size +1]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "from temp import bla2\n",
                "        \n",
                "listtup = [\"a\",\"b\",\"c\",\"b\",\"b\",\"c\",\"c\",\"b\",\"c\",\"h\",\"p\"]\n",
                "\n",
                "list(parallel_chain(listtup,4))\n",
                "\n",
                "# result = slg.util.multiprocessing(bla2, listtup)\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[['a', 'b', 'c', 'b'], ['b', 'b', 'c', 'c'], ['c', 'b', 'c', 'h'], ['h', 'p']]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "result"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[(0, ['a', 'b', 'c'], ['a', 'b', 'c']),\n",
                            " (1, ['b', 'b', 'c'], ['b', 'b', 'c']),\n",
                            " (2, ['c', 'b', 'c'], ['c', 'b', 'c'])]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 3
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "corpus = semiotic.corpus.train\n",
                "\n",
                "normalizer = slg.syntagmatic.tokenizer.normalizers.Sequence(semiotic.vocab.config.normalizer)\n",
                "\n",
                "chain_list = []\n",
                "\n",
                "alphabet = Counter()\n",
                "\n",
                "for sent in tqdm(corpus, desc=\"Chain List & Alphabet:\"):\n",
                "    sent = normalizer.normalize(sent)\n",
                "    sent = list(sent)\n",
                "    if sent !=[]:\n",
                "        chain_list += sent\n",
                "        alphabet.update(Counter(sent))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Chain List & Alphabet:', max=252431.0, style=ProgressStyl…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "2b21500c2a7a490997871d7ad2ce8e06"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "reload(temp)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<module 'temp' from '/Users/Gianni/semiolog/wip/temp.py'>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "for i in range(5):\n",
                "    now = datetime.now()\n",
                "    result = util.multiprocessing(temp.find_best_pair, temp.parallel_chain(chain_list,4), cores = 4)\n",
                "\n",
                "    parallel = reduce(operator.add, result)\n",
                "        \n",
                "    parallel = parallel.most_common()\n",
                "    print(datetime.now() - now)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0:00:02.978095\n",
                        "0:00:02.831269\n",
                        "0:00:03.196081\n",
                        "0:00:03.024566\n",
                        "0:00:02.903223\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "for i in range(5):\n",
                "    now = datetime.now()\n",
                "    \n",
                "    sequential = temp.find_best_pair(chain_list)\n",
                "    sequential = sequential.most_common()\n",
                "    \n",
                "    print(datetime.now() - now)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0:00:05.527317\n",
                        "0:00:05.145561\n",
                        "0:00:05.272142\n",
                        "0:00:05.325645\n",
                        "0:00:05.272945\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                " parallel == sequential"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 19
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "semiotic.vocab.build(vocab_size = 1627)"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Chain List & Alphabet', max=252431.0, style=ProgressStyle…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "21f931d414654818a4565d57646dfe57"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "9a4e9784a94e49f39ebce85225881c21"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=16650242.0, style=Progres…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "2ba478a7da654f679ee8152ae55c6e9e"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "semiotic.vocab.build(vocab_size = 1627, parallel=True, parallel_mode=\"process\")"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Chain List & Alphabet', max=252431.0, style=ProgressStyle…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "066ab039732a45b294debfdd794ca18d"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "ef29784a674e40299b1e5767b735da71"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=16650242.0, style=Progres…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "89a3337b15a6487fa2bb8a18a4304547"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "def chain_list_alpha(self, normalizer, corpus_sents, progress_bar = False):\n",
                "    chain_list = []\n",
                "    alphabet = Counter()\n",
                "    for sent in corpus_sents:\n",
                "        sent = normalizer.normalize(sent)\n",
                "        sent = list(sent)\n",
                "        if sent !=[]:\n",
                "            chain_list += sent\n",
                "            alphabet.update(Counter(sent))\n",
                "    return chain_list, alphabet"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "4"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 3
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "from tqdm.notebook import tqdm\n",
                "import time\n",
                "from temp import chain_list_i, chain_list\n",
                "from functools import partial"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "def parallel_chain(chain, n_of_parts):\n",
                "    \"\"\"\n",
                "    Breaks the chain in n chunks to compute best pair of terms. Chunks are overlapping by one term, so as no pair of terms is lost due to the break.\n",
                "    \"\"\"\n",
                "    if not isinstance(chain,list):\n",
                "        chain = list(chain)\n",
                "    chunk_size = int(len(chain) / n_of_parts)+1\n",
                "    for i in range(0, len(chain), chunk_size):\n",
                "        yield chain[i : i + chunk_size +1]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "normalizer = eval(\n",
                "                f\"slg.syntagmatic.tokenizer.normalizers.Sequence({slg.util.if_none_disable(semiotic.config.vocabulary.normalizer)})\"\n",
                "            )"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "bla = chain_list(normalizer,semiotic.corpus.train)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "%%time\n",
                "\n",
                "bla_p = slg.util.multiprocessing(partial(chain_list, normalizer),parallel_chain(semiotic.corpus.train,4),cores=4)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "CPU times: user 303 ms, sys: 190 ms, total: 493 ms\n",
                        "Wall time: 5.57 s\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "%%time\n",
                "\n",
                "bla_t = slg.util.multithreading(partial(chain_list_i, normalizer),semiotic.corpus.train,cores=4)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}