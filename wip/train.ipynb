{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import os\n",
                "os.chdir(\"../\")\n",
                "\n",
                "import semiolog as slg"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "from pyinstrument import Profiler\n",
                "import sys"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "semiotic = slg.Cenematic(\"fr_wiki\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Warning: models/fr_wiki/vocabulary/merges.txt does not exist.\n",
                        "Vocabulary will not be loaded from file.\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import temp2"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "normalizer = eval(f\"slg.syntagmatic.tokenizer.normalizers.Sequence({semiotic.config.vocabulary.normalizer})\")\n",
                "    \n",
                "profile = Profiler()\n",
                "profile.start()\n",
                "\n",
                "merges, vocabulary = temp2.build_nb(\n",
                "    semiotic.corpus.train,\n",
                "    normalizer = normalizer,\n",
                "    voc_final_length = -10)\n",
                "\n",
                "profile.stop()\n",
                "print(profile.output_text(unicode=True, color=True))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "da4030527b9740da8861af8d4d1c6deb"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "0462b6fef8d14e03afe19a7f06e734bd"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.9/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
                        "  self._set_intXint(row, col, x.flat[0])\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "\n",
                        "  _     ._   __/__   _ _  _  _ _/_   Recorded: 20:12:43  Samples:  3443\n",
                        " /_//_/// /_\\ / //_// / //_'/ //     Duration: 91.119    CPU time: 24.568\n",
                        "/   _/                      v3.4.2\n",
                        "\n",
                        "Program: ipykernel_launcher --ip=127.0.0.1 --stdin=9008 --control=9006 --hb=9005 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"39a38a0c-2bab-418f-99cd-22fe9b37e48f\" --shell=9007 --transport=\"tcp\" --iopub=9009 --f=/var/folders/k4/tv2m69x552l9grwtcdhc0zxm0000gn/T/tmp-5448GHGfzg5Y480c.json\n",
                        "\n",
                        "\u001b[31m91.117\u001b[0m run_code\u001b[0m  \u001b[2mIPython/core/interactiveshell.py:3400\u001b[0m\n",
                        "└─ \u001b[31m91.117\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m<ipython-input-5-7db3d9cec460>:6\u001b[0m\n",
                        "   └─ \u001b[31m91.046\u001b[0m \u001b[48;5;24m\u001b[38;5;15mbuild_nb\u001b[0m  \u001b[2mtemp2.py:50\u001b[0m\n",
                        "      ├─ \u001b[31m73.166\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing\u001b[0m  \u001b[2m../semiolog/util.py:58\u001b[0m\n",
                        "      │  ├─ \u001b[31m63.558\u001b[0m __exit__\u001b[0m  \u001b[2mconcurrent/futures/_base.py:635\u001b[0m\n",
                        "      │  │     [14 frames hidden]  \u001b[2mconcurrent, threading, <built-in>, mu...\u001b[0m\n",
                        "      │  │        \u001b[31m63.214\u001b[0m lock.acquire\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  └─ \u001b[32m9.606\u001b[0m map\u001b[0m  \u001b[2mconcurrent/futures/process.py:702\u001b[0m\n",
                        "      │        [119 frames hidden]  \u001b[2mconcurrent, multiprocessing, <built-i...\u001b[0m\n",
                        "      │           \u001b[32m8.344\u001b[0m _get_chunks\u001b[0m  \u001b[2mconcurrent/futures/process.py:183\u001b[0m\n",
                        "      │           ├─ \u001b[32m7.104\u001b[0m \u001b[48;5;24m\u001b[38;5;15mseparate_chain\u001b[0m  \u001b[2mtemp2.py:90\u001b[0m\n",
                        "      │           │  ├─ \u001b[92m\u001b[2m4.496\u001b[0m str.join\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │           │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      │           │  └─ \u001b[92m\u001b[2m2.608\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "      ├─ \u001b[32m6.090\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing_tqdm\u001b[0m  \u001b[2m../semiolog/util.py:71\u001b[0m\n",
                        "      │  └─ \u001b[32m5.330\u001b[0m __iter__\u001b[0m  \u001b[2mtqdm/notebook.py:226\u001b[0m\n",
                        "      │        [41 frames hidden]  \u001b[2mtqdm, concurrent, threading, <built-i...\u001b[0m\n",
                        "      ├─ \u001b[92m\u001b[2m4.345\u001b[0m str.split\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ├─ \u001b[92m\u001b[2m3.031\u001b[0m \u001b[48;5;24m\u001b[38;5;15magglutinate_chain\u001b[0m  \u001b[2mtemp2.py:64\u001b[0m\n",
                        "      │  └─ \u001b[92m\u001b[2m3.025\u001b[0m Pattern.sub\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      └─ \u001b[92m\u001b[2m2.126\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "semiotic.vocab.build_new(corpus = semiotic.corpus.train, vocab_size = -10, parallel=True)"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "801600b688e3496784abd310b7d96252"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 493\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "80b64be1592c409e95212670ba3f43d9"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.9/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
                        "  self._set_intXint(row, col, x.flat[0])\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "semiotic.vocab.build_new(vocab_size = -30, parallel=False)"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=252431.0, style=ProgressStyle(…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "8c7f7895e73a4db698deafeb59f332a8"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 493\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "a5c05633de5a4c8aa3f63ee049ba1291"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.9/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
                        "  self._set_intXint(row, col, x.flat[0])\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "new_seq = semiotic.vocab.freq"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "semiotic.vocab.build_old(vocab_size = 510, parallel=False)"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=252431.0, style=ProgressStyle(…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "1b58d95d8474487e8a6e987bb414667c"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 498\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "a3ee3e2c98924a6a9d9116e72f6c2fa7"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=15373175.0, style=Progres…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "a2bca1b906804aaf83d63e32186b65ea"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "old_seq = semiotic.vocab.freq"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "semiotic.vocab.build_old(vocab_size = -30, parallel=True, parallel_mode=\"process\")"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "66dd602af9b44035a041aa9990f0554b"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 498\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "d97586896fb94e0d9a14eb870f6b062e"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=13541851.0, style=Progres…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "2077685745cf4af09a290b4574abc4b9"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "old_par = semiotic.vocab.freq"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "source": [
                "n = 10\n",
                "\n",
                "for i,j in zip(new_seq.items(),old_seq.items()):\n",
                "    if i!=j:\n",
                "        print(i,j)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "('s', 701369) ('s', 701370)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import regex as re\n",
                "import numpy as np\n",
                "from collections import Counter\n",
                "from scipy.sparse import csr_matrix, lil_matrix, coo_matrix\n",
                "from tqdm.notebook import tqdm, trange\n",
                "from functools import partial\n",
                "from functools import reduce\n",
                "import operator\n",
                "\n",
                "import time\n",
                "from pyinstrument import Profiler\n",
                "import sys\n",
                "\n",
                "from temp import findall_contexts, find_best_pair"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "def build_nb(\n",
                "    corpus = None,\n",
                "    voc_final_length = -30,\n",
                "    # save = False,\n",
                "    # save_step = None,\n",
                "    # progress_bar = True,\n",
                "    # resume_merges = False,\n",
                "    parallel = True,\n",
                "    sparse = True,\n",
                "    sparse_mode = \"csr\",\n",
                "    cpu_count = 4,\n",
                "    corpus_length = None,\n",
                "    normalizer = None,\n",
                "):\n",
                "    def agglutinate_chain(pair, cl_chain):\n",
                "        bigram = re.escape(\" \".join(pair))\n",
                "        p = re.compile(r\"(?<!\\S)\" + bigram + r\"(?!\\S)\")\n",
                "        cl_chain = p.sub(\"\".join(pair), cl_chain)\n",
                "        return cl_chain\n",
                "\n",
                "    def extract_drc(pairs, encoder: dict):\n",
                "        data = []\n",
                "        rows = []\n",
                "        columns = []\n",
                "        for (r,c),d in pairs:\n",
                "            data.append(d)\n",
                "            rows.append(encoder[r])\n",
                "            columns.append(encoder[c])\n",
                "        return data, rows, columns\n",
                "\n",
                "    def parallel_chain(chain, n_of_parts, overlap = 0):\n",
                "        \"\"\"\n",
                "        Breaks the chain in n chunks to compute best pair of terms. Chunks are overlapping by one term, so as no pair of terms is lost due to the break.\n",
                "        \"\"\"\n",
                "        if not isinstance(chain,list):\n",
                "            chain = list(chain)\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        for i in range(0, len(chain), chunk_size):\n",
                "            yield chain[i : i + chunk_size + overlap]\n",
                "\n",
                "    def separate_chain(chain, n_of_parts, best_pair: list):\n",
                "        \"\"\"\n",
                "        Separate a chain (in list form) for parallel processing of regex findall of pair, taking care that the cuts of the chunks don't fall in the neiborhood of the pair, affecting the final counts\n",
                "        \"\"\"\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        b = 0\n",
                "        n = chunk_size\n",
                "        chain_len = len(chain)\n",
                "        for i in range(n_of_parts):\n",
                "            n = (i+1)*chunk_size\n",
                "            if chain_len > n:\n",
                "                while chain[n-2:n] == best_pair or chain[n-1:n+1] == best_pair:\n",
                "                    n = n+1\n",
                "            yield (\"[SEP_i] \" if i!=0 else \"\") + \" \".join(chain[b:n]) + (\" [SEP_i]\" if i!=n_of_parts-1 else \"\")\n",
                "            b = n-1\n",
                "        \n",
                "        \n",
                "    normalizer = eval(f\"slg.syntagmatic.tokenizer.normalizers.Sequence({semiotic.config.vocabulary.normalizer})\")\n",
                "    \n",
                "    if parallel:\n",
                "        \n",
                "        par_corpus = parallel_chain(corpus[:corpus_length], cpu_count)\n",
                "\n",
                "        result = slg.util.multiprocessing_tqdm(partial(semiotic.vocab.chain_list_alpha, normalizer), par_corpus, cores=cpu_count, desc=\"Normalize & Alphabet\")\n",
                "        \n",
                "        chain_list = []\n",
                "        alphabet = Counter()\n",
                "        for chain_l, alpha in result:\n",
                "            chain_list += chain_l\n",
                "            alphabet += alpha\n",
                "            \n",
                "    else:\n",
                "        chain_list, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train[:corpus_length], progress_bar=True)\n",
                "\n",
                "    # cl, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train, progress_bar=True)\n",
                "    cl_chain = \"[SEP] \"+\" \".join(chain_list)+\" [SEP]\"\n",
                "    encode = {k:i for i,(k,v) in enumerate(alphabet.most_common())}\n",
                "    decode = {i:k for k,i in encode.items()}\n",
                "    new_i = len(encode)\n",
                "    if parallel:\n",
                "        \n",
                "        par_chain = parallel_chain(chain_list, cpu_count, overlap=1)\n",
                "        \n",
                "        result = slg.util.multiprocessing(find_best_pair, par_chain, cores=cpu_count) \n",
                "                            \n",
                "        pairs = reduce(operator.add, result)\n",
                "        pairs = pairs.most_common()\n",
                "        \n",
                "    else:\n",
                "        pairs = find_best_pair(chain_list).most_common()\n",
                "    if voc_final_length<0:\n",
                "        voc_final_length = new_i + abs(voc_final_length)\n",
                "        \n",
                "    if sparse:\n",
                "        data, rows, columns = extract_drc(pairs,encode)\n",
                "        voc_matrix = coo_matrix((np.array(data), (np.array(rows),np.array(columns))), shape=(voc_final_length, voc_final_length), dtype=int)\n",
                "\n",
                "    else:\n",
                "        voc_matrix = np.zeros((voc_final_length, voc_final_length), dtype=int)\n",
                "        for (row,column),value in pairs:\n",
                "            voc_matrix[encode[row], encode[column]] = value\n",
                "    merges = []\n",
                "    delta_voc = voc_final_length - new_i\n",
                "    best_pair = \"init\"\n",
                "    pair_count = \"---\"\n",
                "\n",
                "    t = trange(delta_voc) #, disable = not progress_bar)\n",
                "\n",
                "    for _ in t:\n",
                "        t.set_description(f\"Pair: {best_pair}, {pair_count}\")\n",
                "        t.refresh()\n",
                "\n",
                "        if sparse:\n",
                "            max_i = voc_matrix.data.argmax()\n",
                "            pair_row = voc_matrix.row[max_i]\n",
                "            pair_col = voc_matrix.col[max_i]\n",
                "            pair_count = voc_matrix.data[max_i]\n",
                "        else:\n",
                "            pair_row,pair_col = np.unravel_index(np.argmax(voc_matrix, axis=None), voc_matrix.shape)\n",
                "            pair_count = voc_matrix[pair_row,pair_col]\n",
                "        \n",
                "        if pair_count == 0:\n",
                "            break\n",
                "\n",
                "        best_pair = (decode[pair_row], decode[pair_col])\n",
                "        best_pair_string = \" \".join(best_pair)\n",
                "        merges.append(best_pair_string)\n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        re_voc_l = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\"\\[SEP\\] \",\"\\[SEP_i\\] \"])+\")\"\n",
                "        re_voc_r = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\" \\[SEP\\]\",\" \\[SEP_i\\]\"])+\")\"\n",
                "        if parallel:\n",
                "            result = slg.util.multiprocessing(\n",
                "                partial(findall_contexts,best_pair_string=best_pair_string,re_voc_l=re_voc_l,re_voc_r=re_voc_r),\n",
                "                separate_chain(cl_chain.split(), cpu_count, list(best_pair)),\n",
                "                cores = cpu_count\n",
                "                )\n",
                "            merge_context = reduce(operator.add, result)\n",
                "        else:\n",
                "            merge_context = re.findall(re_voc_l+best_pair_string+re_voc_r, cl_chain, overlapped=True)\n",
                "        merge_context_count_l = Counter()\n",
                "        merge_context_count_r = Counter()\n",
                "        for l,r in merge_context:\n",
                "            if \"[SEP]\" not in l:\n",
                "                merge_context_count_l[encode[l.strip()]] += 1\n",
                "            if \"[SEP]\" not in r:\n",
                "                merge_context_count_r[encode[r.strip()]] += 1\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix to CSR or LIL, for item attribution and arithmetic \n",
                "            if sparse_mode == \"csr\":\n",
                "                voc_matrix = voc_matrix.tocsr()\n",
                "            else:\n",
                "                voc_matrix = voc_matrix.tolil()\n",
                "        \n",
                "        for row,key in merge_context_count_l.items():\n",
                "            voc_matrix[row,new_i] = key\n",
                "            \n",
                "        for column,key in merge_context_count_r.items():\n",
                "            voc_matrix[new_i,column] = key\n",
                "\n",
                "        # Correct previous counts\n",
                "        \n",
                "        # compute #(l,r)-(l,r)\n",
                "        pair_pair_count = len(re.findall(\" \"+best_pair_string+\" \"+best_pair_string+\" \", cl_chain, overlapped=False))\n",
                "        # remove #(l,r)-(l,r) from (l,r)-l\n",
                "        voc_matrix[new_i,pair_row] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-(l,r)\n",
                "        voc_matrix[pair_col,new_i] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-l\n",
                "        voc_matrix[pair_col,pair_row] -= pair_pair_count\n",
                "        # substract (l,r)- from r-\n",
                "        voc_matrix[pair_col,:new_i] -= voc_matrix[new_i,:new_i]\n",
                "        # substract -(l,r)- from -l\n",
                "        voc_matrix[:new_i,pair_row] -= voc_matrix[:new_i,new_i]\n",
                "        \n",
                "        # set l-r to 0\n",
                "        voc_matrix[pair_row,pair_col] = 0\n",
                "        # register #(l,r)-(l,r)\n",
                "        voc_matrix[new_i,new_i] = pair_pair_count\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix back to COO, to restart the loop\n",
                "            voc_matrix = voc_matrix.tocoo()\n",
                "        \n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        encode[best_pair_string_voc] = new_i\n",
                "        decode[new_i] = best_pair_string_voc\n",
                "        new_i += 1\n",
                "        cl_chain = agglutinate_chain(best_pair_string.split(),cl_chain)\n",
                "\n",
                "\n",
                "    if sparse:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()[0]\n",
                "    else:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()\n",
                "    vocabulary = {decode[i]:v for i,v in enumerate(freq_values) if v>0} # Make sure dimension of matrix and size of voc coincide\n",
                "    vocabulary = sorted(vocabulary.items(), key=lambda x: x[1], reverse=True)\n",
                "    \n",
                "    return merges, vocabulary"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "normalizer = eval(f\"slg.syntagmatic.tokenizer.normalizers.Sequence({semiotic.config.vocabulary.normalizer})\")\n",
                "    \n",
                "profile = Profiler()\n",
                "profile.start()\n",
                "\n",
                "merges, vocabulary = build_nb(\n",
                "    semiotic.corpus.train,\n",
                "    normalizer = normalizer,\n",
                "    voc_final_length = -10)\n",
                "\n",
                "profile.stop()\n",
                "print(profile.output_text(unicode=True, color=True))"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'slg' is not defined",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-4-5d79b248b30f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m merges, vocabulary = slg.util.build_nb(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msemiotic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/semiolog/semiolog/util.py\u001b[0m in \u001b[0;36mbuild_nb\u001b[0;34m(corpus, voc_final_length, parallel, sparse, sparse_mode, cpu_count, corpus_length, normalizer)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mpar_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcorpus_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemiotic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain_list_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Normalize & Alphabet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mchain_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'slg' is not defined"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "source": [
                "vocabulary\n",
                "\n",
                "n = 10\n",
                "\n",
                "for i,j in zip(old_par.items(),vocabulary):\n",
                "    if i!=j:\n",
                "        print(i,j)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "('s', 701370) ('s', 701369)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "source": [
                "semiotic.vocab.build(vocab_size = -57,parallel=False, parallel_mode=\"process\")#, corpus_length = int(semiotic.corpus.train_len/2))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=252431.0, style=ProgressStyle(…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "5997a264e6d644218976c60d894b1df4"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 498\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "b6c0e6eaec3c4f79910dbbea2c90fcca"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=12186002.0, style=Progres…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "2ec1886ee3964d738b5ff2a14391a537"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 129,
            "source": [
                "n = 20\n",
                "list(zip(semiotic.vocab.head(n),sorted(freq.items(),key=lambda x: -x[-1])[:n]))"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "[(('s', 508031), ('s', 508042.0)),\n",
                            " (('a', 473573), ('a', 473579.0)),\n",
                            " (('i', 462761), ('i', 462761.0)),\n",
                            " (('c', 430340), ('c', 430340.0)),\n",
                            " (('t', 380467), ('t', 380467.0)),\n",
                            " (('e', 367927), ('e', 367952.0)),\n",
                            " (('o', 362797), ('o', 362797.0)),\n",
                            " (('é', 334122), ('é', 334122.0)),\n",
                            " (('p', 308171), ('p', 308171.0)),\n",
                            " (('u', 291580), ('u', 291580.0)),\n",
                            " (('r', 290367), ('r', 290367.0)),\n",
                            " (('m', 288144), ('m', 288144.0)),\n",
                            " (('d', 257336), ('d', 257336.0)),\n",
                            " (('l', 238515), ('l', 238515.0)),\n",
                            " (('es', 234391), ('es', 234391.0)),\n",
                            " (('g', 232012), ('g', 232012.0)),\n",
                            " (('le', 218298), ('le', 218298.0)),\n",
                            " (('de', 217459), ('de', 217459.0)),\n",
                            " (('en', 216870), ('en', 216870.0)),\n",
                            " (('f', 198180), ('f', 198180.0))]"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 129
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 127,
            "source": [
                "semiotic.vocab.merges == merges"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 127
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "semiotic.vocab.build(vocab_size = -5, parallel=True, parallel_mode=\"process\", corpus_length = int(semiotic.corpus.train_len/2))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "4e9b8995244b455b88bc29c471c9bffe"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 384\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "84fdc68d7d5c423e88f2b4d74fb042c1"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=8304704.0, style=Progress…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "8df26ec9866144168e4ef2e6abafbc52"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "\n",
                "from pyinstrument import Profiler\n",
                "import sys\n",
                "def profiler(process):\n",
                "    profile = Profiler()\n",
                "\n",
                "    profile.start()\n",
                "    \n",
                "    try:\n",
                "        exec(process)\n",
                "    except:\n",
                "        print(f\"{sys.exc_info()}\")\n",
                "\n",
                "    profile.stop()\n",
                "\n",
                "    return print(profile.output_text(unicode=True, color=True))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "profiler(semiotic.vocab.build(vocab_size = 212,parallel=False, parallel_mode=\"process\", corpus_length = int(semiotic.corpus.train_len/10)))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=25243.0, style=ProgressStyle(d…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "dce358e14cc24980aae988e4fad42f57"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 207\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "77a22b6e9f864aa28250ac0b8bcb9f7f"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=1676869.0, style=Progress…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "b82c5bc4314148129a80b30682b3d6f6"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n",
                        "(<class 'TypeError'>, TypeError('exec() arg 1 must be a string, bytes or code object'), <traceback object at 0x14b8bc440>)\n",
                        "\n",
                        "  _     ._   __/__   _ _  _  _ _/_   Recorded: 15:49:47  Samples:  0\n",
                        " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.000     CPU time: 0.000\n",
                        "/   _/                      v3.4.2\n",
                        "\n",
                        "Program: ipykernel_launcher --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"66a0e2b3-2867-465b-8afe-3ed0b96ada4e\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/var/folders/k4/tv2m69x552l9grwtcdhc0zxm0000gn/T/tmp-1226N840kXOqJHYH.json\n",
                        "\n",
                        "No samples were recorded.\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "profile = Profiler()\n",
                "\n",
                "profile.start()\n",
                "\n",
                "semiotic.vocab.build(vocab_size = -5,parallel=False, parallel_mode=\"process\", corpus_length = int(semiotic.corpus.train_len))\n",
                "\n",
                "profile.stop()\n",
                "\n",
                "print(profile.output_text(unicode=True, color=True))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=252431.0, style=ProgressStyle(…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "af4e0c6eef07428d92a947e226f04945"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 498\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "8968d49730e74854a73652cc0aeb6bcb"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=18245393.0, style=Progres…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "16c815be4a4c4ebfa3884eec67d8d997"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-17-2ab4ab5ea391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msemiotic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"process\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msemiotic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/semiolog/semiolog/vocabulary.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, corpus, vocab_size, special_tokens, save, save_step, progress_bar, resume_merges, parallel, parallel_mode, corpus_length)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "profile = Profiler()\n",
                "\n",
                "profile.start()\n",
                "\n",
                "semiotic.vocab.build(vocab_size = 503, parallel=True, parallel_mode=\"process\", corpus_length = int(semiotic.corpus.train_len))\n",
                "\n",
                "profile.stop()\n",
                "\n",
                "print(profile.output_text(unicode=True, color=True))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "3e57fecf6dbc49dda2f6e1d17aeae9b7"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Alphabet Size: 498\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "50d4eb71583b491c84b6877cee12ef0a"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Building Final Vocabulary', max=16650242.0, style=Progres…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "9a6a4b1c0cc84a15b3f5dd4fbe528421"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Vocabulary built\n",
                        "\n",
                        "  _     ._   __/__   _ _  _  _ _/_   Recorded: 15:54:11  Samples:  9363\n",
                        " /_//_/// /_\\ / //_// / //_'/ //     Duration: 58.358    CPU time: 23.010\n",
                        "/   _/                      v3.4.2\n",
                        "\n",
                        "Program: ipykernel_launcher --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"66a0e2b3-2867-465b-8afe-3ed0b96ada4e\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/var/folders/k4/tv2m69x552l9grwtcdhc0zxm0000gn/T/tmp-1226N840kXOqJHYH.json\n",
                        "\n",
                        "\u001b[31m58.359\u001b[0m run_code\u001b[0m  \u001b[2mIPython/core/interactiveshell.py:3400\u001b[0m\n",
                        "└─ \u001b[31m58.359\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m<ipython-input-12-c8129d69a3d6>:5\u001b[0m\n",
                        "   └─ \u001b[31m58.351\u001b[0m \u001b[48;5;24m\u001b[38;5;15mbuild\u001b[0m  \u001b[2msemiolog/vocabulary.py:133\u001b[0m\n",
                        "      ├─ \u001b[31m37.481\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing\u001b[0m  \u001b[2msemiolog/util.py:58\u001b[0m\n",
                        "      │  ├─ \u001b[33m34.059\u001b[0m __exit__\u001b[0m  \u001b[2mconcurrent/futures/_base.py:635\u001b[0m\n",
                        "      │  │     [11 frames hidden]  \u001b[2mconcurrent, threading, <built-in>, mu...\u001b[0m\n",
                        "      │  │        \u001b[33m33.776\u001b[0m lock.acquire\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  └─ \u001b[32m3.418\u001b[0m map\u001b[0m  \u001b[2mconcurrent/futures/process.py:702\u001b[0m\n",
                        "      │        [107 frames hidden]  \u001b[2mconcurrent, multiprocessing, ipykerne...\u001b[0m\n",
                        "      │           \u001b[92m\u001b[2m0.848\u001b[0m _get_chunks\u001b[0m  \u001b[2mconcurrent/futures/process.py:183\u001b[0m\n",
                        "      │           └─ \u001b[92m\u001b[2m0.847\u001b[0m \u001b[48;5;24m\u001b[38;5;15mparallel_chain\u001b[0m  \u001b[2msemiolog/vocabulary.py:170\u001b[0m\n",
                        "      ├─ \u001b[32m6.308\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing_tqdm\u001b[0m  \u001b[2msemiolog/util.py:71\u001b[0m\n",
                        "      │  └─ \u001b[32m5.236\u001b[0m __iter__\u001b[0m  \u001b[2mtqdm/notebook.py:226\u001b[0m\n",
                        "      │        [53 frames hidden]  \u001b[2mtqdm, concurrent, threading, <built-i...\u001b[0m\n",
                        "      ├─ \u001b[32m5.503\u001b[0m __iter__\u001b[0m  \u001b[2mtqdm/notebook.py:226\u001b[0m\n",
                        "      │     [202 frames hidden]  \u001b[2mtqdm, traitlets, ipywidgets, <built-i...\u001b[0m\n",
                        "      ├─ \u001b[32m4.932\u001b[0m \u001b[48;5;24m\u001b[38;5;15magglutinate_chain\u001b[0m  \u001b[2msemiolog/vocabulary.py:181\u001b[0m\n",
                        "      │  ├─ \u001b[92m\u001b[2m1.755\u001b[0m str.join\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      │  ├─ \u001b[92m\u001b[2m1.709\u001b[0m str.split\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      │  └─ \u001b[92m\u001b[2m1.442\u001b[0m Pattern.sub\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      └─ \u001b[32m4.083\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "bla = -500"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "bla"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "-500"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 15
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "abs(-50)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "50"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 16
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}