{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import os\n",
                "os.chdir(\"../\")\n",
                "\n",
                "import semiolog as slg"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "from pyinstrument import Profiler\n",
                "import sys"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "semiotic = slg.Cenematic(\"fr_wiki\",requested_cpu=4)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Warning: models/fr_wiki/vocabulary/merges.txt does not exist.\n",
                        "Vocabulary will not be loaded from file.\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "(92+8) % 10 == 0"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "semiotic.vocab.build_new(vocab_size = -100, parallel=False, save=True, save_step=10)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Normalize & Alphabet: 100%|██████████| 252431/252431 [00:06<00:00, 36417.20it/s]\n",
                        "Pair: init, ---:   0%|          | 0/100 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Alphabet Size: 493\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.9/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
                        "  self._set_intXint(row, col, x.flat[0])\n",
                        "Pair: ('v', 'er'), 19844: 100%|██████████| 100/100 [04:59<00:00,  3.00s/it]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Vocabulary built\n",
                        "Vocabulary saved to models/fr_wiki/vocabulary\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import regex as re\n",
                "import numpy as np\n",
                "from collections import Counter\n",
                "from scipy.sparse import csr_matrix, lil_matrix, coo_matrix\n",
                "from tqdm.notebook import tqdm, trange\n",
                "from functools import partial\n",
                "from functools import reduce\n",
                "import operator\n",
                "\n",
                "import time\n",
                "from pyinstrument import Profiler\n",
                "import sys\n",
                "\n",
                "from temp import findall_contexts, findall_contexts_list, find_best_pair, agglutinate_list"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "def build_nb(\n",
                "    corpus = None,\n",
                "    voc_final_length = -30,\n",
                "    # save = False,\n",
                "    # save_step = None,\n",
                "    # progress_bar = True,\n",
                "    # resume_merges = False,\n",
                "    parallel = False,\n",
                "    sparse = True,\n",
                "    sparse_mode = \"csr\",\n",
                "    cpu_count = 4,\n",
                "    corpus_length = None,\n",
                "    normalizer = None,\n",
                "):\n",
                "    def agglutinate_chain(pair, cl_chain):\n",
                "        bigram = re.escape(\" \".join(pair))\n",
                "        p = re.compile(r\"(?<!\\S)\" + bigram + r\"(?!\\S)\")\n",
                "        cl_chain = p.sub(\"\".join(pair), cl_chain)\n",
                "        return cl_chain\n",
                "\n",
                "    def extract_drc(pairs, encoder: dict):\n",
                "        data = []\n",
                "        rows = []\n",
                "        columns = []\n",
                "        for (r,c),d in pairs:\n",
                "            data.append(d)\n",
                "            rows.append(encoder[r])\n",
                "            columns.append(encoder[c])\n",
                "        return data, rows, columns\n",
                "\n",
                "    def parallel_chain(chain, n_of_parts, overlap = 0):\n",
                "        \"\"\"\n",
                "        Breaks the chain in n chunks to compute best pair of terms. Chunks are overlapping by one term, so as no pair of terms is lost due to the break.\n",
                "        \"\"\"\n",
                "        if not isinstance(chain,list):\n",
                "            chain = list(chain)\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        for i in range(0, len(chain), chunk_size):\n",
                "            yield chain[i : i + chunk_size + overlap]\n",
                "\n",
                "    def separate_chain(chain, n_of_parts, best_pair: list):\n",
                "        \"\"\"\n",
                "        Separate a chain (in list form) for parallel processing of regex findall of pair, taking care that the cuts of the chunks don't fall in the neiborhood of the pair, affecting the final counts\n",
                "        \"\"\"\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        b = 0\n",
                "        n = chunk_size\n",
                "        chain_len = len(chain)\n",
                "        for i in range(n_of_parts):\n",
                "            n = (i+1)*chunk_size\n",
                "            if chain_len > n:\n",
                "                while chain[n-2:n] == best_pair or chain[n-1:n+1] == best_pair:\n",
                "                    n = n+1\n",
                "            yield (\"[SEP_i] \" if i!=0 else \"\") + \" \".join(chain[b:n]) + (\" [SEP_i]\" if i!=n_of_parts-1 else \"\")\n",
                "            b = n-1\n",
                "        \n",
                "        \n",
                "    # normalizer = eval(f\"slg.syntagmatic.tokenizer.normalizers.Sequence({semiotic.config.vocabulary.normalizer})\")\n",
                "    \n",
                "    if parallel:\n",
                "        \n",
                "        par_corpus = parallel_chain(corpus[:corpus_length], cpu_count)\n",
                "\n",
                "        result = slg.util.multiprocessing_tqdm(partial(semiotic.vocab.chain_list_alpha, normalizer), par_corpus, cores=cpu_count, desc=\"Normalize & Alphabet\")\n",
                "        \n",
                "        chain_list = []\n",
                "        alphabet = Counter()\n",
                "        for chain_l, alpha in result:\n",
                "            chain_list += chain_l\n",
                "            alphabet += alpha\n",
                "            \n",
                "    else:\n",
                "        chain_list, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train[:corpus_length], progress_bar=True)\n",
                "\n",
                "    # cl, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train, progress_bar=True)\n",
                "    cl_chain = \"[SEP] \"+\" \".join(chain_list)+\" [SEP]\"\n",
                "    encode = {k:i for i,(k,v) in enumerate(alphabet.most_common())}\n",
                "    decode = {i:k for k,i in encode.items()}\n",
                "    new_i = len(encode)\n",
                "    if parallel:\n",
                "        \n",
                "        par_chain = parallel_chain(chain_list, cpu_count, overlap=1)\n",
                "        \n",
                "        result = slg.util.multiprocessing(find_best_pair, par_chain, cores=cpu_count) \n",
                "                            \n",
                "        pairs = reduce(operator.add, result)\n",
                "        pairs = pairs.most_common()\n",
                "        \n",
                "    else:\n",
                "        pairs = find_best_pair(chain_list).most_common()\n",
                "    if voc_final_length<0:\n",
                "        voc_final_length = new_i + abs(voc_final_length)\n",
                "        \n",
                "    if sparse:\n",
                "        data, rows, columns = extract_drc(pairs,encode)\n",
                "        voc_matrix = coo_matrix((np.array(data), (np.array(rows),np.array(columns))), shape=(voc_final_length, voc_final_length), dtype=int)\n",
                "\n",
                "    else:\n",
                "        voc_matrix = np.zeros((voc_final_length, voc_final_length), dtype=int)\n",
                "        for (row,column),value in pairs:\n",
                "            voc_matrix[encode[row], encode[column]] = value\n",
                "    merges = []\n",
                "    delta_voc = voc_final_length - new_i\n",
                "    best_pair = \"init\"\n",
                "    pair_count = \"---\"\n",
                "\n",
                "    t = trange(delta_voc) #, disable = not progress_bar)\n",
                "\n",
                "    for _ in t:\n",
                "        t.set_description(f\"Pair: {best_pair}, {pair_count}\")\n",
                "        t.refresh()\n",
                "\n",
                "        if sparse:\n",
                "            max_i = voc_matrix.data.argmax()\n",
                "            pair_row = voc_matrix.row[max_i]\n",
                "            pair_col = voc_matrix.col[max_i]\n",
                "            pair_count = voc_matrix.data[max_i]\n",
                "        else:\n",
                "            pair_row,pair_col = np.unravel_index(np.argmax(voc_matrix, axis=None), voc_matrix.shape)\n",
                "            pair_count = voc_matrix[pair_row,pair_col]\n",
                "        \n",
                "        if pair_count == 0:\n",
                "            break\n",
                "\n",
                "        best_pair = (decode[pair_row], decode[pair_col])\n",
                "        best_pair_string = \" \".join(best_pair)\n",
                "        merges.append(best_pair_string)\n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        re_voc_l = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\"\\[SEP\\] \",\"\\[SEP_i\\] \"])+\")\"\n",
                "        re_voc_r = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\" \\[SEP\\]\",\" \\[SEP_i\\]\"])+\")\"\n",
                "        if parallel:\n",
                "            result = slg.util.multiprocessing(\n",
                "                partial(findall_contexts,best_pair_string=best_pair_string,re_voc_l=re_voc_l,re_voc_r=re_voc_r),\n",
                "                separate_chain(cl_chain.split(), cpu_count, list(best_pair)),\n",
                "                cores = cpu_count\n",
                "                )\n",
                "            merge_context = reduce(operator.add, result)\n",
                "        else:\n",
                "            merge_context = re.findall(re_voc_l+best_pair_string+re_voc_r, cl_chain, overlapped=True)\n",
                "        merge_context_count_l = Counter()\n",
                "        merge_context_count_r = Counter()\n",
                "        for l,r in merge_context:\n",
                "            if \"[SEP]\" not in l:\n",
                "                merge_context_count_l[encode[l.strip()]] += 1\n",
                "            if \"[SEP]\" not in r:\n",
                "                merge_context_count_r[encode[r.strip()]] += 1\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix to CSR or LIL, for item attribution and arithmetic \n",
                "            if sparse_mode == \"csr\":\n",
                "                voc_matrix = voc_matrix.tocsr()\n",
                "            else:\n",
                "                voc_matrix = voc_matrix.tolil()\n",
                "        \n",
                "        for row,key in merge_context_count_l.items():\n",
                "            voc_matrix[row,new_i] = key\n",
                "            \n",
                "        for column,key in merge_context_count_r.items():\n",
                "            voc_matrix[new_i,column] = key\n",
                "\n",
                "        # Correct previous counts\n",
                "        \n",
                "        # compute #(l,r)-(l,r)\n",
                "        pair_pair_count = len(re.findall(\" \"+best_pair_string+\" \"+best_pair_string+\" \", cl_chain, overlapped=False))\n",
                "        # remove #(l,r)-(l,r) from (l,r)-l\n",
                "        voc_matrix[new_i,pair_row] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-(l,r)\n",
                "        voc_matrix[pair_col,new_i] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-l\n",
                "        voc_matrix[pair_col,pair_row] -= pair_pair_count\n",
                "        # substract (l,r)- from r-\n",
                "        voc_matrix[pair_col,:new_i] -= voc_matrix[new_i,:new_i]\n",
                "        # substract -(l,r)- from -l\n",
                "        voc_matrix[:new_i,pair_row] -= voc_matrix[:new_i,new_i]\n",
                "        \n",
                "        # set l-r to 0\n",
                "        voc_matrix[pair_row,pair_col] = 0\n",
                "        # register #(l,r)-(l,r)\n",
                "        voc_matrix[new_i,new_i] = pair_pair_count\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix back to COO, to restart the loop\n",
                "            voc_matrix = voc_matrix.tocoo()\n",
                "        \n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        encode[best_pair_string_voc] = new_i\n",
                "        decode[new_i] = best_pair_string_voc\n",
                "        new_i += 1\n",
                "        cl_chain = agglutinate_chain(best_pair_string.split(),cl_chain)\n",
                "\n",
                "\n",
                "    if sparse:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()[0]\n",
                "    else:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()\n",
                "    vocabulary = {decode[i]:v for i,v in enumerate(freq_values) if v>0} # Make sure dimension of matrix and size of voc coincide\n",
                "    vocabulary = sorted(vocabulary.items(), key=lambda x: x[1], reverse=True)\n",
                "    \n",
                "    return merges, vocabulary"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "def build_nb_new(\n",
                "    corpus = None,\n",
                "    voc_final_length = -30,\n",
                "    # save = False,\n",
                "    # save_step = None,\n",
                "    # progress_bar = True,\n",
                "    # resume_merges = False,\n",
                "    parallel = False,\n",
                "    sparse = True,\n",
                "    sparse_mode = \"csr\",\n",
                "    cpu_count = 4,\n",
                "    corpus_length = None,\n",
                "    normalizer = None,\n",
                "):\n",
                "    def agglutinate_chain(pair, cl_chain):\n",
                "        bigram = re.escape(\" \".join(pair))\n",
                "        p = re.compile(r\"(?<!\\S)\" + bigram + r\"(?!\\S)\")\n",
                "        cl_chain = p.sub(\"\".join(pair), cl_chain)\n",
                "        return cl_chain\n",
                "\n",
                "    def extract_drc(pairs, encoder: dict):\n",
                "        data = []\n",
                "        rows = []\n",
                "        columns = []\n",
                "        for (r,c),d in pairs:\n",
                "            data.append(d)\n",
                "            rows.append(encoder[r])\n",
                "            columns.append(encoder[c])\n",
                "        return data, rows, columns\n",
                "\n",
                "    def parallel_chain(chain, n_of_parts, overlap = 0):\n",
                "        \"\"\"\n",
                "        Breaks the chain in n chunks to compute best pair of terms. Chunks are overlapping by one term, so as no pair of terms is lost due to the break.\n",
                "        \"\"\"\n",
                "        if not isinstance(chain,list):\n",
                "            chain = list(chain)\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        for i in range(0, len(chain), chunk_size):\n",
                "            yield chain[i : i + chunk_size + overlap]\n",
                "\n",
                "    def separate_chain(chain, n_of_parts, best_pair: list):\n",
                "        \"\"\"\n",
                "        Separate a chain (in list form) for parallel processing of regex findall of pair, taking care that the cuts of the chunks don't fall in the neiborhood of the pair, affecting the final counts\n",
                "        \"\"\"\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        b = 0\n",
                "        n = chunk_size\n",
                "        chain_len = len(chain)\n",
                "        for i in range(n_of_parts):\n",
                "            n = (i+1)*chunk_size\n",
                "            if chain_len > n:\n",
                "                while chain[n-2:n] == best_pair or chain[n-1:n+1] == best_pair:\n",
                "                    n = n+1\n",
                "            yield chain[b:n]\n",
                "            b = n-1\n",
                "        \n",
                "        \n",
                "    # normalizer = eval(f\"slg.syntagmatic.tokenizer.normalizers.Sequence({semiotic.config.vocabulary.normalizer})\")\n",
                "    \n",
                "    if parallel:\n",
                "        \n",
                "        par_corpus = parallel_chain(corpus[:corpus_length], cpu_count)\n",
                "\n",
                "        result = slg.util.multiprocessing_tqdm(partial(semiotic.vocab.chain_list_alpha, normalizer), par_corpus, cores=cpu_count, desc=\"Normalize & Alphabet\")\n",
                "        \n",
                "        chain_list = []\n",
                "        alphabet = Counter()\n",
                "        for chain_l, alpha in result:\n",
                "            chain_list += chain_l\n",
                "            alphabet += alpha\n",
                "            \n",
                "    else:\n",
                "        chain_list, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train[:corpus_length], progress_bar=True)\n",
                "\n",
                "    # cl, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train, progress_bar=True)\n",
                "    # cl_chain = \"[SEP] \"+\" \".join(chain_list)+\" [SEP]\"\n",
                "    cl_chain = \" \".join(chain_list)\n",
                "    encode = {k:i for i,(k,v) in enumerate(alphabet.most_common())}\n",
                "    decode = {i:k for k,i in encode.items()}\n",
                "    new_i = len(encode)\n",
                "    if parallel:\n",
                "        \n",
                "        par_chain = parallel_chain(chain_list, cpu_count, overlap=1)\n",
                "        \n",
                "        result = slg.util.multiprocessing(find_best_pair, par_chain, cores=cpu_count) \n",
                "                            \n",
                "        pairs = reduce(operator.add, result)\n",
                "        pairs = pairs.most_common()\n",
                "        \n",
                "    else:\n",
                "        pairs = find_best_pair(chain_list).most_common()\n",
                "    if voc_final_length<0:\n",
                "        voc_final_length = new_i + abs(voc_final_length)\n",
                "        \n",
                "    if sparse:\n",
                "        data, rows, columns = extract_drc(pairs,encode)\n",
                "        voc_matrix = coo_matrix((np.array(data), (np.array(rows),np.array(columns))), shape=(voc_final_length, voc_final_length), dtype=int)\n",
                "\n",
                "    else:\n",
                "        voc_matrix = np.zeros((voc_final_length, voc_final_length), dtype=int)\n",
                "        for (row,column),value in pairs:\n",
                "            voc_matrix[encode[row], encode[column]] = value\n",
                "    merges = []\n",
                "    delta_voc = voc_final_length - new_i\n",
                "    best_pair = \"init\"\n",
                "    pair_count = \"---\"\n",
                "\n",
                "    t = trange(delta_voc) #, disable = not progress_bar)\n",
                "\n",
                "    for _ in t:\n",
                "        t.set_description(f\"Pair: {best_pair}, {pair_count}\")\n",
                "        t.refresh()\n",
                "\n",
                "        if sparse:\n",
                "            max_i = voc_matrix.data.argmax()\n",
                "            pair_row = voc_matrix.row[max_i]\n",
                "            pair_col = voc_matrix.col[max_i]\n",
                "            pair_count = voc_matrix.data[max_i]\n",
                "        else:\n",
                "            pair_row,pair_col = np.unravel_index(np.argmax(voc_matrix, axis=None), voc_matrix.shape)\n",
                "            pair_count = voc_matrix[pair_row,pair_col]\n",
                "        \n",
                "        if pair_count == 0:\n",
                "            break\n",
                "\n",
                "        best_pair = (decode[pair_row], decode[pair_col])\n",
                "        best_pair_string = \" \".join(best_pair)\n",
                "        merges.append(best_pair_string)\n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        # re_voc_l = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\"\\[SEP\\] \",\"\\[SEP_i\\] \"])+\")\"\n",
                "        # re_voc_r = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\" \\[SEP\\]\",\" \\[SEP_i\\]\"])+\")\"\n",
                "        if parallel:\n",
                "            result = slg.util.multiprocessing(\n",
                "                partial(findall_contexts_list,best_pair=best_pair,encode=encode),\n",
                "                separate_chain(chain_list, cpu_count, list(best_pair)),\n",
                "                cores = cpu_count\n",
                "                )\n",
                "            merge_context_count_l = Counter()\n",
                "            merge_context_count_r = Counter()\n",
                "            pair_pair_count = 0\n",
                "            for merge_l, merge_r, ppcount in result:\n",
                "                merge_context_count_l += merge_l\n",
                "                merge_context_count_r += merge_r\n",
                "                pair_pair_count += ppcount\n",
                "        else:\n",
                "            merge_context_count_l, merge_context_count_r, pair_pair_count = findall_contexts_list(chain_list,best_pair,encode)\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix to CSR or LIL, for item attribution and arithmetic \n",
                "            if sparse_mode == \"csr\":\n",
                "                voc_matrix = voc_matrix.tocsr()\n",
                "            else:\n",
                "                voc_matrix = voc_matrix.tolil()\n",
                "        \n",
                "        for row,key in merge_context_count_l.items():\n",
                "            voc_matrix[row,new_i] = key\n",
                "            \n",
                "        for column,key in merge_context_count_r.items():\n",
                "            voc_matrix[new_i,column] = key\n",
                "\n",
                "        # Correct previous counts\n",
                "        \n",
                "        # # compute #(l,r)-(l,r)\n",
                "        # pair_pair_count = len(re.findall(\" \"+best_pair_string+\" \"+best_pair_string+\" \", cl_chain, overlapped=False))\n",
                "        # remove #(l,r)-(l,r) from (l,r)-l\n",
                "        voc_matrix[new_i,pair_row] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-(l,r)\n",
                "        voc_matrix[pair_col,new_i] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-l\n",
                "        voc_matrix[pair_col,pair_row] -= pair_pair_count\n",
                "        # substract (l,r)- from r-\n",
                "        voc_matrix[pair_col,:new_i] -= voc_matrix[new_i,:new_i]\n",
                "        # substract -(l,r)- from -l\n",
                "        voc_matrix[:new_i,pair_row] -= voc_matrix[:new_i,new_i]\n",
                "        \n",
                "        # set l-r to 0\n",
                "        voc_matrix[pair_row,pair_col] = 0\n",
                "        # register #(l,r)-(l,r)\n",
                "        voc_matrix[new_i,new_i] = pair_pair_count\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix back to COO, to restart the loop\n",
                "            voc_matrix = voc_matrix.tocoo()\n",
                "        \n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        encode[best_pair_string_voc] = new_i\n",
                "        decode[new_i] = best_pair_string_voc\n",
                "        new_i += 1\n",
                "        cl_chain = agglutinate_chain(best_pair_string.split(),cl_chain)\n",
                "        chain_list = cl_chain.split()\n",
                "\n",
                "\n",
                "    if sparse:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()[0]\n",
                "    else:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()\n",
                "    vocabulary = {decode[i]:v for i,v in enumerate(freq_values) if v>0} # Make sure dimension of matrix and size of voc coincide\n",
                "    vocabulary = sorted(vocabulary.items(), key=lambda x: x[1], reverse=True)\n",
                "    \n",
                "    return merges, vocabulary"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "normalizer = slg.syntagmatic.tokenizer.normalizers.Sequence(semiotic.config.vocabulary.normalizer)\n",
                "    \n",
                "profile = Profiler()\n",
                "profile.start()\n",
                "\n",
                "merges, vocabulary = build_nb(\n",
                "    semiotic.corpus.train,\n",
                "    normalizer=normalizer,\n",
                "    voc_final_length = -30,\n",
                "    parallel=True)\n",
                "\n",
                "profile.stop()\n",
                "print(profile.output_text(unicode=True, color=True))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "c820850d582c4ac5b1a004f5f5e5bd07"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "478defa37e974281b8ea1987e2b966ef"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "\n",
                        "  _     ._   __/__   _ _  _  _ _/_   Recorded: 17:12:21  Samples:  7290\n",
                        " /_//_/// /_\\ / //_// / //_'/ //     Duration: 104.636   CPU time: 61.937\n",
                        "/   _/                      v3.4.2\n",
                        "\n",
                        "Program: ipykernel_launcher --ip=127.0.0.1 --stdin=9018 --control=9016 --hb=9015 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"94d087ff-ccf2-43bf-b73b-54902b508d73\" --shell=9017 --transport=\"tcp\" --iopub=9019 --f=/var/folders/k4/tv2m69x552l9grwtcdhc0zxm0000gn/T/tmp-13680qAjBPdIXB0BA.json\n",
                        "\n",
                        "\u001b[31m104.636\u001b[0m run_code\u001b[0m  \u001b[2mIPython/core/interactiveshell.py:3400\u001b[0m\n",
                        "└─ \u001b[31m104.636\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m<ipython-input-8-9f56a99ed05b>:6\u001b[0m\n",
                        "   └─ \u001b[31m104.563\u001b[0m \u001b[48;5;24m\u001b[38;5;15mbuild_nb\u001b[0m  \u001b[2m<ipython-input-5-fd4ee32eb418>:1\u001b[0m\n",
                        "      ├─ \u001b[31m69.834\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing\u001b[0m  \u001b[2msemiolog/util.py:58\u001b[0m\n",
                        "      │  ├─ \u001b[33m42.395\u001b[0m __exit__\u001b[0m  \u001b[2mconcurrent/futures/_base.py:635\u001b[0m\n",
                        "      │  │     [17 frames hidden]  \u001b[2mconcurrent, threading, <built-in>, mu...\u001b[0m\n",
                        "      │  │        \u001b[33m41.545\u001b[0m lock.acquire\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  └─ \u001b[33m27.430\u001b[0m map\u001b[0m  \u001b[2mconcurrent/futures/process.py:702\u001b[0m\n",
                        "      │        [139 frames hidden]  \u001b[2mconcurrent, multiprocessing, <built-i...\u001b[0m\n",
                        "      │           \u001b[33m25.188\u001b[0m _get_chunks\u001b[0m  \u001b[2mconcurrent/futures/process.py:183\u001b[0m\n",
                        "      │           ├─ \u001b[32m19.896\u001b[0m \u001b[48;5;24m\u001b[38;5;15mseparate_chain\u001b[0m  \u001b[2m<ipython-input-5-fd4ee32eb418>:41\u001b[0m\n",
                        "      │           │  ├─ \u001b[32m11.845\u001b[0m str.join\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │           │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      │           │  └─ \u001b[32m8.051\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "      ├─ \u001b[32m13.988\u001b[0m str.split\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ├─ \u001b[32m6.540\u001b[0m \u001b[48;5;24m\u001b[38;5;15magglutinate_chain\u001b[0m  \u001b[2m<ipython-input-5-fd4ee32eb418>:15\u001b[0m\n",
                        "      │  └─ \u001b[32m6.525\u001b[0m Pattern.sub\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ├─ \u001b[32m5.377\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing_tqdm\u001b[0m  \u001b[2msemiolog/util.py:71\u001b[0m\n",
                        "      │  └─ \u001b[92m\u001b[2m4.639\u001b[0m __iter__\u001b[0m  \u001b[2mtqdm/notebook.py:226\u001b[0m\n",
                        "      │        [44 frames hidden]  \u001b[2mtqdm, concurrent, threading, <built-i...\u001b[0m\n",
                        "      ├─ \u001b[92m\u001b[2m3.643\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "      ├─ \u001b[92m\u001b[2m1.909\u001b[0m __setitem__\u001b[0m  \u001b[2mscipy/sparse/_index.py:75\u001b[0m\n",
                        "      │     [317 frames hidden]  \u001b[2mscipy, <built-in>, numpy, <__array_fu...\u001b[0m\n",
                        "      └─ \u001b[92m\u001b[2m1.290\u001b[0m findall\u001b[0m  \u001b[2mregex/regex.py:331\u001b[0m\n",
                        "            [27 frames hidden]  \u001b[2mregex, <built-in>, locale\u001b[0m\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "normalizer = slg.syntagmatic.tokenizer.normalizers.Sequence(semiotic.config.vocabulary.normalizer)\n",
                "    \n",
                "profile = Profiler()\n",
                "profile.start()\n",
                "\n",
                "merges_new, vocabulary_new = build_nb_new(\n",
                "    semiotic.corpus.train,\n",
                "    normalizer=normalizer,\n",
                "    voc_final_length = -30,\n",
                "    parallel=True)\n",
                "\n",
                "profile.stop()\n",
                "print(profile.output_text(unicode=True, color=True))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "d82e66a0c82740b5b6de3bc38b4a225b"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "e770569fd9c24127a2779768c086340d"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "\n",
                        "  _     ._   __/__   _ _  _  _ _/_   Recorded: 16:20:18  Samples:  3318\n",
                        " /_//_/// /_\\ / //_// / //_'/ //     Duration: 121.256   CPU time: 80.848\n",
                        "/   _/                      v3.4.2\n",
                        "\n",
                        "Program: ipykernel_launcher --ip=127.0.0.1 --stdin=9018 --control=9016 --hb=9015 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"4f3bce2f-170f-493c-8a3b-6232354de0d2\" --shell=9017 --transport=\"tcp\" --iopub=9019 --f=/var/folders/k4/tv2m69x552l9grwtcdhc0zxm0000gn/T/tmp-13680rVHW7F2zrHlL.json\n",
                        "\n",
                        "\u001b[31m121.255\u001b[0m run_code\u001b[0m  \u001b[2mIPython/core/interactiveshell.py:3400\u001b[0m\n",
                        "└─ \u001b[31m121.255\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m<ipython-input-13-46b97c605aec>:6\u001b[0m\n",
                        "   └─ \u001b[31m120.944\u001b[0m \u001b[48;5;24m\u001b[38;5;15mbuild_nb_new\u001b[0m  \u001b[2m<ipython-input-6-0c1cfdc702da>:1\u001b[0m\n",
                        "      ├─ \u001b[31m79.738\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing\u001b[0m  \u001b[2msemiolog/util.py:58\u001b[0m\n",
                        "      │  ├─ \u001b[33m47.981\u001b[0m __exit__\u001b[0m  \u001b[2mconcurrent/futures/_base.py:635\u001b[0m\n",
                        "      │  │     [12 frames hidden]  \u001b[2mconcurrent, threading, <built-in>, mu...\u001b[0m\n",
                        "      │  │        \u001b[33m47.907\u001b[0m lock.acquire\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  └─ \u001b[33m31.724\u001b[0m map\u001b[0m  \u001b[2mconcurrent/futures/process.py:702\u001b[0m\n",
                        "      │        [162 frames hidden]  \u001b[2mconcurrent, multiprocessing, ipykerne...\u001b[0m\n",
                        "      │           \u001b[32m11.516\u001b[0m _get_chunks\u001b[0m  \u001b[2mconcurrent/futures/process.py:183\u001b[0m\n",
                        "      │           └─ \u001b[32m11.338\u001b[0m \u001b[48;5;24m\u001b[38;5;15mseparate_chain\u001b[0m  \u001b[2m<ipython-input-6-0c1cfdc702da>:44\u001b[0m\n",
                        "      ├─ \u001b[33m30.438\u001b[0m \u001b[48;5;24m\u001b[38;5;15magglutinate_chain\u001b[0m  \u001b[2m<ipython-input-6-0c1cfdc702da>:16\u001b[0m\n",
                        "      │  ├─ \u001b[32m13.181\u001b[0m str.split\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      │  ├─ \u001b[32m10.690\u001b[0m str.join\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      │  └─ \u001b[32m6.365\u001b[0m Pattern.sub\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ├─ \u001b[92m\u001b[2m5.435\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing_tqdm\u001b[0m  \u001b[2msemiolog/util.py:71\u001b[0m\n",
                        "      │  └─ \u001b[92m\u001b[2m4.557\u001b[0m __iter__\u001b[0m  \u001b[2mtqdm/notebook.py:226\u001b[0m\n",
                        "      │        [54 frames hidden]  \u001b[2mtqdm, concurrent, threading, <built-i...\u001b[0m\n",
                        "      ├─ \u001b[92m\u001b[2m3.174\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "      └─ \u001b[92m\u001b[2m1.834\u001b[0m __setitem__\u001b[0m  \u001b[2mscipy/sparse/_index.py:75\u001b[0m\n",
                        "            [332 frames hidden]  \u001b[2mscipy, <built-in>, <__array_function_...\u001b[0m\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "normalizer = slg.syntagmatic.tokenizer.normalizers.Sequence(semiotic.config.vocabulary.normalizer)\n",
                "    \n",
                "profile = Profiler()\n",
                "profile.start()\n",
                "\n",
                "merges_new, vocabulary_new = build_nb_new(\n",
                "    semiotic.corpus.train,\n",
                "    normalizer=normalizer,\n",
                "    voc_final_length = -30,\n",
                "    parallel=True)\n",
                "\n",
                "profile.stop()\n",
                "print(profile.output_text(unicode=True, color=True))"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "fec60eb9033e40b480b0676fe566ca04"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "6783276d2adc4f77a578960230a8eb81"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.9/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
                        "  self._set_intXint(row, col, x.flat[0])\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "\n",
                        "  _     ._   __/__   _ _  _  _ _/_   Recorded: 17:28:52  Samples:  3408\n",
                        " /_//_/// /_\\ / //_// / //_'/ //     Duration: 127.850   CPU time: 81.221\n",
                        "/   _/                      v3.4.2\n",
                        "\n",
                        "Program: ipykernel_launcher --ip=127.0.0.1 --stdin=9011 --control=9009 --hb=9008 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"ce9657c1-93ff-41b6-8450-89cff71102fd\" --shell=9010 --transport=\"tcp\" --iopub=9012 --f=/var/folders/k4/tv2m69x552l9grwtcdhc0zxm0000gn/T/tmp-13680vi5S5W5Rij3d.json\n",
                        "\n",
                        "\u001b[31m127.850\u001b[0m run_code\u001b[0m  \u001b[2mIPython/core/interactiveshell.py:3400\u001b[0m\n",
                        "└─ \u001b[31m127.850\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m<ipython-input-7-46b97c605aec>:6\u001b[0m\n",
                        "   └─ \u001b[31m127.518\u001b[0m \u001b[48;5;24m\u001b[38;5;15mbuild_nb_new\u001b[0m  \u001b[2m<ipython-input-6-d180641c9b6f>:1\u001b[0m\n",
                        "      ├─ \u001b[31m90.126\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing\u001b[0m  \u001b[2msemiolog/util.py:58\u001b[0m\n",
                        "      │  ├─ \u001b[33m55.105\u001b[0m __exit__\u001b[0m  \u001b[2mconcurrent/futures/_base.py:635\u001b[0m\n",
                        "      │  │     [7 frames hidden]  \u001b[2mconcurrent, threading, <built-in>\u001b[0m\n",
                        "      │  │        \u001b[33m55.047\u001b[0m lock.acquire\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  └─ \u001b[33m34.758\u001b[0m map\u001b[0m  \u001b[2mconcurrent/futures/process.py:702\u001b[0m\n",
                        "      │        [177 frames hidden]  \u001b[2mconcurrent, multiprocessing, ipykerne...\u001b[0m\n",
                        "      │           \u001b[32m12.392\u001b[0m _get_chunks\u001b[0m  \u001b[2mconcurrent/futures/process.py:183\u001b[0m\n",
                        "      │           └─ \u001b[32m12.229\u001b[0m \u001b[48;5;24m\u001b[38;5;15mseparate_chain\u001b[0m  \u001b[2m<ipython-input-6-d180641c9b6f>:41\u001b[0m\n",
                        "      ├─ \u001b[32m19.616\u001b[0m str.split\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ├─ \u001b[32m7.175\u001b[0m \u001b[48;5;24m\u001b[38;5;15magglutinate_chain\u001b[0m  \u001b[2m<ipython-input-6-d180641c9b6f>:15\u001b[0m\n",
                        "      │  └─ \u001b[32m7.172\u001b[0m Pattern.sub\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ├─ \u001b[92m\u001b[2m6.354\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing_tqdm\u001b[0m  \u001b[2msemiolog/util.py:71\u001b[0m\n",
                        "      │  └─ \u001b[92m\u001b[2m5.401\u001b[0m __iter__\u001b[0m  \u001b[2mtqdm/notebook.py:226\u001b[0m\n",
                        "      │        [57 frames hidden]  \u001b[2mtqdm, concurrent, threading, <built-i...\u001b[0m\n",
                        "      └─ \u001b[92m\u001b[2m2.534\u001b[0m __setitem__\u001b[0m  \u001b[2mscipy/sparse/_index.py:75\u001b[0m\n",
                        "            [351 frames hidden]  \u001b[2mscipy, <__array_function__ internals>...\u001b[0m\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "profile.stop()\n",
                "print(profile.output_text(unicode=True, color=True))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "  _     ._   __/__   _ _  _  _ _/_   Recorded: 16:53:33  Samples:  2232\n",
                        " /_//_/// /_\\ / //_// / //_'/ //     Duration: 62.016    CPU time: 5.339\n",
                        "/   _/                      v3.4.2\n",
                        "\n",
                        "Program: ipykernel_launcher --ip=127.0.0.1 --stdin=9018 --control=9016 --hb=9015 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"51502a65-9e8e-47b4-9af7-0744af68f09a\" --shell=9017 --transport=\"tcp\" --iopub=9019 --f=/var/folders/k4/tv2m69x552l9grwtcdhc0zxm0000gn/T/tmp-13680WCWKxqMwEp4H.json\n",
                        "\n",
                        "\u001b[31m62.016\u001b[0m _run_once\u001b[0m  \u001b[2masyncio/base_events.py:1815\u001b[0m\n",
                        "├─ \u001b[31m48.866\u001b[0m select\u001b[0m  \u001b[2mselectors.py:554\u001b[0m\n",
                        "│     [3 frames hidden]  \u001b[2mselectors, <built-in>\u001b[0m\n",
                        "│        \u001b[31m48.866\u001b[0m kqueue.control\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "└─ \u001b[33m13.149\u001b[0m _run\u001b[0m  \u001b[2masyncio/events.py:78\u001b[0m\n",
                        "      [199 frames hidden]  \u001b[2masyncio, tornado, ipykernel, IPython,...\u001b[0m\n",
                        "         \u001b[33m13.143\u001b[0m run_code\u001b[0m  \u001b[2mIPython/core/interactiveshell.py:3400\u001b[0m\n",
                        "         └─ \u001b[33m12.801\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m<ipython-input-7-46b97c605aec>:6\u001b[0m\n",
                        "            └─ \u001b[33m12.801\u001b[0m \u001b[48;5;24m\u001b[38;5;15mbuild_nb_new\u001b[0m  \u001b[2m<ipython-input-6-4ed4f9368b8c>:1\u001b[0m\n",
                        "               ├─ \u001b[32m5.471\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing_tqdm\u001b[0m  \u001b[2msemiolog/util.py:71\u001b[0m\n",
                        "               │  └─ \u001b[32m4.505\u001b[0m __iter__\u001b[0m  \u001b[2mtqdm/notebook.py:226\u001b[0m\n",
                        "               │        [55 frames hidden]  \u001b[2mtqdm, concurrent, threading, <built-i...\u001b[0m\n",
                        "               ├─ \u001b[32m5.207\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing\u001b[0m  \u001b[2msemiolog/util.py:58\u001b[0m\n",
                        "               │  ├─ \u001b[32m4.084\u001b[0m __exit__\u001b[0m  \u001b[2mconcurrent/futures/_base.py:635\u001b[0m\n",
                        "               │  │     [7 frames hidden]  \u001b[2mconcurrent, threading, <built-in>\u001b[0m\n",
                        "               │  └─ \u001b[92m\u001b[2m1.120\u001b[0m map\u001b[0m  \u001b[2mconcurrent/futures/process.py:702\u001b[0m\n",
                        "               │        [64 frames hidden]  \u001b[2mconcurrent, multiprocessing, ipykerne...\u001b[0m\n",
                        "               └─ \u001b[92m\u001b[2m1.868\u001b[0m \u001b[48;5;24m\u001b[38;5;15magglutinate_list\u001b[0m  \u001b[2mtemp.py:34\u001b[0m\n",
                        "                  └─ \u001b[92m\u001b[2m1.747\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "print(vocabulary == vocabulary_new)\n",
                "print(merges == merges_new)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "True\n",
                        "True\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}