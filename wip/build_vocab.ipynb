{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import os\n",
                "os.chdir(\"../\")\n",
                "\n",
                "import semiolog as slg\n",
                "\n",
                "semiotic = slg.Cenematic(\"fr_wiki\")\n",
                "\n",
                "import regex as re\n",
                "import numpy as np\n",
                "from collections import Counter\n",
                "from scipy.sparse import csr_matrix, lil_matrix, coo_matrix\n",
                "from tqdm.notebook import tqdm, trange\n",
                "from functools import partial\n",
                "from functools import reduce\n",
                "import operator\n",
                "\n",
                "from pyinstrument import Profiler\n",
                "import sys\n",
                "\n",
                "import time\n",
                "from pyinstrument import Profiler\n",
                "import sys\n",
                "\n",
                "from temp import findall_contexts, findall_contexts_list, find_best_pair, agglutinate_list\n",
                "\n",
                "def build_nb(\n",
                "    corpus = None,\n",
                "    voc_final_length = -30,\n",
                "    # save = False,\n",
                "    # save_step = None,\n",
                "    # progress_bar = True,\n",
                "    # resume_merges = False,\n",
                "    parallel = False,\n",
                "    sparse = True,\n",
                "    sparse_mode = \"csr\",\n",
                "    cpu_count = 4,\n",
                "    corpus_length = None,\n",
                "    normalizer = None,\n",
                "):\n",
                "    def agglutinate_chain(pair, cl_chain):\n",
                "        bigram = re.escape(\" \".join(pair))\n",
                "        p = re.compile(r\"(?<!\\S)\" + bigram + r\"(?!\\S)\")\n",
                "        cl_chain = p.sub(\"\".join(pair), cl_chain)\n",
                "        return cl_chain\n",
                "\n",
                "    def extract_drc(pairs, encoder: dict):\n",
                "        data = []\n",
                "        rows = []\n",
                "        columns = []\n",
                "        for (r,c),d in pairs:\n",
                "            data.append(d)\n",
                "            rows.append(encoder[r])\n",
                "            columns.append(encoder[c])\n",
                "        return data, rows, columns\n",
                "\n",
                "    def parallel_chain(chain, n_of_parts, overlap = 0):\n",
                "        \"\"\"\n",
                "        Breaks the chain in n chunks to compute best pair of terms. Chunks are overlapping by one term, so as no pair of terms is lost due to the break.\n",
                "        \"\"\"\n",
                "        if not isinstance(chain,list):\n",
                "            chain = list(chain)\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        for i in range(0, len(chain), chunk_size):\n",
                "            yield chain[i : i + chunk_size + overlap]\n",
                "\n",
                "    def separate_chain(chain, n_of_parts, best_pair: list):\n",
                "        \"\"\"\n",
                "        Separate a chain (in list form) for parallel processing of regex findall of pair, taking care that the cuts of the chunks don't fall in the neiborhood of the pair, affecting the final counts\n",
                "        \"\"\"\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        b = 0\n",
                "        n = chunk_size\n",
                "        chain_len = len(chain)\n",
                "        for i in range(n_of_parts):\n",
                "            n = (i+1)*chunk_size\n",
                "            if chain_len > n:\n",
                "                while chain[n-2:n] == best_pair or chain[n-1:n+1] == best_pair:\n",
                "                    n = n+1\n",
                "            yield (\"[SEP_i] \" if i!=0 else \"\") + \" \".join(chain[b:n]) + (\" [SEP_i]\" if i!=n_of_parts-1 else \"\")\n",
                "            b = n-1\n",
                "        \n",
                "        \n",
                "    # normalizer = eval(f\"slg.syntagmatic.tokenizer.normalizers.Sequence({semiotic.config.vocabulary.normalizer})\")\n",
                "    \n",
                "    if parallel:\n",
                "        \n",
                "        par_corpus = parallel_chain(corpus[:corpus_length], cpu_count)\n",
                "\n",
                "        result = slg.util.multiprocessing_tqdm(partial(semiotic.vocab.chain_list_alpha, normalizer), par_corpus, cores=cpu_count, desc=\"Normalize & Alphabet\")\n",
                "        \n",
                "        chain_list = []\n",
                "        alphabet = Counter()\n",
                "        for chain_l, alpha in result:\n",
                "            chain_list += chain_l\n",
                "            alphabet += alpha\n",
                "            \n",
                "    else:\n",
                "        chain_list, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train[:corpus_length], progress_bar=True)\n",
                "\n",
                "    # cl, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train, progress_bar=True)\n",
                "    cl_chain = \"[SEP] \"+\" \".join(chain_list)+\" [SEP]\"\n",
                "    encode = {k:i for i,(k,v) in enumerate(alphabet.most_common())}\n",
                "    decode = {i:k for k,i in encode.items()}\n",
                "    new_i = len(encode)\n",
                "    if parallel:\n",
                "        \n",
                "        par_chain = parallel_chain(chain_list, cpu_count, overlap=1)\n",
                "        \n",
                "        result = slg.util.multiprocessing(find_best_pair, par_chain, cores=cpu_count) \n",
                "                            \n",
                "        pairs = reduce(operator.add, result)\n",
                "        pairs = pairs.most_common()\n",
                "        \n",
                "    else:\n",
                "        pairs = find_best_pair(chain_list).most_common()\n",
                "    if voc_final_length<0:\n",
                "        voc_final_length = new_i + abs(voc_final_length)\n",
                "        \n",
                "    if sparse:\n",
                "        data, rows, columns = extract_drc(pairs,encode)\n",
                "        voc_matrix = coo_matrix((np.array(data), (np.array(rows),np.array(columns))), shape=(voc_final_length, voc_final_length), dtype=int)\n",
                "\n",
                "    else:\n",
                "        voc_matrix = np.zeros((voc_final_length, voc_final_length), dtype=int)\n",
                "        for (row,column),value in pairs:\n",
                "            voc_matrix[encode[row], encode[column]] = value\n",
                "    merges = []\n",
                "    delta_voc = voc_final_length - new_i\n",
                "    best_pair = \"init\"\n",
                "    pair_count = \"---\"\n",
                "\n",
                "    t = trange(delta_voc) #, disable = not progress_bar)\n",
                "\n",
                "    for _ in t:\n",
                "        t.set_description(f\"Pair: {best_pair}, {pair_count}\")\n",
                "        t.refresh()\n",
                "\n",
                "        if sparse:\n",
                "            max_i = voc_matrix.data.argmax()\n",
                "            pair_row = voc_matrix.row[max_i]\n",
                "            pair_col = voc_matrix.col[max_i]\n",
                "            pair_count = voc_matrix.data[max_i]\n",
                "        else:\n",
                "            pair_row,pair_col = np.unravel_index(np.argmax(voc_matrix, axis=None), voc_matrix.shape)\n",
                "            pair_count = voc_matrix[pair_row,pair_col]\n",
                "        \n",
                "        if pair_count == 0:\n",
                "            break\n",
                "\n",
                "        best_pair = (decode[pair_row], decode[pair_col])\n",
                "        best_pair_string = \" \".join(best_pair)\n",
                "        merges.append(best_pair_string)\n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        re_voc_l = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\"\\[SEP\\] \",\"\\[SEP_i\\] \"])+\")\"\n",
                "        re_voc_r = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\" \\[SEP\\]\",\" \\[SEP_i\\]\"])+\")\"\n",
                "        if parallel:\n",
                "            result = slg.util.multiprocessing(\n",
                "                partial(findall_contexts,best_pair_string=best_pair_string,re_voc_l=re_voc_l,re_voc_r=re_voc_r),\n",
                "                separate_chain(cl_chain.split(), cpu_count, list(best_pair)),\n",
                "                cores = cpu_count\n",
                "                )\n",
                "            merge_context = reduce(operator.add, result)\n",
                "        else:\n",
                "            merge_context = re.findall(re_voc_l+best_pair_string+re_voc_r, cl_chain, overlapped=True)\n",
                "        merge_context_count_l = Counter()\n",
                "        merge_context_count_r = Counter()\n",
                "        for l,r in merge_context:\n",
                "            if \"[SEP]\" not in l:\n",
                "                merge_context_count_l[encode[l.strip()]] += 1\n",
                "            if \"[SEP]\" not in r:\n",
                "                merge_context_count_r[encode[r.strip()]] += 1\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix to CSR or LIL, for item attribution and arithmetic \n",
                "            if sparse_mode == \"csr\":\n",
                "                voc_matrix = voc_matrix.tocsr()\n",
                "            else:\n",
                "                voc_matrix = voc_matrix.tolil()\n",
                "        \n",
                "        for row,key in merge_context_count_l.items():\n",
                "            voc_matrix[row,new_i] = key\n",
                "            \n",
                "        for column,key in merge_context_count_r.items():\n",
                "            voc_matrix[new_i,column] = key\n",
                "\n",
                "        # Correct previous counts\n",
                "        \n",
                "        # compute #(l,r)-(l,r)\n",
                "        pair_pair_count = len(re.findall(\" \"+best_pair_string+\" \"+best_pair_string+\" \", cl_chain, overlapped=False))\n",
                "        # remove #(l,r)-(l,r) from (l,r)-l\n",
                "        voc_matrix[new_i,pair_row] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-(l,r)\n",
                "        voc_matrix[pair_col,new_i] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-l\n",
                "        voc_matrix[pair_col,pair_row] -= pair_pair_count\n",
                "        # substract (l,r)- from r-\n",
                "        voc_matrix[pair_col,:new_i] -= voc_matrix[new_i,:new_i]\n",
                "        # substract -(l,r)- from -l\n",
                "        voc_matrix[:new_i,pair_row] -= voc_matrix[:new_i,new_i]\n",
                "        \n",
                "        # set l-r to 0\n",
                "        voc_matrix[pair_row,pair_col] = 0\n",
                "        # register #(l,r)-(l,r)\n",
                "        voc_matrix[new_i,new_i] = pair_pair_count\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix back to COO, to restart the loop\n",
                "            voc_matrix = voc_matrix.tocoo()\n",
                "        \n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        encode[best_pair_string_voc] = new_i\n",
                "        decode[new_i] = best_pair_string_voc\n",
                "        new_i += 1\n",
                "        cl_chain = agglutinate_chain(best_pair_string.split(),cl_chain)\n",
                "\n",
                "\n",
                "    if sparse:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()[0]\n",
                "    else:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()\n",
                "    vocabulary = {decode[i]:v for i,v in enumerate(freq_values) if v>0} # Make sure dimension of matrix and size of voc coincide\n",
                "    vocabulary = sorted(vocabulary.items(), key=lambda x: x[1], reverse=True)\n",
                "    \n",
                "    return merges, vocabulary\n",
                "\n",
                "normalizer = slg.syntagmatic.tokenizer.normalizers.Sequence(semiotic.config.vocabulary.normalizer)\n",
                "    \n",
                "profile = Profiler()\n",
                "profile.start()\n",
                "\n",
                "merges, vocabulary = build_nb(\n",
                "    semiotic.corpus.train,\n",
                "    normalizer=normalizer,\n",
                "    voc_final_length = -30,\n",
                "    parallel=True)\n",
                "\n",
                "profile.stop()\n",
                "print(profile.output_text(unicode=True, color=True))\n",
                "\n",
                "print(merges)\n",
                "\n",
                "print(vocabulary[:100])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Warning: models/fr_wiki/vocabulary/merges.txt does not exist.\n",
                        "Vocabulary will not be loaded from file.\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr‚Ä¶"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "c41bb4f5699444dca76f03a2168222f2"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "677a39982e4d4c8c9413f0bf39ae907b"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.9/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
                        "  self._set_intXint(row, col, x.flat[0])\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "\n",
                        "  _     ._   __/__   _ _  _  _ _/_   Recorded: 21:21:04  Samples:  6874\n",
                        " /_//_/// /_\\ / //_// / //_'/ //     Duration: 101.432   CPU time: 58.903\n",
                        "/   _/                      v3.4.2\n",
                        "\n",
                        "Program: ipykernel_launcher --ip=127.0.0.1 --stdin=9023 --control=9021 --hb=9020 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"251d6f1f-0330-4a4a-9983-8deb4d63e290\" --shell=9022 --transport=\"tcp\" --iopub=9024 --f=/var/folders/k4/tv2m69x552l9grwtcdhc0zxm0000gn/T/tmp-13680Zl7H7um2xFO2.json\n",
                        "\n",
                        "\u001b[31m101.433\u001b[0m run_code\u001b[0m  \u001b[2mIPython/core/interactiveshell.py:3400\u001b[0m\n",
                        "‚îî‚îÄ \u001b[31m101.433\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m<ipython-input-1-56e6f81fac91>:231\u001b[0m\n",
                        "   ‚îî‚îÄ \u001b[31m101.367\u001b[0m \u001b[48;5;24m\u001b[38;5;15mbuild_nb\u001b[0m  \u001b[2m<ipython-input-1-56e6f81fac91>:26\u001b[0m\n",
                        "      ‚îú‚îÄ \u001b[31m66.846\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing\u001b[0m  \u001b[2msemiolog/util.py:58\u001b[0m\n",
                        "      ‚îÇ  ‚îú‚îÄ \u001b[33m40.703\u001b[0m __exit__\u001b[0m  \u001b[2mconcurrent/futures/_base.py:635\u001b[0m\n",
                        "      ‚îÇ  ‚îÇ     [14 frames hidden]  \u001b[2mconcurrent, threading, <built-in>, mu...\u001b[0m\n",
                        "      ‚îÇ  ‚îÇ        \u001b[33m39.749\u001b[0m lock.acquire\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      ‚îÇ  ‚îî‚îÄ \u001b[33m26.130\u001b[0m map\u001b[0m  \u001b[2mconcurrent/futures/process.py:702\u001b[0m\n",
                        "      ‚îÇ        [147 frames hidden]  \u001b[2mconcurrent, multiprocessing, <built-i...\u001b[0m\n",
                        "      ‚îÇ           \u001b[33m23.922\u001b[0m _get_chunks\u001b[0m  \u001b[2mconcurrent/futures/process.py:183\u001b[0m\n",
                        "      ‚îÇ           ‚îú‚îÄ \u001b[32m18.711\u001b[0m \u001b[48;5;24m\u001b[38;5;15mseparate_chain\u001b[0m  \u001b[2m<ipython-input-1-56e6f81fac91>:66\u001b[0m\n",
                        "      ‚îÇ           ‚îÇ  ‚îú‚îÄ \u001b[32m11.078\u001b[0m str.join\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      ‚îÇ           ‚îÇ  ‚îÇ     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ‚îÇ           ‚îÇ  ‚îî‚îÄ \u001b[32m7.632\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "      ‚îú‚îÄ \u001b[32m13.300\u001b[0m str.split\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      ‚îÇ     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ‚îú‚îÄ \u001b[32m6.381\u001b[0m \u001b[48;5;24m\u001b[38;5;15magglutinate_chain\u001b[0m  \u001b[2m<ipython-input-1-56e6f81fac91>:40\u001b[0m\n",
                        "      ‚îÇ  ‚îî‚îÄ \u001b[32m6.362\u001b[0m Pattern.sub\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      ‚îÇ        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ‚îú‚îÄ \u001b[32m6.341\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing_tqdm\u001b[0m  \u001b[2msemiolog/util.py:71\u001b[0m\n",
                        "      ‚îÇ  ‚îî‚îÄ \u001b[32m5.381\u001b[0m __iter__\u001b[0m  \u001b[2mtqdm/notebook.py:226\u001b[0m\n",
                        "      ‚îÇ        [49 frames hidden]  \u001b[2mtqdm, concurrent, threading, <built-i...\u001b[0m\n",
                        "      ‚îú‚îÄ \u001b[92m\u001b[2m3.518\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "      ‚îú‚îÄ \u001b[92m\u001b[2m1.766\u001b[0m __setitem__\u001b[0m  \u001b[2mscipy/sparse/_index.py:75\u001b[0m\n",
                        "      ‚îÇ     [315 frames hidden]  \u001b[2mscipy, <built-in>, <__array_function_...\u001b[0m\n",
                        "      ‚îî‚îÄ \u001b[92m\u001b[2m1.150\u001b[0m findall\u001b[0m  \u001b[2mregex/regex.py:331\u001b[0m\n",
                        "            [17 frames hidden]  \u001b[2mregex, <built-in>, locale, _bootlocale\u001b[0m\n",
                        "\n",
                        "\n",
                        "['e s', 'e n', 'o n', 'd e', 'a n', 'l e', 'l a', 'r e', 't i', 'e r', 'i s', 'i n', 'u r', 'a r', 'q u', 'e t', 'en t', 'i t', 'u n', 'l es', 'o r', 'o u', 'a u', 'd es', 't e', 'i l', 'c h', 'a l', 'o m', 'ti on']\n",
                        "[('s', 701369), ('e', 671181), ('a', 649651), ('i', 613493), ('t', 590305), ('c', 526886), ('p', 497908), ('r', 475814), ('√©', 422979), ('m', 419721), ('o', 419278), ('d', 408639), ('l', 363233), ('u', 356109), ('es', 278522), ('de', 263697), ('an', 242143), ('g', 232012), ('v', 224262), ('le', 218298), ('en', 216870), ('on', 215662), ('la', 201302), ('f', 198180), ('n', 188543), ('re', 187768), ('b', 187737), ('er', 168797), ('is', 162890), ('in', 153777), ('ur', 149731), ('ar', 147341), ('qu', 127799), ('et', 123237), ('h', 116235), ('ent', 112765), ('ti', 111757), ('it', 109387), ('un', 107296), ('1', 106323), ('les', 104238), ('or', 101688), ('ou', 92865), ('au', 89885), ('des', 88776), ('te', 84979), ('il', 83865), ('ch', 83381), ('y', 79691), ('x', 77466), ('al', 77195), ('om', 74418), ('√†', 73672), ('tion', 72478), ('0', 71514), ('√®', 66540), ('9', 65768), ('j', 59196), ('2', 57157), ('k', 46887), ('8', 32822), ('w', 27586), ('3', 26276), ('z', 25807), ('7', 25588), ('5', 25550), ('4', 24803), ('6', 23762), ('√™', 16535), ('√ß', 11036), ('¬´', 9662), ('¬ª', 9385), ('√¥', 7920), ('√¢', 7716), ('√Æ', 6555), ('‚ñ°', 5034), ('√Ø', 4197), ('√π', 3839), ('≈ì', 3589), ('q', 2713), ('√ª', 2209), ('√°', 1639), ('¬∞', 1367), ('√º', 1160), ('√≠', 1095), ('√≥', 1079), ('√∂', 926), ('√´', 837), ('≈ç', 837), ('√§', 690), ('≈Ç', 474), ('‚Ä†', 461), ('≈°', 421), ('ƒá', 400), ('ƒç', 313), ('√±', 284), ('√£', 268), ('√∫', 228), ('√ó', 200), ('≈´', 188), ('ƒÅ', 186), ('√¶', 171), ('Œ±', 125), ('ÃÅ', 125), ('≈õ', 123), ('√•', 122), ('≈Ñ', 121), ('≈æ', 113), ('»ô', 112), ('ƒÉ', 101), ('√∏', 97), ('ƒ±', 97), ('‚Äú', 92), ('‚Äù', 91), (' º', 88), ('ƒô', 88), ('ƒÖ', 81), ('≈ü', 80), ('Àà', 78), ('√¨', 78), ('√ü', 76), ('√≤', 72), ('Œ∏', 72), ('Œπ', 71), ('‚Äò', 69), ('≈º', 69), ('Œø', 68), ('√Ω', 65), ('ƒõ', 64), ('ƒë', 64), ('ƒ´', 62), ('ŒΩ', 61), ('‚ôô', 60), ('œÑ', 58), ('œÉ', 58), ('‚àí', 58), ('‚Ç¨', 58), ('œÇ', 57), ('»õ', 55), ('œÅ', 53), ('Œº', 53), ('Œª', 53), ('…õ', 53), ('œÄ', 50), ('Œ¥', 50), ('≈ô', 48), ('≈∫', 47), ('‚Üí', 47), ('Œ∫', 43), ('…î', 42), ('Œ≥', 39), ('ƒì', 39), ('≈ë', 39), ('‚ôï', 38), ('Œµ', 37), ('œâ', 37), ('Œ≤', 36), ('¬ß', 36), ('‚Ä≤', 36), ('ƒü', 33), ('¬∑', 32), ('Õ°', 30), ('‚ÅÑ', 29), (' ª', 28), ('Œ∑', 27), ('√µ', 27), ('«é', 26), ('œÖ', 26), ('…ô', 24), ('„Äú', 23), ('·πÖ', 23), ('‡ºã', 23), ('≈à', 22), ('Àê', 22), ('ƒó', 20), ('ƒØ', 19), ('Ãá', 19), ('Œ¨', 18), ('√∞', 17), ('œå', 17), ('¬£', 16), ('√ø', 16), ('‚Ä∞', 16), ('¬±', 16), (' Ç', 15), ('œá', 15), ('ŒØ', 14), ('…®', 14), ('·π≠', 14), ('„Äã', 14), ('‡∏£', 13), ('„Ää', 13), ('Œ≠', 12), ('·∏•', 12), ('…ï', 11), ('«ê', 11), ('‡∏≤', 11), ('‡∏Å', 11), ('«ö', 10), ('·Éò', 10), ('‡Ωº', 10), ('√æ', 9), (' ø', 9), ('≈Ø', 9), ('‚à´', 9), ('ŒÆ', 9), ('ƒï', 9), ('‡∏ß', 8), ('·π£', 8), ('…æ', 8), ('œÜ', 8), ('‚âà', 8), ('…≤', 7), (' ê', 7), ('ƒæ', 7), ('≈£', 7), ('≈•', 7), ('‡∏±', 7), ('‡Ω¢', 7), ('‡∏á', 7), ('≈Ü', 7), ('¬°', 6), ('¬©', 6), ('‚òÜ', 6), ('œç', 6), ('¬ø', 6), ('«î', 6), ('‚Üî', 6), ('‡∏°', 6), ('‡ΩÇ', 6), ('·∫Ø', 6), ('·πá', 6), ('≈ã', 6), ('‚â§', 6), ('‚îÄ', 6), ('ƒß', 6), ('·Éê', 6), ('‚àà', 5), ('œé', 5), ('‚Äï', 5), ('Œ∂', 5), ('«í', 5), ('…°', 5), ('‚Äû', 5), ('∆í', 5), ('‡∏≠', 5), ('‡∏∏', 5), ('·äÄ', 5), ('‡∏∞', 5), ('‚Äê', 5), ('ÀÅ', 5), ('·∏´', 5), ('ƒ°', 5), ('‚àó', 5), ('‡Ωñ', 5), ('·ªã', 5), ('≈±', 4), ('·∫£', 4), ('·ªÖ', 4), ('·πÉ', 4), ('‚Ñû', 4), ('ÃÄ', 4), (' É', 4), ('·ºÄ', 4), ('‡∏ä', 4), ('‡∏´', 4), ('‡Ωì', 4), ('‡ΩÑ', 4), ('‡≥ç', 4), ('∆°', 4), ('‡∏•', 4), ('·∏ç', 4), ('‡πÅ', 4), ('·É°', 4), ('·ø∂', 4), ('‚ñà', 4), ('‚≤Å', 4), ('‚¥∞', 4), ('Ãì', 3), ('‚òÖ', 3), ('‚Äö', 3), ('‚áí', 3), ('·∫ø', 3), ('‡∏î', 3), ('‡∏¥', 3), ('·º∞', 3), ('‚â™', 3), ('·ªì', 3), ('‡∏ó', 3), ('‡Ω∫', 3), ('≈≠', 3), ('¬Æ', 3), ('‚ñº', 3), ('‡∏ï', 3), ('‡∏µ', 3), ('‡∏ö', 3), ('‚úù', 3), ('…í', 3), ('·Éî', 3), ('·Éö', 3), ('·É¢', 3), ('‡∫≤', 3), ('·∏≥', 3), ('ÃÑ', 3), ('·Éì', 3), ('‡Ωë', 3), ('·∫•', 3), ('·øñ', 2), ('·ºî', 2), ('·πõ', 2), ('‚àû', 2), ('·Éù', 2), ('·Éú', 2), ('‚â°', 2), (' Å', 2), ('Àå', 2), ('‚â´', 2), ('·∫±', 2), ('‡∏™', 2), ('‡∏Ç', 2), ('‡Ωê', 2), ('‡Ω¥', 2), ('‡Ω≤', 2), ('·ΩÅ', 2), ('‡Ω†', 2), ('‡Ω¶', 2), ('·äÑ', 2), ('‡Ωò', 2), ('≈©', 2), ('·äÉ', 2), ('‡≥ã', 2), ('‡≤∞', 2), ('‚îî', 2), ('·øÜ', 2), (' ë', 2), ('·ªá', 2), ('‡∏ô', 2), ('‡πÄ', 2), ('‡∏∂', 2), (' é', 2), ('…ë', 2), ('‚ãÖ', 2), ('·äÅ', 2), ('‡≤ï', 2), ('‡≤§', 2), ('‚îå', 2), ('‡æ±', 2), ('‡ΩÜ', 2), ('·ø¶', 2), ('·äá', 2), ('…ü', 2), (' ù', 2), ('·Éõ', 2), ('·É£', 2), ('‡ªâ', 2), ('‡πà', 2), ('ÀÄ', 2), ('Àã', 2), ('Œæ', 2), ('·äÇ', 2), ('·ªü', 2), ('·ªô', 2), ('‚áå', 2), ('«ß', 2), ('‚≤°', 2), ('‚≤É', 2), ('ÃÉ', 2), ('·πµ', 2), ('‚µî', 2), ('‚µ¢', 2), ('‚â•', 2), ('·Éë', 2), ('»ë', 2), (' Ä', 2), ('‡ØÅ', 2), ('Ãõ', 2), ('·ªç', 1), ('œà', 1), ('üßµ', 1), ('Ãî', 1), (' æ', 1), ('ƒè', 1), ('·äÜ', 1), ('ƒã', 1), ('·∫ì', 1), ('…™', 1), ('…ê', 1), ('‡∏ì', 1), ('·ä†', 1), ('·à≠', 1), ('·à≤', 1), ('·äê', 1), ('·åà', 1), ('·àå', 1), ('‡Ωß', 1), ('·º°', 1), ('‚±ò', 1), ('‡∏Ñ', 1), ('‡æ´', 1), ('‡ºç', 1), ('ÃØ', 1), ('·º±', 1), ('‚Äí', 1), ('‡Ωû', 1), ('‡Ωï', 1), ('‡Ω§', 1), ('‡æ©', 1), ('‚ôõ', 1), ('‡≤ó', 1), ('‡≤ü', 1), ('·∫≠', 1), ('·Ω∏', 1), ('∆∞', 1), ('‡πÉ', 1), ('‡∏à', 1), ('‡πÇ', 1), ('·êÖ', 1), ('‚áî', 1), ('ƒº', 1), ('·º∂', 1), ('‡≤≤', 1), ('‡≤æ', 1), ('‡≥Å', 1), ('‡≤¨', 1), ('‡≤¶', 1), ('‡≤®', 1), ('‡≤ø', 1), ('„Äå', 1), ('„Äç', 1), ('‡æí', 1), ('‡ΩÅ', 1), ('‚Üë', 1), ('‚Üì', 1), ('‡πä', 1), ('«ò', 1), ('‚ô≠', 1), ('·É©', 1), ('·ÉÆ', 1), ('·É†', 1), ('·É™', 1), ('·Éû', 1), ('„ÄÖ', 1), ('¬•', 1), ('‡∫ñ', 1), ('‡ªç', 1), ('‡∫ú', 1), ('‡∫Å', 1), ('‡∏ò', 1), ('‡πâ', 1), ('‡∏¢', 1), ('…£', 1), (' ä', 1), ('…µ', 1), ('„Äé', 1), ('„Äè', 1), ('„Ñç', 1), ('„Ñ®', 1), ('„Ñõ', 1), ('Àä', 1), ('„Ñ©', 1), ('Àá', 1), ('„Ññ', 1), ('„ÑÖ', 1), ('„Ñ†', 1), ('·ΩÄ', 1), ('·ø•', 1), ('·∫ß', 1), ('ƒ∑', 1), ('≈ó', 1), ('\\uf062', 1), ('·Ωê', 1), ('„ö§', 1), ('·ªπ', 1), ('·äÖ', 1), (' ï', 1), ('…ó', 1), ('‡∏õ', 1), ('·ªë', 1), ('‡∏ç', 1), ('‡Ωâ', 1), ('‚îÉ', 1), ('‚ãØ', 1), ('Ã±', 1), ('œ£', 1), ('‚≤â', 1), ('‚≤õ', 1), ('‚≤ü', 1), ('‚≤©', 1), ('œØ', 1), ('‚≤Ö', 1), ('ÃÖ', 1), ('·É•', 1), ('·É¶', 1), ('·Éß', 1), ('·Éï', 1), ('·º†', 1), ('‚¥∑', 1), ('‚µè', 1), ('‚µÑ', 1), ('‚µõ', 1), ('·ª´', 1), ('‡Ωö', 1), ('‡Ωî', 1), ('‡Ω£', 1), ('·Éô', 1), (' î', 1), ('‚àÄ', 1), (' í', 1), ('ƒ≠', 1), ('üëç', 1), ('‡æ≥', 1), ('‡Æï', 1), ('‡Æ¥', 1), ('‡Æ®', 1), ('‡Øç', 1), ('‡Æ§', 1), ('‡Øà', 1), ('‡Æè', 1), ('‡Æö', 1), ('·∫°', 1), ('œä', 1), ('≈∑', 1), ('‚ôû', 1)]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}