{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import os\n",
                "os.chdir(\"../\")\n",
                "\n",
                "import semiolog as slg\n",
                "\n",
                "semiotic = slg.Cenematic(\"fr_wiki\")\n",
                "\n",
                "import regex as re\n",
                "import numpy as np\n",
                "from collections import Counter\n",
                "from scipy.sparse import csr_matrix, lil_matrix, coo_matrix\n",
                "from tqdm.notebook import tqdm, trange\n",
                "from functools import partial\n",
                "from functools import reduce\n",
                "import operator\n",
                "\n",
                "from pyinstrument import Profiler\n",
                "import sys\n",
                "\n",
                "import time\n",
                "from pyinstrument import Profiler\n",
                "import sys\n",
                "\n",
                "from temp import findall_contexts, findall_contexts_list, find_best_pair, agglutinate_list\n",
                "\n",
                "def build_nb(\n",
                "    corpus = None,\n",
                "    voc_final_length = -30,\n",
                "    # save = False,\n",
                "    # save_step = None,\n",
                "    # progress_bar = True,\n",
                "    # resume_merges = False,\n",
                "    parallel = False,\n",
                "    sparse = True,\n",
                "    sparse_mode = \"csr\",\n",
                "    cpu_count = 4,\n",
                "    corpus_length = None,\n",
                "    normalizer = None,\n",
                "):\n",
                "    def agglutinate_chain(pair, cl_chain):\n",
                "        bigram = re.escape(\" \".join(pair))\n",
                "        p = re.compile(r\"(?<!\\S)\" + bigram + r\"(?!\\S)\")\n",
                "        cl_chain = p.sub(\"\".join(pair), cl_chain)\n",
                "        return cl_chain\n",
                "\n",
                "    def extract_drc(pairs, encoder: dict):\n",
                "        data = []\n",
                "        rows = []\n",
                "        columns = []\n",
                "        for (r,c),d in pairs:\n",
                "            data.append(d)\n",
                "            rows.append(encoder[r])\n",
                "            columns.append(encoder[c])\n",
                "        return data, rows, columns\n",
                "\n",
                "    def parallel_chain(chain, n_of_parts, overlap = 0):\n",
                "        \"\"\"\n",
                "        Breaks the chain in n chunks to compute best pair of terms. Chunks are overlapping by one term, so as no pair of terms is lost due to the break.\n",
                "        \"\"\"\n",
                "        if not isinstance(chain,list):\n",
                "            chain = list(chain)\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        for i in range(0, len(chain), chunk_size):\n",
                "            yield chain[i : i + chunk_size + overlap]\n",
                "\n",
                "    def separate_chain(chain, n_of_parts, best_pair: list):\n",
                "        \"\"\"\n",
                "        Separate a chain (in list form) for parallel processing of regex findall of pair, taking care that the cuts of the chunks don't fall in the neiborhood of the pair, affecting the final counts\n",
                "        \"\"\"\n",
                "        chunk_size = int(len(chain) / n_of_parts)+1\n",
                "        b = 0\n",
                "        n = chunk_size\n",
                "        chain_len = len(chain)\n",
                "        for i in range(n_of_parts):\n",
                "            n = (i+1)*chunk_size\n",
                "            if chain_len > n:\n",
                "                while chain[n-2:n] == best_pair or chain[n-1:n+1] == best_pair:\n",
                "                    n = n+1\n",
                "            yield (\"[SEP_i] \" if i!=0 else \"\") + \" \".join(chain[b:n]) + (\" [SEP_i]\" if i!=n_of_parts-1 else \"\")\n",
                "            b = n-1\n",
                "        \n",
                "        \n",
                "    # normalizer = eval(f\"slg.syntagmatic.tokenizer.normalizers.Sequence({semiotic.config.vocabulary.normalizer})\")\n",
                "    \n",
                "    if parallel:\n",
                "        \n",
                "        par_corpus = parallel_chain(corpus[:corpus_length], cpu_count)\n",
                "\n",
                "        result = slg.util.multiprocessing_tqdm(partial(semiotic.vocab.chain_list_alpha, normalizer), par_corpus, cores=cpu_count, desc=\"Normalize & Alphabet\")\n",
                "        \n",
                "        chain_list = []\n",
                "        alphabet = Counter()\n",
                "        for chain_l, alpha in result:\n",
                "            chain_list += chain_l\n",
                "            alphabet += alpha\n",
                "            \n",
                "    else:\n",
                "        chain_list, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train[:corpus_length], progress_bar=True)\n",
                "\n",
                "    # cl, alphabet = semiotic.vocab.chain_list_alpha(normalizer, semiotic.corpus.train, progress_bar=True)\n",
                "    cl_chain = \"[SEP] \"+\" \".join(chain_list)+\" [SEP]\"\n",
                "    encode = {k:i for i,(k,v) in enumerate(alphabet.most_common())}\n",
                "    decode = {i:k for k,i in encode.items()}\n",
                "    new_i = len(encode)\n",
                "    if parallel:\n",
                "        \n",
                "        par_chain = parallel_chain(chain_list, cpu_count, overlap=1)\n",
                "        \n",
                "        result = slg.util.multiprocessing(find_best_pair, par_chain, cores=cpu_count) \n",
                "                            \n",
                "        pairs = reduce(operator.add, result)\n",
                "        pairs = pairs.most_common()\n",
                "        \n",
                "    else:\n",
                "        pairs = find_best_pair(chain_list).most_common()\n",
                "    if voc_final_length<0:\n",
                "        voc_final_length = new_i + abs(voc_final_length)\n",
                "        \n",
                "    if sparse:\n",
                "        data, rows, columns = extract_drc(pairs,encode)\n",
                "        voc_matrix = coo_matrix((np.array(data), (np.array(rows),np.array(columns))), shape=(voc_final_length, voc_final_length), dtype=int)\n",
                "\n",
                "    else:\n",
                "        voc_matrix = np.zeros((voc_final_length, voc_final_length), dtype=int)\n",
                "        for (row,column),value in pairs:\n",
                "            voc_matrix[encode[row], encode[column]] = value\n",
                "    merges = []\n",
                "    delta_voc = voc_final_length - new_i\n",
                "    best_pair = \"init\"\n",
                "    pair_count = \"---\"\n",
                "\n",
                "    t = trange(delta_voc) #, disable = not progress_bar)\n",
                "\n",
                "    for _ in t:\n",
                "        t.set_description(f\"Pair: {best_pair}, {pair_count}\")\n",
                "        t.refresh()\n",
                "\n",
                "        if sparse:\n",
                "            max_i = voc_matrix.data.argmax()\n",
                "            pair_row = voc_matrix.row[max_i]\n",
                "            pair_col = voc_matrix.col[max_i]\n",
                "            pair_count = voc_matrix.data[max_i]\n",
                "        else:\n",
                "            pair_row,pair_col = np.unravel_index(np.argmax(voc_matrix, axis=None), voc_matrix.shape)\n",
                "            pair_count = voc_matrix[pair_row,pair_col]\n",
                "        \n",
                "        if pair_count == 0:\n",
                "            break\n",
                "\n",
                "        best_pair = (decode[pair_row], decode[pair_col])\n",
                "        best_pair_string = \" \".join(best_pair)\n",
                "        merges.append(best_pair_string)\n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        re_voc_l = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\"\\[SEP\\] \",\"\\[SEP_i\\] \"])+\")\"\n",
                "        re_voc_r = \"(\"+\"|\".join([\" \"+k+\" \" for k in encode.keys()]+[\" \\[SEP\\]\",\" \\[SEP_i\\]\"])+\")\"\n",
                "        if parallel:\n",
                "            result = slg.util.multiprocessing(\n",
                "                partial(findall_contexts,best_pair_string=best_pair_string,re_voc_l=re_voc_l,re_voc_r=re_voc_r),\n",
                "                separate_chain(cl_chain.split(), cpu_count, list(best_pair)),\n",
                "                cores = cpu_count\n",
                "                )\n",
                "            merge_context = reduce(operator.add, result)\n",
                "        else:\n",
                "            merge_context = re.findall(re_voc_l+best_pair_string+re_voc_r, cl_chain, overlapped=True)\n",
                "        merge_context_count_l = Counter()\n",
                "        merge_context_count_r = Counter()\n",
                "        for l,r in merge_context:\n",
                "            if \"[SEP]\" not in l:\n",
                "                merge_context_count_l[encode[l.strip()]] += 1\n",
                "            if \"[SEP]\" not in r:\n",
                "                merge_context_count_r[encode[r.strip()]] += 1\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix to CSR or LIL, for item attribution and arithmetic \n",
                "            if sparse_mode == \"csr\":\n",
                "                voc_matrix = voc_matrix.tocsr()\n",
                "            else:\n",
                "                voc_matrix = voc_matrix.tolil()\n",
                "        \n",
                "        for row,key in merge_context_count_l.items():\n",
                "            voc_matrix[row,new_i] = key\n",
                "            \n",
                "        for column,key in merge_context_count_r.items():\n",
                "            voc_matrix[new_i,column] = key\n",
                "\n",
                "        # Correct previous counts\n",
                "        \n",
                "        # compute #(l,r)-(l,r)\n",
                "        pair_pair_count = len(re.findall(\" \"+best_pair_string+\" \"+best_pair_string+\" \", cl_chain, overlapped=False))\n",
                "        # remove #(l,r)-(l,r) from (l,r)-l\n",
                "        voc_matrix[new_i,pair_row] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-(l,r)\n",
                "        voc_matrix[pair_col,new_i] -= pair_pair_count\n",
                "        # remove #(l,r)-(l,r) from r-l\n",
                "        voc_matrix[pair_col,pair_row] -= pair_pair_count\n",
                "        # substract (l,r)- from r-\n",
                "        voc_matrix[pair_col,:new_i] -= voc_matrix[new_i,:new_i]\n",
                "        # substract -(l,r)- from -l\n",
                "        voc_matrix[:new_i,pair_row] -= voc_matrix[:new_i,new_i]\n",
                "        \n",
                "        # set l-r to 0\n",
                "        voc_matrix[pair_row,pair_col] = 0\n",
                "        # register #(l,r)-(l,r)\n",
                "        voc_matrix[new_i,new_i] = pair_pair_count\n",
                "        \n",
                "        if sparse:\n",
                "            # Convert matrix back to COO, to restart the loop\n",
                "            voc_matrix = voc_matrix.tocoo()\n",
                "        \n",
                "        best_pair_string_voc = \"\".join(best_pair)\n",
                "        encode[best_pair_string_voc] = new_i\n",
                "        decode[new_i] = best_pair_string_voc\n",
                "        new_i += 1\n",
                "        cl_chain = agglutinate_chain(best_pair_string.split(),cl_chain)\n",
                "\n",
                "\n",
                "    if sparse:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()[0]\n",
                "    else:\n",
                "        freq_values = voc_matrix.sum(axis=1).T.tolist()\n",
                "    vocabulary = {decode[i]:v for i,v in enumerate(freq_values) if v>0} # Make sure dimension of matrix and size of voc coincide\n",
                "    vocabulary = sorted(vocabulary.items(), key=lambda x: x[1], reverse=True)\n",
                "    \n",
                "    return merges, vocabulary\n",
                "\n",
                "normalizer = slg.syntagmatic.tokenizer.normalizers.Sequence(semiotic.config.vocabulary.normalizer)\n",
                "    \n",
                "profile = Profiler()\n",
                "profile.start()\n",
                "\n",
                "merges, vocabulary = build_nb(\n",
                "    semiotic.corpus.train,\n",
                "    normalizer=normalizer,\n",
                "    voc_final_length = -30,\n",
                "    parallel=True)\n",
                "\n",
                "profile.stop()\n",
                "print(profile.output_text(unicode=True, color=True))\n",
                "\n",
                "print(merges)\n",
                "\n",
                "print(vocabulary[:100])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Warning: models/fr_wiki/vocabulary/merges.txt does not exist.\n",
                        "Vocabulary will not be loaded from file.\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, description='Normalize & Alphabet', max=4.0, style=ProgressStyle(descr…"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "c41bb4f5699444dca76f03a2168222f2"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "677a39982e4d4c8c9413f0bf39ae907b"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.9/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
                        "  self._set_intXint(row, col, x.flat[0])\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "\n",
                        "  _     ._   __/__   _ _  _  _ _/_   Recorded: 21:21:04  Samples:  6874\n",
                        " /_//_/// /_\\ / //_// / //_'/ //     Duration: 101.432   CPU time: 58.903\n",
                        "/   _/                      v3.4.2\n",
                        "\n",
                        "Program: ipykernel_launcher --ip=127.0.0.1 --stdin=9023 --control=9021 --hb=9020 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"251d6f1f-0330-4a4a-9983-8deb4d63e290\" --shell=9022 --transport=\"tcp\" --iopub=9024 --f=/var/folders/k4/tv2m69x552l9grwtcdhc0zxm0000gn/T/tmp-13680Zl7H7um2xFO2.json\n",
                        "\n",
                        "\u001b[31m101.433\u001b[0m run_code\u001b[0m  \u001b[2mIPython/core/interactiveshell.py:3400\u001b[0m\n",
                        "└─ \u001b[31m101.433\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m<ipython-input-1-56e6f81fac91>:231\u001b[0m\n",
                        "   └─ \u001b[31m101.367\u001b[0m \u001b[48;5;24m\u001b[38;5;15mbuild_nb\u001b[0m  \u001b[2m<ipython-input-1-56e6f81fac91>:26\u001b[0m\n",
                        "      ├─ \u001b[31m66.846\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing\u001b[0m  \u001b[2msemiolog/util.py:58\u001b[0m\n",
                        "      │  ├─ \u001b[33m40.703\u001b[0m __exit__\u001b[0m  \u001b[2mconcurrent/futures/_base.py:635\u001b[0m\n",
                        "      │  │     [14 frames hidden]  \u001b[2mconcurrent, threading, <built-in>, mu...\u001b[0m\n",
                        "      │  │        \u001b[33m39.749\u001b[0m lock.acquire\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │  └─ \u001b[33m26.130\u001b[0m map\u001b[0m  \u001b[2mconcurrent/futures/process.py:702\u001b[0m\n",
                        "      │        [147 frames hidden]  \u001b[2mconcurrent, multiprocessing, <built-i...\u001b[0m\n",
                        "      │           \u001b[33m23.922\u001b[0m _get_chunks\u001b[0m  \u001b[2mconcurrent/futures/process.py:183\u001b[0m\n",
                        "      │           ├─ \u001b[32m18.711\u001b[0m \u001b[48;5;24m\u001b[38;5;15mseparate_chain\u001b[0m  \u001b[2m<ipython-input-1-56e6f81fac91>:66\u001b[0m\n",
                        "      │           │  ├─ \u001b[32m11.078\u001b[0m str.join\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │           │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      │           │  └─ \u001b[32m7.632\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "      ├─ \u001b[32m13.300\u001b[0m str.split\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ├─ \u001b[32m6.381\u001b[0m \u001b[48;5;24m\u001b[38;5;15magglutinate_chain\u001b[0m  \u001b[2m<ipython-input-1-56e6f81fac91>:40\u001b[0m\n",
                        "      │  └─ \u001b[32m6.362\u001b[0m Pattern.sub\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
                        "      │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
                        "      ├─ \u001b[32m6.341\u001b[0m \u001b[48;5;24m\u001b[38;5;15mmultiprocessing_tqdm\u001b[0m  \u001b[2msemiolog/util.py:71\u001b[0m\n",
                        "      │  └─ \u001b[32m5.381\u001b[0m __iter__\u001b[0m  \u001b[2mtqdm/notebook.py:226\u001b[0m\n",
                        "      │        [49 frames hidden]  \u001b[2mtqdm, concurrent, threading, <built-i...\u001b[0m\n",
                        "      ├─ \u001b[92m\u001b[2m3.518\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
                        "      ├─ \u001b[92m\u001b[2m1.766\u001b[0m __setitem__\u001b[0m  \u001b[2mscipy/sparse/_index.py:75\u001b[0m\n",
                        "      │     [315 frames hidden]  \u001b[2mscipy, <built-in>, <__array_function_...\u001b[0m\n",
                        "      └─ \u001b[92m\u001b[2m1.150\u001b[0m findall\u001b[0m  \u001b[2mregex/regex.py:331\u001b[0m\n",
                        "            [17 frames hidden]  \u001b[2mregex, <built-in>, locale, _bootlocale\u001b[0m\n",
                        "\n",
                        "\n",
                        "['e s', 'e n', 'o n', 'd e', 'a n', 'l e', 'l a', 'r e', 't i', 'e r', 'i s', 'i n', 'u r', 'a r', 'q u', 'e t', 'en t', 'i t', 'u n', 'l es', 'o r', 'o u', 'a u', 'd es', 't e', 'i l', 'c h', 'a l', 'o m', 'ti on']\n",
                        "[('s', 701369), ('e', 671181), ('a', 649651), ('i', 613493), ('t', 590305), ('c', 526886), ('p', 497908), ('r', 475814), ('é', 422979), ('m', 419721), ('o', 419278), ('d', 408639), ('l', 363233), ('u', 356109), ('es', 278522), ('de', 263697), ('an', 242143), ('g', 232012), ('v', 224262), ('le', 218298), ('en', 216870), ('on', 215662), ('la', 201302), ('f', 198180), ('n', 188543), ('re', 187768), ('b', 187737), ('er', 168797), ('is', 162890), ('in', 153777), ('ur', 149731), ('ar', 147341), ('qu', 127799), ('et', 123237), ('h', 116235), ('ent', 112765), ('ti', 111757), ('it', 109387), ('un', 107296), ('1', 106323), ('les', 104238), ('or', 101688), ('ou', 92865), ('au', 89885), ('des', 88776), ('te', 84979), ('il', 83865), ('ch', 83381), ('y', 79691), ('x', 77466), ('al', 77195), ('om', 74418), ('à', 73672), ('tion', 72478), ('0', 71514), ('è', 66540), ('9', 65768), ('j', 59196), ('2', 57157), ('k', 46887), ('8', 32822), ('w', 27586), ('3', 26276), ('z', 25807), ('7', 25588), ('5', 25550), ('4', 24803), ('6', 23762), ('ê', 16535), ('ç', 11036), ('«', 9662), ('»', 9385), ('ô', 7920), ('â', 7716), ('î', 6555), ('□', 5034), ('ï', 4197), ('ù', 3839), ('œ', 3589), ('q', 2713), ('û', 2209), ('á', 1639), ('°', 1367), ('ü', 1160), ('í', 1095), ('ó', 1079), ('ö', 926), ('ë', 837), ('ō', 837), ('ä', 690), ('ł', 474), ('†', 461), ('š', 421), ('ć', 400), ('č', 313), ('ñ', 284), ('ã', 268), ('ú', 228), ('×', 200), ('ū', 188), ('ā', 186), ('æ', 171), ('α', 125), ('́', 125), ('ś', 123), ('å', 122), ('ń', 121), ('ž', 113), ('ș', 112), ('ă', 101), ('ø', 97), ('ı', 97), ('“', 92), ('”', 91), ('ʼ', 88), ('ę', 88), ('ą', 81), ('ş', 80), ('ˈ', 78), ('ì', 78), ('ß', 76), ('ò', 72), ('θ', 72), ('ι', 71), ('‘', 69), ('ż', 69), ('ο', 68), ('ý', 65), ('ě', 64), ('đ', 64), ('ī', 62), ('ν', 61), ('♙', 60), ('τ', 58), ('σ', 58), ('−', 58), ('€', 58), ('ς', 57), ('ț', 55), ('ρ', 53), ('μ', 53), ('λ', 53), ('ɛ', 53), ('π', 50), ('δ', 50), ('ř', 48), ('ź', 47), ('→', 47), ('κ', 43), ('ɔ', 42), ('γ', 39), ('ē', 39), ('ő', 39), ('♕', 38), ('ε', 37), ('ω', 37), ('β', 36), ('§', 36), ('′', 36), ('ğ', 33), ('·', 32), ('͡', 30), ('⁄', 29), ('ʻ', 28), ('η', 27), ('õ', 27), ('ǎ', 26), ('υ', 26), ('ə', 24), ('〜', 23), ('ṅ', 23), ('་', 23), ('ň', 22), ('ː', 22), ('ė', 20), ('į', 19), ('̇', 19), ('ά', 18), ('ð', 17), ('ό', 17), ('£', 16), ('ÿ', 16), ('‰', 16), ('±', 16), ('ʂ', 15), ('χ', 15), ('ί', 14), ('ɨ', 14), ('ṭ', 14), ('》', 14), ('ร', 13), ('《', 13), ('έ', 12), ('ḥ', 12), ('ɕ', 11), ('ǐ', 11), ('า', 11), ('ก', 11), ('ǚ', 10), ('ი', 10), ('ོ', 10), ('þ', 9), ('ʿ', 9), ('ů', 9), ('∫', 9), ('ή', 9), ('ĕ', 9), ('ว', 8), ('ṣ', 8), ('ɾ', 8), ('φ', 8), ('≈', 8), ('ɲ', 7), ('ʐ', 7), ('ľ', 7), ('ţ', 7), ('ť', 7), ('ั', 7), ('ར', 7), ('ง', 7), ('ņ', 7), ('¡', 6), ('©', 6), ('☆', 6), ('ύ', 6), ('¿', 6), ('ǔ', 6), ('↔', 6), ('ม', 6), ('ག', 6), ('ắ', 6), ('ṇ', 6), ('ŋ', 6), ('≤', 6), ('─', 6), ('ħ', 6), ('ა', 6), ('∈', 5), ('ώ', 5), ('―', 5), ('ζ', 5), ('ǒ', 5), ('ɡ', 5), ('„', 5), ('ƒ', 5), ('อ', 5), ('ุ', 5), ('ኀ', 5), ('ะ', 5), ('‐', 5), ('ˁ', 5), ('ḫ', 5), ('ġ', 5), ('∗', 5), ('བ', 5), ('ị', 5), ('ű', 4), ('ả', 4), ('ễ', 4), ('ṃ', 4), ('℞', 4), ('̀', 4), ('ʃ', 4), ('ἀ', 4), ('ช', 4), ('ห', 4), ('ན', 4), ('ང', 4), ('್', 4), ('ơ', 4), ('ล', 4), ('ḍ', 4), ('แ', 4), ('ს', 4), ('ῶ', 4), ('█', 4), ('ⲁ', 4), ('ⴰ', 4), ('̓', 3), ('★', 3), ('‚', 3), ('⇒', 3), ('ế', 3), ('ด', 3), ('ิ', 3), ('ἰ', 3), ('≪', 3), ('ồ', 3), ('ท', 3), ('ེ', 3), ('ŭ', 3), ('®', 3), ('▼', 3), ('ต', 3), ('ี', 3), ('บ', 3), ('✝', 3), ('ɒ', 3), ('ე', 3), ('ლ', 3), ('ტ', 3), ('າ', 3), ('ḳ', 3), ('̄', 3), ('დ', 3), ('ད', 3), ('ấ', 3), ('ῖ', 2), ('ἔ', 2), ('ṛ', 2), ('∞', 2), ('ო', 2), ('ნ', 2), ('≡', 2), ('ʁ', 2), ('ˌ', 2), ('≫', 2), ('ằ', 2), ('ส', 2), ('ข', 2), ('ཐ', 2), ('ུ', 2), ('ི', 2), ('ὁ', 2), ('འ', 2), ('ས', 2), ('ኄ', 2), ('མ', 2), ('ũ', 2), ('ኃ', 2), ('ೋ', 2), ('ರ', 2), ('└', 2), ('ῆ', 2), ('ʑ', 2), ('ệ', 2), ('น', 2), ('เ', 2), ('ึ', 2), ('ʎ', 2), ('ɑ', 2), ('⋅', 2), ('ኁ', 2), ('ಕ', 2), ('ತ', 2), ('┌', 2), ('ྱ', 2), ('ཆ', 2), ('ῦ', 2), ('ኇ', 2), ('ɟ', 2), ('ʝ', 2), ('მ', 2), ('უ', 2), ('້', 2), ('่', 2), ('ˀ', 2), ('ˋ', 2), ('ξ', 2), ('ኂ', 2), ('ở', 2), ('ộ', 2), ('⇌', 2), ('ǧ', 2), ('ⲡ', 2), ('ⲃ', 2), ('̃', 2), ('ṵ', 2), ('ⵔ', 2), ('ⵢ', 2), ('≥', 2), ('ბ', 2), ('ȑ', 2), ('ʀ', 2), ('ு', 2), ('̛', 2), ('ọ', 1), ('ψ', 1), ('🧵', 1), ('̔', 1), ('ʾ', 1), ('ď', 1), ('ኆ', 1), ('ċ', 1), ('ẓ', 1), ('ɪ', 1), ('ɐ', 1), ('ณ', 1), ('አ', 1), ('ር', 1), ('ሲ', 1), ('ነ', 1), ('ገ', 1), ('ሌ', 1), ('ཧ', 1), ('ἡ', 1), ('ⱘ', 1), ('ค', 1), ('ྫ', 1), ('།', 1), ('̯', 1), ('ἱ', 1), ('‒', 1), ('ཞ', 1), ('ཕ', 1), ('ཤ', 1), ('ྩ', 1), ('♛', 1), ('ಗ', 1), ('ಟ', 1), ('ậ', 1), ('ὸ', 1), ('ư', 1), ('ใ', 1), ('จ', 1), ('โ', 1), ('ᐅ', 1), ('⇔', 1), ('ļ', 1), ('ἶ', 1), ('ಲ', 1), ('ಾ', 1), ('ು', 1), ('ಬ', 1), ('ದ', 1), ('ನ', 1), ('ಿ', 1), ('「', 1), ('」', 1), ('ྒ', 1), ('ཁ', 1), ('↑', 1), ('↓', 1), ('๊', 1), ('ǘ', 1), ('♭', 1), ('ჩ', 1), ('ხ', 1), ('რ', 1), ('ც', 1), ('პ', 1), ('々', 1), ('¥', 1), ('ຖ', 1), ('ໍ', 1), ('ຜ', 1), ('ກ', 1), ('ธ', 1), ('้', 1), ('ย', 1), ('ɣ', 1), ('ʊ', 1), ('ɵ', 1), ('『', 1), ('』', 1), ('ㄍ', 1), ('ㄨ', 1), ('ㄛ', 1), ('ˊ', 1), ('ㄩ', 1), ('ˇ', 1), ('ㄖ', 1), ('ㄅ', 1), ('ㄠ', 1), ('ὀ', 1), ('ῥ', 1), ('ầ', 1), ('ķ', 1), ('ŗ', 1), ('\\uf062', 1), ('ὐ', 1), ('㚤', 1), ('ỹ', 1), ('ኅ', 1), ('ʕ', 1), ('ɗ', 1), ('ป', 1), ('ố', 1), ('ญ', 1), ('ཉ', 1), ('┃', 1), ('⋯', 1), ('̱', 1), ('ϣ', 1), ('ⲉ', 1), ('ⲛ', 1), ('ⲟ', 1), ('ⲩ', 1), ('ϯ', 1), ('ⲅ', 1), ('̅', 1), ('ქ', 1), ('ღ', 1), ('ყ', 1), ('ვ', 1), ('ἠ', 1), ('ⴷ', 1), ('ⵏ', 1), ('ⵄ', 1), ('ⵛ', 1), ('ừ', 1), ('ཚ', 1), ('པ', 1), ('ལ', 1), ('კ', 1), ('ʔ', 1), ('∀', 1), ('ʒ', 1), ('ĭ', 1), ('👍', 1), ('ླ', 1), ('க', 1), ('ழ', 1), ('ந', 1), ('்', 1), ('த', 1), ('ை', 1), ('ஏ', 1), ('ச', 1), ('ạ', 1), ('ϊ', 1), ('ŷ', 1), ('♞', 1)]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.5 64-bit"
        },
        "interpreter": {
            "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}