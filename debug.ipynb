{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/corpus to /Users/Gianni/.cache/huggingface/datasets/text/corpus-86b2280e5e7bac95/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2972.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 453.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /Users/Gianni/.cache/huggingface/datasets/text/corpus-86b2280e5e7bac95/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 44.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import semiolog as slg\n",
    "\n",
    "semiotic = slg.Cenematic(\"en_bnc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! Please ensure your labels are passed as the 'labels' key of the input dict so that they are accessible to the model during the forward pass. To disable this behaviour, please pass a loss argument, or explicitly pass loss=None if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLG: Compiling model\n",
      "SLG: Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.20ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.25ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.22ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLG: Building train set\n",
      "SLG: Building validation set\n",
      "SLG: Starting training...\n",
      "\n",
      "Epoch 1/2\n",
      "3/3 [==============================] - 40s 9s/step - loss: 10.3446 - val_loss: 10.3301\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 21s 7s/step - loss: 10.1677 - val_loss: 10.3435\n",
      "SLG: Training finished\n",
      "\n",
      "SLG: Model saved.\n",
      "SLG: Training history saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SLG: Model built!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "semiotic.paradigmatic.build(dataset=DatasetDict({\n",
    "    \"train\": Dataset.from_dict(semiotic.corpus.dataset[\"train\"][:100]),\n",
    "    \"dev\": Dataset.from_dict(semiotic.corpus.dataset[\"dev\"][:100]),\n",
    "    \"test\": Dataset.from_dict(semiotic.corpus.dataset[\"test\"][:100])\n",
    "})\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
